{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"TaPS: Task Performance Suite","text":"<p>TaPS is a standardized framework for evaluating task-based execution frameworks and data management systems using a suite a real and synthetic scientific applications.</p> <p>TaPS provides:</p> <ul> <li>A framework for writing benchmark applications and a plugin system for evaluating arbitrary task executors and data management systems.</li> <li>A suite of benchmark applications spanning domains like linear algebra, drug discovery, machine learning, text analysis, molecular design, and astronomy.</li> <li>Support for popular task execution frameworks (Dask Distributed, Globus Compute, Parsl, Ray) and data management systems (ProxyStore).</li> </ul> <p>Check out the Get Started Guide to learn more.</p>"},{"location":"get-started/","title":"Quick Start","text":"<p>TaPS is a standardized framework for evaluating task-based execution frameworks and data management systems using a suite a real and synthetic scientific applications.</p>"},{"location":"get-started/#installation","title":"Installation","text":"<pre><code>git clone https://github.com/proxystore/taps\ncd taps\npython -m venv venv\n. venv/bin/activate\npip install -e .\n</code></pre> <p>Documentation on installing for local development is provided in Contributing.</p>"},{"location":"get-started/#usage","title":"Usage","text":"<p>Applications can be executed from the CLI. <pre><code>python -m taps.run --app {name} {args}\n</code></pre> See <code>python -m taps.run --help</code> for a list of applications.</p>"},{"location":"get-started/#example-app","title":"Example App","text":"<p>The Cholesky Factorization app, for example, can be run using <code>--app cholesky</code> and the required arguments. <pre><code>python -m taps.run --app cholesky --app.matrix_size 100 --app.block_size 25\n</code></pre></p> <p>Note</p> <p>This <code>cholesky</code> app requires having installed TaPS with the <code>[cholesky]</code> option. <pre><code>pip install -e .[cholesky]\n</code></pre></p> <p>Many execution options can be altered directly from the command line. The above example, by default, used a <code>ProcessPoolExecutor</code> but we can switch to a different executor easily with the <code>--engine.executor</code> flag. <pre><code>python -m taps.run \\\n    --app cholesky --app.matrix_size 100 --app.block_size 25 \\\n    --engine.executor thread-pool\n</code></pre></p>"},{"location":"get-started/#config-files","title":"Config Files","text":"<p>Alternatively, applications can be configured using a TOML configuration file.</p> config.toml<pre><code>[app]\nname = \"cholesky\"\nmatrix_size = 100\nblock_size = 25\n\n[engine]\ntask_record_file_name = \"tasks.jsonl\"\n\n[engine.executor]\nname = \"process-pool\"\nmax_processes = 10\n\n[engine.filter]\nname = \"null\"\n\n[engine.transformer]\nname = \"null\"\n\n[run]\ndir_format = \"runs/{name}_{executor}_{timestamp}\"\n\n[logging]\nfile_level = \"WARNING\"\nfile_name = \"log.txt\"\nlevel = \"INFO\"\n</code></pre> <p>To execute from a config, use the <code>-c/--config</code> option. <pre><code>python -m taps.run --config config.toml\n</code></pre></p> <p>Options provided via the CLI will override those options present in a config file.</p>"},{"location":"get-started/#apps","title":"Apps","text":"<p>Checkout the Application Guides to learn about all of the different benchmarking applications provided by TaPS.</p>"},{"location":"api/","title":"taps","text":"<code>taps/__init__.py</code> <p>Task Performance Suite (TaPS).</p> <p>TaPS is provides a common framework for writing task-based, distributed applications supported through an extensive plugin system for running applications with arbitrary task executors and data management systems. The run CLI enables users to run performance experiments in a reproducible manner.</p> <p></p> <p>Overview of the abstraction stack with the TaPS framework. TaPS provides a framework for writing applications that can be executed with a variety of plugins.</p>"},{"location":"api/SUMMARY/","title":"SUMMARY","text":"<ul> <li>taps</li> <li>taps.apps<ul> <li>app</li> <li>cholesky</li> <li>configs<ul> <li>cholesky</li> <li>docking</li> <li>failures</li> <li>fedlearn</li> <li>mapreduce</li> <li>moldesign</li> <li>montage</li> <li>synthetic</li> </ul> </li> <li>docking<ul> <li>app</li> <li>data</li> <li>train</li> </ul> </li> <li>failures<ul> <li>app</li> <li>types</li> </ul> </li> <li>fedlearn<ul> <li>app</li> <li>modules</li> <li>tasks</li> <li>types</li> <li>utils</li> </ul> </li> <li>mapreduce</li> <li>moldesign<ul> <li>app</li> <li>chemfunctions</li> <li>tasks</li> </ul> </li> <li>montage</li> <li>synthetic</li> </ul> </li> <li>taps.engine<ul> <li>config</li> <li>engine</li> <li>transform</li> </ul> </li> <li>taps.executor<ul> <li>config</li> <li>dask</li> <li>globus</li> <li>parsl</li> <li>python</li> <li>ray</li> <li>utils</li> </ul> </li> <li>taps.filter<ul> <li>config</li> <li>filters</li> </ul> </li> <li>taps.logging</li> <li>taps.plugins</li> <li>taps.record</li> <li>taps.run<ul> <li>config</li> <li>main</li> <li>parse</li> <li>utils</li> </ul> </li> <li>taps.transformer<ul> <li>config</li> <li>file</li> <li>null</li> <li>protocol</li> <li>proxy</li> </ul> </li> </ul>"},{"location":"api/logging/","title":"taps.logging","text":"<code>taps/logging.py</code>"},{"location":"api/logging/#taps.logging.init_logging","title":"init_logging()","text":"<pre><code>init_logging(\n    logfile: Path | None = None,\n    level: int | str = logging.INFO,\n    logfile_level: int | str = logging.INFO,\n    force: bool = False,\n) -&gt; None\n</code></pre> <p>Initialize logging with custom formats.</p> <p>Adds a custom log levels <code>RUN</code> and <code>APP</code> which are higher than <code>INFO</code> and lower than <code>WARNING</code>. <code>RUN</code> is used by the benchmark harness and <code>APP</code> is using within the applications.</p> Usage <pre><code>import logging\nfrom taps.logging import init_logger\n\ninit_logger(...)\n\nlogger = logging.getLogger(__name__)\nlogger.log(RUN_LOG_LEVEL, 'message')\n</code></pre> <p>Parameters:</p> <ul> <li> <code>logfile</code>             (<code>str</code>, default:                 <code>None</code> )         \u2013          <p>option filepath to write log to.</p> </li> <li> <code>level</code>             (<code>(int, str)</code>, default:                 <code>INFO</code> )         \u2013          <p>minimum logging level.</p> </li> <li> <code>logfile_level</code>             (<code>(int, str)</code>, default:                 <code>INFO</code> )         \u2013          <p>minimum logging level for the logfile.</p> </li> <li> <code>force</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>remove any existing handlers attached to the root handler. This option is useful to silencing the third-party package logging. Note: should not be set when running inside pytest.</p> </li> </ul> Source code in <code>taps/logging.py</code> <pre><code>def init_logging(\n    logfile: pathlib.Path | None = None,\n    level: int | str = logging.INFO,\n    logfile_level: int | str = logging.INFO,\n    force: bool = False,\n) -&gt; None:\n    \"\"\"Initialize logging with custom formats.\n\n    Adds a custom log levels `RUN` and `APP` which are higher than `INFO` and\n    lower than `WARNING`. `RUN` is used by the benchmark harness\n    and `APP` is using within the applications.\n\n    Usage:\n        ```python\n        import logging\n        from taps.logging import init_logger\n\n        init_logger(...)\n\n        logger = logging.getLogger(__name__)\n        logger.log(RUN_LOG_LEVEL, 'message')\n        ```\n\n    Args:\n        logfile (str): option filepath to write log to.\n        level (int, str): minimum logging level.\n        logfile_level (int, str): minimum logging level for the logfile.\n        force (bool): remove any existing handlers attached to the root\n            handler. This option is useful to silencing the third-party\n            package logging. Note: should not be set when running inside\n            pytest.\n    \"\"\"\n    logging.addLevelName(RUN_LOG_LEVEL, 'RUN')\n    logging.addLevelName(APP_LOG_LEVEL, 'APP')\n\n    stdout_handler = logging.StreamHandler(sys.stdout)\n    stdout_handler.setLevel(level)\n\n    handlers: list[logging.Handler] = [stdout_handler]\n    if logfile is not None:\n        logfile.parent.mkdir(parents=True, exist_ok=True)\n        handler = logging.FileHandler(logfile)\n        handler.setLevel(logfile_level)\n        handlers.append(handler)\n\n    kwargs: dict[str, Any] = {}\n    if force:  # pragma: no cover\n        kwargs['force'] = force\n\n    logging.basicConfig(\n        format=(\n            '[%(asctime)s.%(msecs)03d] %(levelname)-5s (%(name)s) :: '\n            '%(message)s'\n        ),\n        datefmt='%Y-%m-%d %H:%M:%S',\n        level=logging.DEBUG,\n        handlers=handlers,\n        **kwargs,\n    )\n</code></pre>"},{"location":"api/plugins/","title":"taps.plugins","text":"<code>taps/plugins.py</code>"},{"location":"api/plugins/#taps.plugins.register","title":"register()","text":"<pre><code>register(\n    kind: PluginType,\n) -&gt; Callable[[type[ConfigType]], type[ConfigType]]\n</code></pre> <p>Decorator for registering plugin configurations.</p> Example <p>An app config can be defined and registered using a name. <pre><code>from concurrent.futures import Executor\n\nfrom pydantic import Field\n\nfrom taps.plugins import register\nfrom taps.executor.config import ExecutorConfig\n\n@register('executor')\nclass FooConfig(ExecutorConfig):\n    name: Literal['foo'] = 'foo'\n    n: int = Field(1, description='count')\n\n    def get_executor(self) -&gt; Executor:\n        ...\n</code></pre></p> <p>Registration will make the executor named \"foo\" available within the CLI and configuration files. ```</p> <p>Parameters:</p> <ul> <li> <code>kind</code>             (<code>PluginType</code>)         \u2013          <p>Kind of plugin that is being registered.</p> </li> </ul> Source code in <code>taps/plugins.py</code> <pre><code>def register(\n    kind: PluginType,\n) -&gt; Callable[[type[ConfigType]], type[ConfigType]]:\n    \"\"\"Decorator for registering plugin configurations.\n\n    Example:\n        An app config can be defined and registered using a name.\n        ```python\n        from concurrent.futures import Executor\n\n        from pydantic import Field\n\n        from taps.plugins import register\n        from taps.executor.config import ExecutorConfig\n\n        @register('executor')\n        class FooConfig(ExecutorConfig):\n            name: Literal['foo'] = 'foo'\n            n: int = Field(1, description='count')\n\n            def get_executor(self) -&gt; Executor:\n                ...\n        ```\n\n        Registration will make the executor named \"foo\" available within\n        the CLI and configuration files.\n        ```\n\n    Args:\n        kind: Kind of plugin that is being registered.\n    \"\"\"\n\n    def _decorator(cls: type[ConfigType]) -&gt; type[ConfigType]:\n        try:\n            registry = _REGISTERED_CONFIGS[kind]\n        except KeyError:\n            raise ValueError(f'Unknown plugin type \"{kind}\".') from None\n\n        try:\n            name = cls.model_fields['name'].default\n            registry[name] = cls  # type: ignore[index]\n        except Exception as e:\n            raise RuntimeError(\n                f'Failed to register {cls.__name__} as a {kind} plugin.',\n            ) from e\n\n        return cls\n\n    return _decorator\n</code></pre>"},{"location":"api/plugins/#taps.plugins.get_app_configs","title":"get_app_configs()","text":"<pre><code>get_app_configs() -&gt; dict[str, type[AppConfig]]\n</code></pre> <p>Get all registered application configs.</p> <p>Returns:</p> <ul> <li> <code>dict[str, type[AppConfig]]</code>         \u2013          <p>Mapping of application name to the config type.</p> </li> </ul> Source code in <code>taps/plugins.py</code> <pre><code>def get_app_configs() -&gt; dict[str, type[AppConfig]]:\n    \"\"\"Get all registered application configs.\n\n    Returns:\n        Mapping of application name to the config type.\n    \"\"\"\n    return _REGISTERED_APP_CONFIGS.copy()\n</code></pre>"},{"location":"api/plugins/#taps.plugins.get_executor_configs","title":"get_executor_configs()","text":"<pre><code>get_executor_configs() -&gt; dict[str, type[ExecutorConfig]]\n</code></pre> <p>Get all registered executor configs.</p> <p>Returns:</p> <ul> <li> <code>dict[str, type[ExecutorConfig]]</code>         \u2013          <p>Mapping of executor name to the config type.</p> </li> </ul> Source code in <code>taps/plugins.py</code> <pre><code>def get_executor_configs() -&gt; dict[str, type[ExecutorConfig]]:\n    \"\"\"Get all registered executor configs.\n\n    Returns:\n        Mapping of executor name to the config type.\n    \"\"\"\n    return _REGISTERED_EXECUTOR_CONFIGS.copy()\n</code></pre>"},{"location":"api/plugins/#taps.plugins.get_filter_configs","title":"get_filter_configs()","text":"<pre><code>get_filter_configs() -&gt; dict[str, type[FilterConfig]]\n</code></pre> <p>Get all registered filter configs.</p> <p>Returns:</p> <ul> <li> <code>dict[str, type[FilterConfig]]</code>         \u2013          <p>Mapping of filter name to the config type.</p> </li> </ul> Source code in <code>taps/plugins.py</code> <pre><code>def get_filter_configs() -&gt; dict[str, type[FilterConfig]]:\n    \"\"\"Get all registered filter configs.\n\n    Returns:\n        Mapping of filter name to the config type.\n    \"\"\"\n    return _REGISTERED_FILTER_CONFIGS.copy()\n</code></pre>"},{"location":"api/plugins/#taps.plugins.get_transformer_configs","title":"get_transformer_configs()","text":"<pre><code>get_transformer_configs() -&gt; (\n    dict[str, type[TransformerConfig]]\n)\n</code></pre> <p>Get all registered transformer configs.</p> <p>Returns:</p> <ul> <li> <code>dict[str, type[TransformerConfig]]</code>         \u2013          <p>Mapping of transformer name to the config type.</p> </li> </ul> Source code in <code>taps/plugins.py</code> <pre><code>def get_transformer_configs() -&gt; dict[str, type[TransformerConfig]]:\n    \"\"\"Get all registered transformer configs.\n\n    Returns:\n        Mapping of transformer name to the config type.\n    \"\"\"\n    return _REGISTERED_TRANSFORMER_CONFIGS.copy()\n</code></pre>"},{"location":"api/record/","title":"taps.record","text":"<code>taps/record.py</code>"},{"location":"api/record/#taps.record.Record","title":"Record  <code>module-attribute</code>","text":"<pre><code>Record: TypeAlias = Dict[str, Any]\n</code></pre> <p>Record type.</p>"},{"location":"api/record/#taps.record.RecordLogger","title":"RecordLogger","text":"<p>             Bases: <code>Protocol</code></p> <p>Record logger protocol.</p>"},{"location":"api/record/#taps.record.RecordLogger.log","title":"log()","text":"<pre><code>log(record: Record) -&gt; None\n</code></pre> <p>Log a record.</p> Source code in <code>taps/record.py</code> <pre><code>def log(self, record: Record) -&gt; None:\n    \"\"\"Log a record.\"\"\"\n    ...\n</code></pre>"},{"location":"api/record/#taps.record.RecordLogger.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the logger.</p> Source code in <code>taps/record.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close the logger.\"\"\"\n    ...\n</code></pre>"},{"location":"api/record/#taps.record.JSONRecordLogger","title":"JSONRecordLogger","text":"<pre><code>JSONRecordLogger(filepath: Path | str)\n</code></pre> <p>JSON lines record logger.</p> <p>Logs records as JSON strings per line to a file.</p> <p>Parameters:</p> <ul> <li> <code>filepath</code>             (<code>Path | str</code>)         \u2013          <p>Filepath to log to.</p> </li> </ul> Source code in <code>taps/record.py</code> <pre><code>def __init__(self, filepath: pathlib.Path | str) -&gt; None:\n    self._filepath = pathlib.Path(filepath)\n    self._handle = open(self._filepath, 'a')  # noqa: SIM115\n</code></pre>"},{"location":"api/record/#taps.record.JSONRecordLogger.log","title":"log()","text":"<pre><code>log(record: Record) -&gt; None\n</code></pre> <p>Log a record.</p> Source code in <code>taps/record.py</code> <pre><code>def log(self, record: Record) -&gt; None:\n    \"\"\"Log a record.\"\"\"\n    self._handle.write(json.dumps(record) + '\\n')\n</code></pre>"},{"location":"api/record/#taps.record.JSONRecordLogger.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the logger.</p> Source code in <code>taps/record.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close the logger.\"\"\"\n    self._handle.close()\n</code></pre>"},{"location":"api/record/#taps.record.NullRecordLogger","title":"NullRecordLogger","text":"<p>Null/no-op record logger.</p>"},{"location":"api/record/#taps.record.NullRecordLogger.log","title":"log()","text":"<pre><code>log(record: Record) -&gt; None\n</code></pre> <p>Log a record.</p> Source code in <code>taps/record.py</code> <pre><code>def log(self, record: Record) -&gt; None:\n    \"\"\"Log a record.\"\"\"\n    return\n</code></pre>"},{"location":"api/record/#taps.record.NullRecordLogger.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the logger.</p> Source code in <code>taps/record.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close the logger.\"\"\"\n    return\n</code></pre>"},{"location":"api/apps/","title":"taps.apps","text":"<code>taps/apps/__init__.py</code>"},{"location":"api/apps/app/","title":"taps.apps.app","text":"<code>taps/apps/app.py</code>"},{"location":"api/apps/app/#taps.apps.app.App","title":"App","text":"<p>             Bases: <code>Protocol</code></p> <p>Application protocol.</p>"},{"location":"api/apps/app/#taps.apps.app.App.run","title":"run()","text":"<pre><code>run(engine: Engine, run_dir: Path) -&gt; None\n</code></pre> <p>Run the application.</p> Source code in <code>taps/apps/app.py</code> <pre><code>def run(\n    self,\n    engine: Engine,\n    run_dir: pathlib.Path,\n) -&gt; None:\n    \"\"\"Run the application.\"\"\"\n    ...\n</code></pre>"},{"location":"api/apps/app/#taps.apps.app.App.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the application.</p> Source code in <code>taps/apps/app.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close the application.\"\"\"\n    ...\n</code></pre>"},{"location":"api/apps/app/#taps.apps.app.AppConfig","title":"AppConfig","text":"<p>             Bases: <code>BaseModel</code>, <code>ABC</code></p> <p>Application config protocol.</p> <p>Application configs must define the <code>create_app()</code> method.</p> <p>After instantiation, all <code>pathlib.Path</code> types will be resolved to convert them to absolute paths.</p>"},{"location":"api/apps/app/#taps.apps.app.AppConfig.get_app","title":"get_app()  <code>abstractmethod</code>","text":"<pre><code>get_app() -&gt; App\n</code></pre> <p>Initialize an app instance from this config.</p> Source code in <code>taps/apps/app.py</code> <pre><code>@abc.abstractmethod\ndef get_app(self) -&gt; App:\n    \"\"\"Initialize an app instance from this config.\"\"\"\n    ...\n</code></pre>"},{"location":"api/apps/cholesky/","title":"taps.apps.cholesky","text":"<code>taps/apps/cholesky.py</code> <p>Cholesky decomposition application.</p>"},{"location":"api/apps/cholesky/#taps.apps.cholesky.CholeskyApp","title":"CholeskyApp","text":"<pre><code>CholeskyApp(matrix_size: int, block_size: int)\n</code></pre> <p>Cholesky decomposition application.</p> <p>Computes the tiled Cholesky decomposition of a random positive-definite square matrix.</p> <p>Parameters:</p> <ul> <li> <code>matrix_size</code>             (<code>int</code>)         \u2013          <p>Matrix side length.</p> </li> <li> <code>block_size</code>             (<code>int</code>)         \u2013          <p>Block size length.</p> </li> </ul> Source code in <code>taps/apps/cholesky.py</code> <pre><code>def __init__(self, matrix_size: int, block_size: int) -&gt; None:\n    self.matrix_size = matrix_size\n    self.block_size = block_size\n</code></pre>"},{"location":"api/apps/cholesky/#taps.apps.cholesky.CholeskyApp.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the application.</p> Source code in <code>taps/apps/cholesky.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close the application.\"\"\"\n    pass\n</code></pre>"},{"location":"api/apps/cholesky/#taps.apps.cholesky.CholeskyApp.run","title":"run()","text":"<pre><code>run(engine: Engine, run_dir: Path) -&gt; None\n</code></pre> <p>Run the application.</p> <p>Parameters:</p> <ul> <li> <code>engine</code>             (<code>Engine</code>)         \u2013          <p>Application execution engine.</p> </li> <li> <code>run_dir</code>             (<code>Path</code>)         \u2013          <p>Run directory.</p> </li> </ul> Source code in <code>taps/apps/cholesky.py</code> <pre><code>def run(self, engine: Engine, run_dir: pathlib.Path) -&gt; None:\n    \"\"\"Run the application.\n\n    Args:\n        engine: Application execution engine.\n        run_dir: Run directory.\n    \"\"\"\n    max_print_size = 8\n\n    matrix = create_psd_matrix(self.matrix_size)\n    lower = np.zeros_like(matrix)\n\n    n = matrix.shape[0]\n    block_size = min(self.block_size, n)\n\n    if matrix.shape[0] &lt;= max_print_size:\n        logger.log(\n            APP_LOG_LEVEL,\n            f'Generated input matrix: {matrix.shape}\\n{matrix}',\n        )\n    else:\n        logger.log(\n            APP_LOG_LEVEL,\n            f'Generated input matrix: {matrix.shape}',\n        )\n    logger.log(APP_LOG_LEVEL, f'Block size: {block_size}')\n\n    for k in range(0, n, block_size):\n        end_k = min(k + block_size, n)\n        lower_tasks: dict[tuple[int, int], TaskFuture[np.ndarray]] = {}\n\n        lower_tasks[(k, k)] = engine.submit(\n            potrf,\n            matrix[k:end_k, k:end_k],\n        )\n\n        for i in range(k + block_size, n, block_size):\n            end_i = min(i + block_size, n)\n\n            lower_tasks[(i, k)] = engine.submit(\n                trsm,\n                lower_tasks[(k, k)],\n                matrix[i:end_i, k:end_k],\n            )\n\n        gemm_tasks: dict[tuple[int, int], TaskFuture[np.ndarray]] = {}\n\n        for i in range(k + block_size, n, block_size):\n            end_i = min(i + block_size, n)\n            for j in range(i, n, block_size):\n                end_j = min(j + block_size, n)\n\n                syrk_task = engine.submit(\n                    syrk,\n                    matrix[i:end_i, j:end_j],\n                    lower_tasks[(i, k)],\n                )\n\n                gemm_tasks[(i, j)] = engine.submit(\n                    gemm,\n                    syrk_task,\n                    lower_tasks[(i, k)],\n                    lower_tasks[(j, k)],\n                )\n\n        for (i, j), tile in lower_tasks.items():\n            end_i = min(i + block_size, n)\n            end_j = min(j + block_size, n)\n            lower[i:end_i, j:end_j] = tile.result()\n\n        for (i, j), tile in gemm_tasks.items():\n            end_i = min(i + block_size, n)\n            end_j = min(j + block_size, n)\n            matrix[i:end_i, j:end_j] = tile.result()\n\n    if matrix.shape[0] &lt;= max_print_size:\n        logger.log(APP_LOG_LEVEL, f'Output matrix:\\n{lower}')\n    else:\n        logger.log(APP_LOG_LEVEL, f'Output matrix: {lower.shape}')\n</code></pre>"},{"location":"api/apps/cholesky/#taps.apps.cholesky.potrf","title":"potrf()","text":"<pre><code>potrf(tile: ndarray) -&gt; ndarray\n</code></pre> <p>POTRF task.</p> Source code in <code>taps/apps/cholesky.py</code> <pre><code>def potrf(tile: np.ndarray) -&gt; np.ndarray:\n    \"\"\"POTRF task.\"\"\"\n    return np.linalg.cholesky(tile)\n</code></pre>"},{"location":"api/apps/cholesky/#taps.apps.cholesky.trsm","title":"trsm()","text":"<pre><code>trsm(lower: ndarray, block: ndarray) -&gt; ndarray\n</code></pre> <p>TRSM task.</p> Source code in <code>taps/apps/cholesky.py</code> <pre><code>def trsm(lower: np.ndarray, block: np.ndarray) -&gt; np.ndarray:\n    \"\"\"TRSM task.\"\"\"\n    return np.linalg.solve(lower, block.T).T\n</code></pre>"},{"location":"api/apps/cholesky/#taps.apps.cholesky.syrk","title":"syrk()","text":"<pre><code>syrk(tile: ndarray, lower: ndarray) -&gt; ndarray\n</code></pre> <p>SYRK task.</p> Source code in <code>taps/apps/cholesky.py</code> <pre><code>def syrk(tile: np.ndarray, lower: np.ndarray) -&gt; np.ndarray:\n    \"\"\"SYRK task.\"\"\"\n    return tile - np.dot(lower, lower.T)\n</code></pre>"},{"location":"api/apps/cholesky/#taps.apps.cholesky.gemm","title":"gemm()","text":"<pre><code>gemm(a: ndarray, b: ndarray, c: ndarray) -&gt; ndarray\n</code></pre> <p>GEMM task.</p> Source code in <code>taps/apps/cholesky.py</code> <pre><code>def gemm(a: np.ndarray, b: np.ndarray, c: np.ndarray) -&gt; np.ndarray:\n    \"\"\"GEMM task.\"\"\"\n    return a - np.dot(b, c)\n</code></pre>"},{"location":"api/apps/cholesky/#taps.apps.cholesky.create_psd_matrix","title":"create_psd_matrix()","text":"<pre><code>create_psd_matrix(n: int) -&gt; ndarray\n</code></pre> <p>Create a positive semi-definite matrix.</p> <p>Parameters:</p> <ul> <li> <code>n</code>             (<code>int</code>)         \u2013          <p>Create an <code>n</code> x <code>n</code> square matrix.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>         \u2013          <p>Random matrix that is positive semi-definite.</p> </li> </ul> Source code in <code>taps/apps/cholesky.py</code> <pre><code>def create_psd_matrix(n: int) -&gt; np.ndarray:\n    \"\"\"Create a positive semi-definite matrix.\n\n    Args:\n        n: Create an `n` x `n` square matrix.\n\n    Returns:\n        Random matrix that is positive semi-definite.\n    \"\"\"\n    psd = np.random.randn(n, n)\n    psd = np.dot(psd, psd.T)\n    psd += n * np.eye(n)\n    return psd\n</code></pre>"},{"location":"api/apps/mapreduce/","title":"taps.apps.mapreduce","text":"<code>taps/apps/mapreduce.py</code>"},{"location":"api/apps/mapreduce/#taps.apps.mapreduce.MapreduceApp","title":"MapreduceApp","text":"<pre><code>MapreduceApp(\n    data_dir: Path,\n    map_tasks: int | None = None,\n    generate: bool = False,\n    generated_files: int = 10,\n    generated_words: int = 10000,\n)\n</code></pre> <p>Mapreduce application.</p> <p>Parameters:</p> <ul> <li> <code>data_dir</code>             (<code>Path</code>)         \u2013          <p>Text file directory. Either contains existing text files (including in subdirectories) or will be used to store the randomly generated files.</p> </li> <li> <code>map_tasks</code>             (<code>int | None</code>, default:                 <code>None</code> )         \u2013          <p>Number of map tasks. If <code>None</code>, one map task is generated per text file. Otherwise, files are evenly distributed across the map tasks.</p> </li> <li> <code>generate</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Generate random text files for the application.</p> </li> <li> <code>generated_files</code>             (<code>int</code>, default:                 <code>10</code> )         \u2013          <p>Number of text files to generate.</p> </li> <li> <code>generated_words</code>             (<code>int</code>, default:                 <code>10000</code> )         \u2013          <p>Number of words per text file to generate.</p> </li> </ul> Source code in <code>taps/apps/mapreduce.py</code> <pre><code>def __init__(\n    self,\n    data_dir: pathlib.Path,\n    map_tasks: int | None = None,\n    generate: bool = False,\n    generated_files: int = 10,\n    generated_words: int = 10_000,\n) -&gt; None:\n    self.generate = generate\n    self.data_dir = data_dir\n\n    if self.generate:\n        files = generate_files(data_dir, generated_files, generated_words)\n        logger.log(APP_LOG_LEVEL, f'Generated {len(files)} in {data_dir}')\n    else:\n        files = [f for f in data_dir.glob('**/*') if f.is_file()]\n        logger.log(APP_LOG_LEVEL, f'Found {len(files)} in {data_dir}')\n\n    self.files = files\n    self.map_tasks = len(self.files) if map_tasks is None else map_tasks\n</code></pre>"},{"location":"api/apps/mapreduce/#taps.apps.mapreduce.MapreduceApp.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the application.</p> Source code in <code>taps/apps/mapreduce.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close the application.\"\"\"\n    if self.generate:\n        shutil.rmtree(self.data_dir)\n        logger.log(\n            APP_LOG_LEVEL,\n            f'Removed generated files in {self.data_dir}',\n        )\n</code></pre>"},{"location":"api/apps/mapreduce/#taps.apps.mapreduce.MapreduceApp.run","title":"run()","text":"<pre><code>run(engine: Engine, run_dir: Path) -&gt; None\n</code></pre> <p>Run the application.</p> <p>Parameters:</p> <ul> <li> <code>engine</code>             (<code>Engine</code>)         \u2013          <p>Application execution engine.</p> </li> <li> <code>run_dir</code>             (<code>Path</code>)         \u2013          <p>Run directory.</p> </li> </ul> Source code in <code>taps/apps/mapreduce.py</code> <pre><code>def run(self, engine: Engine, run_dir: pathlib.Path) -&gt; None:\n    \"\"\"Run the application.\n\n    Args:\n        engine: Application execution engine.\n        run_dir: Run directory.\n    \"\"\"\n    map_futures = [\n        engine.submit(map_task, *batch)\n        for batch in _chunkify(self.files, self.map_tasks)\n    ]\n    logger.log(\n        APP_LOG_LEVEL,\n        f'Submitted {len(map_futures):,} map tasks over '\n        f'{len(self.files):,} input files',\n    )\n\n    reduce_future = engine.submit(reduce_task, *map_futures)\n    logger.log(APP_LOG_LEVEL, 'Submitted reduce task')\n\n    word_counts = reduce_future.result()\n    logger.log(APP_LOG_LEVEL, 'Reduce task finished')\n\n    most_common_words = word_counts.most_common(10)\n    logger.log(\n        APP_LOG_LEVEL,\n        f'{len(most_common_words)} most frequent words:',\n    )\n    for word, count in most_common_words:\n        logger.log(APP_LOG_LEVEL, f'{word} ({count:,})')\n\n    logger.log(\n        APP_LOG_LEVEL,\n        f'Total number of words: {sum(word_counts.values()):,}',\n    )\n</code></pre>"},{"location":"api/apps/mapreduce/#taps.apps.mapreduce.map_task","title":"map_task()","text":"<pre><code>map_task(*files: Path) -&gt; Counter[str]\n</code></pre> <p>Count words in files.</p> Source code in <code>taps/apps/mapreduce.py</code> <pre><code>def map_task(*files: pathlib.Path) -&gt; Counter[str]:\n    \"\"\"Count words in files.\"\"\"\n    counts: Counter[str] = Counter()\n    for file in files:\n        with open(file, errors='ignore') as f:\n            for line in f:\n                counts.update(line.split())\n    return counts\n</code></pre>"},{"location":"api/apps/mapreduce/#taps.apps.mapreduce.reduce_task","title":"reduce_task()","text":"<pre><code>reduce_task(*counts: Counter[str]) -&gt; Counter[str]\n</code></pre> <p>Combine word counts.</p> Source code in <code>taps/apps/mapreduce.py</code> <pre><code>def reduce_task(*counts: Counter[str]) -&gt; Counter[str]:\n    \"\"\"Combine word counts.\"\"\"\n    total: Counter[str] = Counter()\n    for count in counts:\n        total.update(count)\n    return total\n</code></pre>"},{"location":"api/apps/mapreduce/#taps.apps.mapreduce.generate_word","title":"generate_word()","text":"<pre><code>generate_word(\n    word_min_length: int, word_max_length: int\n) -&gt; str\n</code></pre> <p>Generate a random word.</p> Source code in <code>taps/apps/mapreduce.py</code> <pre><code>def generate_word(word_min_length: int, word_max_length: int) -&gt; str:\n    \"\"\"Generate a random word.\"\"\"\n    length = random.randint(word_min_length, word_max_length)\n    return ''.join(random.choices(string.ascii_lowercase, k=length))\n</code></pre>"},{"location":"api/apps/mapreduce/#taps.apps.mapreduce.generate_text","title":"generate_text()","text":"<pre><code>generate_text(\n    word_count: int,\n    word_min_length: int,\n    word_max_length: int,\n) -&gt; str\n</code></pre> <p>Generate a paragraph with the specified number of words.</p> Source code in <code>taps/apps/mapreduce.py</code> <pre><code>def generate_text(\n    word_count: int,\n    word_min_length: int,\n    word_max_length: int,\n) -&gt; str:\n    \"\"\"Generate a paragraph with the specified number of words.\"\"\"\n    return ' '.join(\n        generate_word(word_min_length, word_max_length)\n        for _ in range(word_count)\n    )\n</code></pre>"},{"location":"api/apps/mapreduce/#taps.apps.mapreduce.generate_files","title":"generate_files()","text":"<pre><code>generate_files(\n    directory: Path,\n    file_count: int,\n    words_per_file: int,\n    *,\n    min_word_length: int = 2,\n    max_word_length: int = 10\n) -&gt; list[Path]\n</code></pre> <p>Generate text files with random text.</p> <p>Parameters:</p> <ul> <li> <code>directory</code>             (<code>Path</code>)         \u2013          <p>Directory to write the files to.</p> </li> <li> <code>file_count</code>             (<code>int</code>)         \u2013          <p>Number of files to generate.</p> </li> <li> <code>words_per_file</code>             (<code>int</code>)         \u2013          <p>Number of words per file.</p> </li> <li> <code>min_word_length</code>             (<code>int</code>, default:                 <code>2</code> )         \u2013          <p>Minimum character length of randomly generated words.</p> </li> <li> <code>max_word_length</code>             (<code>int</code>, default:                 <code>10</code> )         \u2013          <p>Maximum character length of randomly generated words.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[Path]</code>         \u2013          <p>List of generated files.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013          <p>if <code>directory</code> is not empty.</p> </li> </ul> Source code in <code>taps/apps/mapreduce.py</code> <pre><code>def generate_files(\n    directory: pathlib.Path,\n    file_count: int,\n    words_per_file: int,\n    *,\n    min_word_length: int = 2,\n    max_word_length: int = 10,\n) -&gt; list[pathlib.Path]:\n    \"\"\"Generate text files with random text.\n\n    Args:\n        directory: Directory to write the files to.\n        file_count: Number of files to generate.\n        words_per_file: Number of words per file.\n        min_word_length: Minimum character length of randomly generated words.\n        max_word_length: Maximum character length of randomly generated words.\n\n    Returns:\n        List of generated files.\n\n    Raises:\n        ValueError: if `directory` is not empty.\n    \"\"\"\n    if directory.is_dir() and any(directory.iterdir()):\n        raise ValueError('Directory {directory} is not empty')\n\n    directory.mkdir(parents=True, exist_ok=True)\n\n    files = []\n    for i in range(file_count):\n        filename = (directory / f'{i}.txt').resolve()\n        text = generate_text(words_per_file, min_word_length, max_word_length)\n        with open(filename, 'w') as f:\n            f.write(text)\n        files.append(filename)\n\n    return files\n</code></pre>"},{"location":"api/apps/montage/","title":"taps.apps.montage","text":"<code>taps/apps/montage.py</code>"},{"location":"api/apps/montage/#taps.apps.montage.MontageApp","title":"MontageApp","text":"<pre><code>MontageApp(\n    img_folder: Path,\n    img_tbl: str = \"Kimages.tbl\",\n    img_hdr: str = \"Kimages.hdr\",\n    output_dir: str = \"data/\",\n)\n</code></pre> <p>Montage application.</p> <p>Parameters:</p> <ul> <li> <code>img_folder</code>             (<code>Path</code>)         \u2013          <p>Path to input image directory.</p> </li> <li> <code>img_tbl</code>             (<code>str</code>, default:                 <code>'Kimages.tbl'</code> )         \u2013          <p>Name of the image table file.</p> </li> <li> <code>img_hdr</code>             (<code>str</code>, default:                 <code>'Kimages.hdr'</code> )         \u2013          <p>Name of the image header file.</p> </li> <li> <code>output_dir</code>             (<code>str</code>, default:                 <code>'data/'</code> )         \u2013          <p>Output directory path for intermediate and result data.</p> </li> </ul> Source code in <code>taps/apps/montage.py</code> <pre><code>def __init__(\n    self,\n    img_folder: pathlib.Path,\n    img_tbl: str = 'Kimages.tbl',\n    img_hdr: str = 'Kimages.hdr',\n    output_dir: str = 'data/',\n) -&gt; None:\n    self.img_folder = img_folder\n    self.img_tbl = img_tbl\n    self.img_hdr = img_hdr\n    self.output_dir = output_dir\n</code></pre>"},{"location":"api/apps/montage/#taps.apps.montage.MontageApp.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the application.</p> Source code in <code>taps/apps/montage.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close the application.\"\"\"\n    pass\n</code></pre>"},{"location":"api/apps/montage/#taps.apps.montage.MontageApp.run","title":"run()","text":"<pre><code>run(engine: Engine, run_dir: Path) -&gt; None\n</code></pre> <p>Run the application.</p> <p>Parameters:</p> <ul> <li> <code>engine</code>             (<code>Engine</code>)         \u2013          <p>Application execution engine.</p> </li> <li> <code>run_dir</code>             (<code>Path</code>)         \u2013          <p>Run directory.</p> </li> </ul> Source code in <code>taps/apps/montage.py</code> <pre><code>def run(self, engine: Engine, run_dir: pathlib.Path) -&gt; None:  # noqa: PLR0915\n    \"\"\"Run the application.\n\n    Args:\n        engine: Application execution engine.\n        run_dir: Run directory.\n    \"\"\"\n    output_dir = run_dir / self.output_dir\n    output_dir.mkdir(parents=True, exist_ok=True)\n\n    img_tbl = output_dir / self.img_tbl\n    img_hdr = output_dir / self.img_hdr\n    configure_montage(self.img_folder, img_tbl, img_hdr)\n\n    logger.log(\n        APP_LOG_LEVEL,\n        f'Configured output directory ({output_dir})',\n    )\n\n    projections_dir = output_dir / 'projections'\n    projections_dir.mkdir(parents=True, exist_ok=True)\n\n    mproject_outputs = []\n    logger.log(APP_LOG_LEVEL, 'Starting projections')\n    for image in self.img_folder.glob('*.fits'):\n        input_image = self.img_folder / image\n        output_image_path = projections_dir / f'hdu0_{image.name}'\n\n        out = engine.submit(\n            mproject,\n            input_path=input_image,\n            template_path=img_hdr,\n            output_path=output_image_path,\n        )\n        mproject_outputs.append(out)\n\n    wait(mproject_outputs)\n    logger.log(APP_LOG_LEVEL, 'Projections completed')\n\n    img_tbl_fut = engine.submit(\n        mimgtbl,\n        img_dir=projections_dir,\n        tbl_path=output_dir / 'images.tbl',\n    )\n    diffs_tbl_fut = engine.submit(\n        moverlaps,\n        img_tbl=img_tbl_fut,\n        diffs_tbl=output_dir / 'diffs.tbl',\n    )\n    diffs_dir = output_dir / 'diffs'\n    diffs_dir.mkdir(parents=True, exist_ok=True)\n\n    diffs_tbl = diffs_tbl_fut.result()\n    df = pd.read_csv(diffs_tbl, comment='#', sep='\\\\s+').drop(0)\n    images1 = list(df['|.1'])\n    images2 = list(df['cntr2'])\n    outputs = list(df['|.2'])\n\n    mdiff_futures = []\n    logger.log(APP_LOG_LEVEL, 'Starting difference computations')\n    for image1, image2, output in zip(images1, images2, outputs):\n        future = engine.submit(\n            mdiff,\n            image_1=projections_dir / image1,\n            image_2=projections_dir / image2,\n            template=img_hdr,\n            output_path=diffs_dir / output,\n        )\n        mdiff_futures.append(future)\n\n    wait(mdiff_futures)\n    logger.log(APP_LOG_LEVEL, 'Differences completed')\n\n    corrections_fut = engine.submit(\n        bgexec_prep,\n        img_table=img_tbl_fut,\n        diffs_table=diffs_tbl,\n        diff_dir=diffs_dir,\n        output_dir=output_dir,\n    )\n\n    corrections_dir = output_dir / 'corrections'\n    corrections_dir.mkdir(parents=True, exist_ok=True)\n\n    corrections_tbl = corrections_fut.result()\n\n    corrections = pd.read_csv(corrections_tbl, comment='|', sep='\\\\s+')\n    corrections.loc[90] = list(corrections.columns)\n    corrections.columns = ['id', 'a', 'b', 'c']\n    corrections['id'] = corrections['id'].astype(int)\n\n    img_tbl = img_tbl_fut.result()\n    images_table = pd.read_csv(img_tbl, comment='|', sep='\\\\s+')\n\n    bgexec_futures = []\n    logger.log(APP_LOG_LEVEL, 'Starting background computations')\n    for i, input_image in enumerate(list(images_table['fitshdr'])):\n        input_path = pathlib.Path(input_image)\n        output_path = corrections_dir / input_path.name\n        correction_values = list(\n            corrections.loc[corrections['id'] == i].values[0],\n        )\n\n        future = engine.submit(\n            mbackground,\n            in_image=input_path,\n            out_image=output_path,\n            a=correction_values[1],\n            b=correction_values[2],\n            c=correction_values[3],\n        )\n\n        bgexec_futures.append(future)\n\n    wait(bgexec_futures)\n    logger.log(APP_LOG_LEVEL, 'Backgrounds completed')\n\n    mosaic_future = engine.submit(\n        madd,\n        img_tbl_fut,\n        img_hdr,\n        output_dir / 'm17.fits',\n        corrections_dir,\n    )\n\n    logger.log(\n        APP_LOG_LEVEL,\n        f'Created output FITS file at {mosaic_future.result()}',\n    )\n</code></pre>"},{"location":"api/apps/montage/#taps.apps.montage.configure_montage","title":"configure_montage()","text":"<pre><code>configure_montage(\n    img_folder: Path, img_tbl: Path, img_hdr: Path\n) -&gt; None\n</code></pre> <p>Montage Mosaic application setup.</p> <p>This function generates a header file bounding a collection of data specified by the input image dir.</p> <p>Parameters:</p> <ul> <li> <code>img_folder</code>             (<code>Path</code>)         \u2013          <p>Path to input image directory.</p> </li> <li> <code>img_tbl</code>             (<code>Path</code>)         \u2013          <p>Name of the image table file.</p> </li> <li> <code>img_hdr</code>             (<code>Path</code>)         \u2013          <p>Name of the image header file.</p> </li> </ul> Source code in <code>taps/apps/montage.py</code> <pre><code>def configure_montage(\n    img_folder: pathlib.Path,\n    img_tbl: pathlib.Path,\n    img_hdr: pathlib.Path,\n) -&gt; None:\n    \"\"\"Montage Mosaic application setup.\n\n    This function generates a header file bounding a\n    collection of data specified by the input image dir.\n\n    Args:\n        img_folder: Path to input image directory.\n        img_tbl: Name of the image table file.\n        img_hdr: Name of the image header file.\n    \"\"\"\n    import montage_wrapper as montage\n\n    imgtbl_log = montage.mImgtbl(str(img_folder), str(img_tbl))\n    logger.debug(f'mImgtbl:\\n{imgtbl_log}')\n\n    mkhdr_log = montage.mMakeHdr(str(img_tbl), str(img_hdr))\n    logger.debug(f'mMakeHdr:\\n{mkhdr_log}')\n</code></pre>"},{"location":"api/apps/montage/#taps.apps.montage.mproject","title":"mproject()","text":"<pre><code>mproject(\n    input_path: Path, template_path: Path, output_path: Path\n) -&gt; Path\n</code></pre> <p>Wrapper to Montage mProject function.</p> <p>The function reprojects a single image to the scale defined in a FITS header template file.</p> <p>Parameters:</p> <ul> <li> <code>input_path</code>             (<code>Path</code>)         \u2013          <p>FITS file to reproject.</p> </li> <li> <code>template_path</code>             (<code>Path</code>)         \u2013          <p>FITS header file used to define the desired output.</p> </li> <li> <code>output_path</code>             (<code>Path</code>)         \u2013          <p>Output filepath.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Path</code>         \u2013          <p>Output filepath for chaining task dependencies.</p> </li> </ul> Source code in <code>taps/apps/montage.py</code> <pre><code>def mproject(\n    input_path: pathlib.Path,\n    template_path: pathlib.Path,\n    output_path: pathlib.Path,\n) -&gt; pathlib.Path:\n    \"\"\"Wrapper to Montage mProject function.\n\n    The function reprojects a single image to the scale defined\n    in a FITS header template file.\n\n    Args:\n        input_path: FITS file to reproject.\n        template_path: FITS header file used to define the desired output.\n        output_path: Output filepath.\n\n    Returns:\n        Output filepath for chaining task dependencies.\n    \"\"\"\n    import montage_wrapper as montage\n\n    project_log = montage.mProject(\n        str(input_path),\n        str(output_path),\n        str(template_path),\n    )\n    logger.debug(f'mProject:\\n{project_log}')\n\n    return output_path\n</code></pre>"},{"location":"api/apps/montage/#taps.apps.montage.mimgtbl","title":"mimgtbl()","text":"<pre><code>mimgtbl(img_dir: Path, tbl_path: Path) -&gt; Path\n</code></pre> <p>Wrapper to Montage Imgtbl function.</p> <p>The function extracts the FITS header geometry information from a set of files and creates an ASCII image metadata table.</p> <p>Parameters:</p> <ul> <li> <code>img_dir</code>             (<code>Path</code>)         \u2013          <p>Input image directory.</p> </li> <li> <code>tbl_path</code>             (<code>Path</code>)         \u2013          <p>FITS table path.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Path</code>         \u2013          <p>Path to table file for chaining task dependencies.</p> </li> </ul> Source code in <code>taps/apps/montage.py</code> <pre><code>def mimgtbl(\n    img_dir: pathlib.Path,\n    tbl_path: pathlib.Path,\n) -&gt; pathlib.Path:\n    \"\"\"Wrapper to Montage Imgtbl function.\n\n    The function extracts the FITS header geometry information\n    from a set of files and creates an ASCII image metadata table.\n\n    Args:\n        img_dir: Input image directory.\n        tbl_path: FITS table path.\n\n    Returns:\n        Path to table file for chaining task dependencies.\n    \"\"\"\n    import montage_wrapper as montage\n\n    imgtbl_log = montage.mImgtbl(str(img_dir), str(tbl_path))\n    logger.debug(f'mImgtbl:\\n{imgtbl_log}')\n\n    return tbl_path\n</code></pre>"},{"location":"api/apps/montage/#taps.apps.montage.moverlaps","title":"moverlaps()","text":"<pre><code>moverlaps(img_tbl: Path, diffs_tbl: Path) -&gt; Path\n</code></pre> <p>Wrapper to Montage Overlaps function.</p> <p>The function takes a list of of images and generates a list of overlaps.</p> <p>Parameters:</p> <ul> <li> <code>img_tbl</code>             (<code>Path</code>)         \u2013          <p>Image metadata file.</p> </li> <li> <code>diffs_tbl</code>             (<code>Path</code>)         \u2013          <p>Path for the output diff table.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Path</code>         \u2013          <p>Path to the difference table file for chaining task dependencies.</p> </li> </ul> Source code in <code>taps/apps/montage.py</code> <pre><code>def moverlaps(\n    img_tbl: pathlib.Path,\n    diffs_tbl: pathlib.Path,\n) -&gt; pathlib.Path:\n    \"\"\"Wrapper to Montage Overlaps function.\n\n    The function takes a list of of images and generates a list of overlaps.\n\n    Args:\n        img_tbl: Image metadata file.\n        diffs_tbl: Path for the output diff table.\n\n    Returns:\n        Path to the difference table file for chaining task dependencies.\n    \"\"\"\n    import montage_wrapper as montage\n\n    overlaps_log = montage.mOverlaps(str(img_tbl), str(diffs_tbl))\n    logger.debug(f'mOverlaps:\\n{overlaps_log}')\n\n    return diffs_tbl\n</code></pre>"},{"location":"api/apps/montage/#taps.apps.montage.mdiff","title":"mdiff()","text":"<pre><code>mdiff(\n    image_1: Path,\n    image_2: Path,\n    template: Path,\n    output_path: Path,\n) -&gt; Path\n</code></pre> <p>Wrapper to Montage diff function.</p> <p>The function subtracts one image from another (both in the same projection).</p> <p>Parameters:</p> <ul> <li> <code>image_1</code>             (<code>Path</code>)         \u2013          <p>First input file for differencing.</p> </li> <li> <code>image_2</code>             (<code>Path</code>)         \u2013          <p>Second input file for differencing.</p> </li> <li> <code>template</code>             (<code>Path</code>)         \u2013          <p>FITS header file used to define the desired output.</p> </li> <li> <code>output_path</code>             (<code>Path</code>)         \u2013          <p>Output filepath.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Path</code>         \u2013          <p>Output filepath for chaining task dependencies.</p> </li> </ul> Source code in <code>taps/apps/montage.py</code> <pre><code>def mdiff(\n    image_1: pathlib.Path,\n    image_2: pathlib.Path,\n    template: pathlib.Path,\n    output_path: pathlib.Path,\n) -&gt; pathlib.Path:\n    \"\"\"Wrapper to Montage diff function.\n\n    The function subtracts one image from another (both in the same\n    projection).\n\n    Args:\n        image_1: First input file for differencing.\n        image_2: Second input file for differencing.\n        template: FITS header file used to define the desired output.\n        output_path: Output filepath.\n\n    Returns:\n        Output filepath for chaining task dependencies.\n    \"\"\"\n    import montage_wrapper as montage\n\n    diff_log = montage.mDiff(\n        str(image_1),\n        str(image_2),\n        str(output_path),\n        str(template),\n    )\n    logger.debug(f'mDiff:\\n{diff_log}')\n\n    return output_path\n</code></pre>"},{"location":"api/apps/montage/#taps.apps.montage.bgexec_prep","title":"bgexec_prep()","text":"<pre><code>bgexec_prep(\n    img_table: Path,\n    diffs_table: Path,\n    diff_dir: Path,\n    output_dir: Path,\n) -&gt; Path\n</code></pre> <p>Prep to call Montage bg function.</p> <p>The function creates an image-to-image difference parameter table and then applies a set of corrections to achieve a best global fit.</p> <p>Parameters:</p> <ul> <li> <code>img_table</code>             (<code>Path</code>)         \u2013          <p>Reprojected image metadata list.</p> </li> <li> <code>diffs_table</code>             (<code>Path</code>)         \u2013          <p>Table file list of input difference images.</p> </li> <li> <code>diff_dir</code>             (<code>Path</code>)         \u2013          <p>Directory for temporary difference files.</p> </li> <li> <code>output_dir</code>             (<code>Path</code>)         \u2013          <p>Output directory path.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Path</code>         \u2013          <p>corrections table path</p> </li> </ul> Source code in <code>taps/apps/montage.py</code> <pre><code>def bgexec_prep(\n    img_table: pathlib.Path,\n    diffs_table: pathlib.Path,\n    diff_dir: pathlib.Path,\n    output_dir: pathlib.Path,\n) -&gt; pathlib.Path:\n    \"\"\"Prep to call Montage bg function.\n\n    The function creates an image-to-image difference parameter table and\n    then applies a set of corrections to achieve a best global fit.\n\n    Args:\n        img_table: Reprojected image metadata list.\n        diffs_table: Table file list of input difference images.\n        diff_dir: Directory for temporary difference files.\n        output_dir: Output directory path.\n\n    Returns:\n            corrections table path\n    \"\"\"\n    import montage_wrapper as montage\n\n    fits_tbl = output_dir / 'fits.tbl'\n    corrections_tbl = output_dir / 'corrections.tbl'\n\n    fit_log = montage.mFitExec(\n        str(diffs_table),\n        str(fits_tbl),\n        str(diff_dir),\n    )\n    logger.debug(f'mFitExec\\n{fit_log}')\n\n    bg_log = montage.mBgModel(\n        str(img_table),\n        str(fits_tbl),\n        str(corrections_tbl),\n    )\n    logger.debug(f'mBgModel\\n{bg_log}')\n\n    return corrections_tbl\n</code></pre>"},{"location":"api/apps/montage/#taps.apps.montage.mbackground","title":"mbackground()","text":"<pre><code>mbackground(\n    in_image: Path,\n    out_image: Path,\n    a: float,\n    b: float,\n    c: float,\n) -&gt; Path\n</code></pre> <p>Wrapper to Montage Background function.</p> <p>Function subtracts a planar background from a FITS image.</p> <p>Parameters:</p> <ul> <li> <code>in_image</code>             (<code>Path</code>)         \u2013          <p>Input FITS file.</p> </li> <li> <code>out_image</code>             (<code>Path</code>)         \u2013          <p>Output background-removed FITS file.</p> </li> <li> <code>a</code>             (<code>float</code>)         \u2013          <p>A coefficient in (A*x + B*y + C) background level equation.</p> </li> <li> <code>b</code>             (<code>float</code>)         \u2013          <p>B coefficient in (A*x + B*y + C) background level equation.</p> </li> <li> <code>c</code>             (<code>float</code>)         \u2013          <p>C level in (A*x + B*y + C) background level equation.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Path</code>         \u2013          <p>Output image path for chaining task dependencies.</p> </li> </ul> Source code in <code>taps/apps/montage.py</code> <pre><code>def mbackground(\n    in_image: pathlib.Path,\n    out_image: pathlib.Path,\n    a: float,\n    b: float,\n    c: float,\n) -&gt; pathlib.Path:\n    \"\"\"Wrapper to Montage Background function.\n\n    Function subtracts a planar background from a FITS image.\n\n    Args:\n        in_image: Input FITS file.\n        out_image: Output background-removed FITS file.\n        a: A coefficient in (A*x + B*y + C) background level equation.\n        b: B coefficient in (A*x + B*y + C) background level equation.\n        c: C level in (A*x + B*y + C) background level equation.\n\n    Returns:\n        Output image path for chaining task dependencies.\n    \"\"\"\n    import montage_wrapper as montage\n\n    bg_log = montage.mBackground(str(in_image), str(out_image), a, b, c)\n    logger.debug(f'mBackground:\\n{bg_log}')\n\n    return out_image\n</code></pre>"},{"location":"api/apps/montage/#taps.apps.montage.madd","title":"madd()","text":"<pre><code>madd(\n    images_table: Path,\n    template_header: Path,\n    out_image: Path,\n    corr_dir: Path,\n) -&gt; Path\n</code></pre> <p>Coadd reprojected images to form a mosaic.</p> <p>Parameters:</p> <ul> <li> <code>images_table</code>             (<code>Path</code>)         \u2013          <p>table file containing metadata for images to be coadded.</p> </li> <li> <code>template_header</code>             (<code>Path</code>)         \u2013          <p>FITS header template to use in generation of output FITS.</p> </li> <li> <code>out_image</code>             (<code>Path</code>)         \u2013          <p>Output FITS image.</p> </li> <li> <code>corr_dir</code>             (<code>Path</code>)         \u2013          <p>Directory containing reprojected image.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Path</code>         \u2013          <p>FITS output header file.</p> </li> </ul> Source code in <code>taps/apps/montage.py</code> <pre><code>def madd(\n    images_table: pathlib.Path,\n    template_header: pathlib.Path,\n    out_image: pathlib.Path,\n    corr_dir: pathlib.Path,\n) -&gt; pathlib.Path:\n    \"\"\"Coadd reprojected images to form a mosaic.\n\n    Args:\n        images_table: table file containing metadata for images to be coadded.\n        template_header: FITS header template to use in generation of output\n            FITS.\n        out_image: Output FITS image.\n        corr_dir: Directory containing reprojected image.\n\n    Returns:\n        FITS output header file.\n    \"\"\"\n    import montage_wrapper as montage\n\n    add_log = montage.mAdd(\n        str(images_table),\n        str(template_header),\n        str(out_image),\n        str(corr_dir),\n    )\n    logger.debug(f'mAdd:\\n{add_log}')\n\n    return out_image\n</code></pre>"},{"location":"api/apps/synthetic/","title":"taps.apps.synthetic","text":"<code>taps/apps/synthetic.py</code>"},{"location":"api/apps/synthetic/#taps.apps.synthetic.Data","title":"Data","text":"<pre><code>Data(raw: bytes)\n</code></pre> <p>Synthetic task data.</p> Source code in <code>taps/apps/synthetic.py</code> <pre><code>def __init__(self, raw: bytes) -&gt; None:\n    self.raw = raw\n</code></pre>"},{"location":"api/apps/synthetic/#taps.apps.synthetic.WorkflowStructure","title":"WorkflowStructure","text":"<p>             Bases: <code>Enum</code></p> <p>Workflow structure types.</p>"},{"location":"api/apps/synthetic/#taps.apps.synthetic.SyntheticApp","title":"SyntheticApp","text":"<pre><code>SyntheticApp(\n    structure: WorkflowStructure,\n    task_count: int,\n    task_data_bytes: int,\n    task_sleep: float,\n    bag_max_running: int | None,\n    *,\n    warmup_task: bool = True\n)\n</code></pre> <p>Synthetic workflow application.</p> <p>Parameters:</p> <ul> <li> <code>structure</code>             (<code>WorkflowStructure</code>)         \u2013          <p>Workflow structure.</p> </li> <li> <code>task_count</code>             (<code>int</code>)         \u2013          <p>Number of tasks.</p> </li> <li> <code>task_data_bytes</code>             (<code>int</code>)         \u2013          <p>Size of random input and output data of tasks.</p> </li> <li> <code>task_sleep</code>             (<code>float</code>)         \u2013          <p>Seconds to sleep for in each task.</p> </li> <li> <code>bag_max_running</code>             (<code>int | None</code>)         \u2013          <p>Maximum concurrently executing tasks in the \"bag\" workflow.</p> </li> </ul> Source code in <code>taps/apps/synthetic.py</code> <pre><code>def __init__(\n    self,\n    structure: WorkflowStructure,\n    task_count: int,\n    task_data_bytes: int,\n    task_sleep: float,\n    bag_max_running: int | None,\n    *,\n    warmup_task: bool = True,\n) -&gt; None:\n    self.structure = structure\n    self.task_count = task_count\n    self.task_data_bytes = task_data_bytes\n    self.task_sleep = task_sleep\n    self.bag_max_running = bag_max_running\n    self.warmup_task = warmup_task\n</code></pre>"},{"location":"api/apps/synthetic/#taps.apps.synthetic.SyntheticApp.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the application.</p> Source code in <code>taps/apps/synthetic.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close the application.\"\"\"\n    pass\n</code></pre>"},{"location":"api/apps/synthetic/#taps.apps.synthetic.SyntheticApp.run","title":"run()","text":"<pre><code>run(engine: Engine, run_dir: Path) -&gt; None\n</code></pre> <p>Run the application.</p> <p>Parameters:</p> <ul> <li> <code>engine</code>             (<code>Engine</code>)         \u2013          <p>Application execution engine.</p> </li> <li> <code>run_dir</code>             (<code>Path</code>)         \u2013          <p>Run directory.</p> </li> </ul> Source code in <code>taps/apps/synthetic.py</code> <pre><code>def run(self, engine: Engine, run_dir: pathlib.Path) -&gt; None:\n    \"\"\"Run the application.\n\n    Args:\n        engine: Application execution engine.\n        run_dir: Run directory.\n    \"\"\"\n    if self.warmup_task:\n        logger.log(APP_LOG_LEVEL, 'Submitting warmup task')\n        engine.submit(warmup_task).result()\n        logger.log(APP_LOG_LEVEL, 'Warmup task completed')\n\n    logger.log(APP_LOG_LEVEL, f'Starting {self.structure.value} workflow')\n    if self.structure == WorkflowStructure.BAG:\n        assert self.bag_max_running is not None\n        run_bag_of_tasks(\n            engine,\n            task_count=self.task_count,\n            task_data_bytes=self.task_data_bytes,\n            task_sleep=self.task_sleep,\n            max_running_tasks=self.bag_max_running,\n        )\n    elif self.structure == WorkflowStructure.DIAMOND:\n        run_diamond(\n            engine,\n            task_count=self.task_count,\n            task_data_bytes=self.task_data_bytes,\n            task_sleep=self.task_sleep,\n        )\n    elif self.structure == WorkflowStructure.REDUCE:\n        run_reduce(\n            engine,\n            task_count=self.task_count,\n            task_data_bytes=self.task_data_bytes,\n            task_sleep=self.task_sleep,\n        )\n    elif self.structure == WorkflowStructure.SEQUENTIAL:\n        run_sequential(\n            engine,\n            task_count=self.task_count,\n            task_data_bytes=self.task_data_bytes,\n            task_sleep=self.task_sleep,\n        )\n    else:\n        raise AssertionError(\n            f'Unhandled workflow structure type {self.structure}.',\n        )\n</code></pre>"},{"location":"api/apps/synthetic/#taps.apps.synthetic.generate_data","title":"generate_data()","text":"<pre><code>generate_data(size: int) -&gt; Data\n</code></pre> <p>Get random data of specified size.</p> <p>Uses <code>random.randbytes()</code> in Python 3.9 or newer and <code>os.urandom()</code> in Python 3.8 and older.</p> Note <p>This class returns a <code>Data</code> object rather than a bytestring directly. This indirection is because some serializers skip <code>bytes</code> which will cause problems if ProxyStore is used in this application because the <code>Proxy[bytes]</code> will be an instance of <code>bytes</code> and won't get properly serialized. This is the case with Ray, for example.</p> <p>Parameters:</p> <ul> <li> <code>size</code>             (<code>int</code>)         \u2013          <p>size of byte string to return.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Data</code>         \u2013          <p>random data.</p> </li> </ul> Source code in <code>taps/apps/synthetic.py</code> <pre><code>def generate_data(size: int) -&gt; Data:\n    \"\"\"Get random data of specified size.\n\n    Uses `random.randbytes()` in Python 3.9 or newer and\n    `os.urandom()` in Python 3.8 and older.\n\n    Note:\n        This class returns a `Data` object rather than a bytestring directly.\n        This indirection is because some serializers skip [`bytes`][bytes]\n        which will cause problems if ProxyStore is used in this application\n        because the `Proxy[bytes]` will be an instance of [`bytes`][bytes] and\n        won't get properly serialized. This is the case with Ray, for example.\n\n    Args:\n        size (int): size of byte string to return.\n\n    Returns:\n        random data.\n    \"\"\"\n    max_bytes = int(1e9)\n    if sys.version_info &gt;= (3, 9) and size &lt; max_bytes:  # pragma: &gt;=3.9 cover\n        raw = random.randbytes(size)\n    else:  # pragma: &lt;3.9 cover\n        raw = os.urandom(size)\n    return Data(raw)\n</code></pre>"},{"location":"api/apps/synthetic/#taps.apps.synthetic.noop_task","title":"noop_task()","text":"<pre><code>noop_task(\n    *data: Data,\n    output_size: int,\n    sleep: float,\n    task_id: UUID | None = None\n) -&gt; Data\n</code></pre> <p>No-op sleep task.</p> <p>Parameters:</p> <ul> <li> <code>data</code>             (<code>Data</code>, default:                 <code>()</code> )         \u2013          <p>Input data.</p> </li> <li> <code>output_size</code>             (<code>int</code>)         \u2013          <p>Size in bytes of output byte-string.</p> </li> <li> <code>sleep</code>             (<code>float</code>)         \u2013          <p>Minimum runtime of the task. Time required to generate the output data will be subtracted from this sleep time.</p> </li> <li> <code>task_id</code>             (<code>UUID | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional unique task ID to prevent engines from caching the task result.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Data</code>         \u2013          <p>Byte-string of length <code>output_size</code>.</p> </li> </ul> Source code in <code>taps/apps/synthetic.py</code> <pre><code>def noop_task(\n    *data: Data,\n    output_size: int,\n    sleep: float,\n    task_id: uuid.UUID | None = None,\n) -&gt; Data:\n    \"\"\"No-op sleep task.\n\n    Args:\n        data: Input data.\n        output_size: Size in bytes of output byte-string.\n        sleep: Minimum runtime of the task. Time required to generate the\n            output data will be subtracted from this sleep time.\n        task_id: Optional unique task ID to prevent engines from caching\n            the task result.\n\n    Returns:\n        Byte-string of length `output_size`.\n    \"\"\"\n    start = time.perf_counter_ns()\n    # Validate the data is real\n    assert all(len(d.raw) &gt;= 0 for d in data)\n    result = generate_data(output_size)\n    elapsed = (time.perf_counter_ns() - start) / 1e9\n\n    # Remove elapsed time for generating result from remaining sleep time.\n    time.sleep(max(0, sleep - elapsed))\n    return result\n</code></pre>"},{"location":"api/apps/synthetic/#taps.apps.synthetic.warmup_task","title":"warmup_task()","text":"<pre><code>warmup_task() -&gt; None\n</code></pre> <p>No-op warmup task.</p> Source code in <code>taps/apps/synthetic.py</code> <pre><code>def warmup_task() -&gt; None:\n    \"\"\"No-op warmup task.\"\"\"\n    pass\n</code></pre>"},{"location":"api/apps/synthetic/#taps.apps.synthetic.run_bag_of_tasks","title":"run_bag_of_tasks()","text":"<pre><code>run_bag_of_tasks(\n    engine: Engine,\n    task_count: int,\n    task_data_bytes: int,\n    task_sleep: float,\n    max_running_tasks: int,\n) -&gt; None\n</code></pre> <p>Run bag of tasks workflow.</p> Source code in <code>taps/apps/synthetic.py</code> <pre><code>def run_bag_of_tasks(\n    engine: Engine,\n    task_count: int,\n    task_data_bytes: int,\n    task_sleep: float,\n    max_running_tasks: int,\n) -&gt; None:\n    \"\"\"Run bag of tasks workflow.\"\"\"\n    max_running_tasks = min(max_running_tasks, task_count)\n    start = time.monotonic()\n\n    running_tasks = [\n        engine.submit(\n            noop_task,\n            generate_data(task_data_bytes),\n            output_size=task_data_bytes,\n            sleep=task_sleep,\n            task_id=uuid.uuid4(),\n        )\n        for _ in range(max_running_tasks)\n    ]\n    logger.log(\n        APP_LOG_LEVEL,\n        f'Submitted {max_running_tasks} initial tasks',\n    )\n\n    completed_tasks = 0\n    submitted_tasks = len(running_tasks)\n\n    while submitted_tasks &lt; task_count:\n        finished_tasks, _ = wait(running_tasks, return_when='FIRST_COMPLETED')\n        for task in finished_tasks:\n            assert task.exception() is None\n            running_tasks.remove(task)\n            completed_tasks += 1\n\n        new_tasks = [\n            engine.submit(\n                noop_task,\n                generate_data(task_data_bytes),\n                output_size=task_data_bytes,\n                sleep=task_sleep,\n                task_id=uuid.uuid4(),\n            )\n            for _ in finished_tasks\n        ]\n        running_tasks.extend(new_tasks)\n        submitted_tasks += len(new_tasks)\n\n        if completed_tasks % max_running_tasks == 0:\n            rate = completed_tasks / (time.monotonic() - start)\n            logger.log(\n                APP_LOG_LEVEL,\n                f'Completed {completed_tasks}/{task_count} tasks '\n                f'(rate: {rate:.2f} tasks/s, running tasks: '\n                f'{len(running_tasks)})',\n            )\n\n    wait(running_tasks, return_when='ALL_COMPLETED')\n    # Validate task results are real\n    assert all(len(task.result().raw) &gt;= 0 for task in running_tasks)\n    completed_tasks += len(running_tasks)\n    rate = completed_tasks / (time.monotonic() - start)\n    logger.log(\n        APP_LOG_LEVEL,\n        f'Completed {completed_tasks}/{task_count} (rate: {rate:.2f} tasks/s)',\n    )\n</code></pre>"},{"location":"api/apps/synthetic/#taps.apps.synthetic.run_diamond","title":"run_diamond()","text":"<pre><code>run_diamond(\n    engine: Engine,\n    task_count: int,\n    task_data_bytes: int,\n    task_sleep: float,\n) -&gt; None\n</code></pre> <p>Run diamond workflow.</p> Source code in <code>taps/apps/synthetic.py</code> <pre><code>def run_diamond(\n    engine: Engine,\n    task_count: int,\n    task_data_bytes: int,\n    task_sleep: float,\n) -&gt; None:\n    \"\"\"Run diamond workflow.\"\"\"\n    initial_task = engine.submit(\n        noop_task,\n        generate_data(task_data_bytes),\n        output_size=task_data_bytes,\n        sleep=task_sleep,\n        task_id=uuid.uuid4(),\n    )\n    logger.log(APP_LOG_LEVEL, 'Submitted initial task')\n\n    intermediate_tasks = [\n        engine.submit(\n            noop_task,\n            initial_task,\n            output_size=task_data_bytes,\n            sleep=task_sleep,\n            task_id=uuid.uuid4(),\n        )\n        for _ in range(task_count)\n    ]\n    logger.log(\n        APP_LOG_LEVEL,\n        f'Submitting {task_count} intermediate tasks',\n    )\n\n    final_task = engine.submit(\n        noop_task,\n        *intermediate_tasks,\n        output_size=task_data_bytes,\n        sleep=task_sleep,\n        task_id=uuid.uuid4(),\n    )\n    logger.log(APP_LOG_LEVEL, 'Submitted final task')\n\n    final_task.result()\n    logger.log(APP_LOG_LEVEL, 'Final task completed')\n</code></pre>"},{"location":"api/apps/synthetic/#taps.apps.synthetic.run_reduce","title":"run_reduce()","text":"<pre><code>run_reduce(\n    engine: Engine,\n    task_count: int,\n    task_data_bytes: int,\n    task_sleep: float,\n) -&gt; None\n</code></pre> <p>Run reduce worklow.</p> Source code in <code>taps/apps/synthetic.py</code> <pre><code>def run_reduce(\n    engine: Engine,\n    task_count: int,\n    task_data_bytes: int,\n    task_sleep: float,\n) -&gt; None:\n    \"\"\"Run reduce worklow.\"\"\"\n    map_tasks = [\n        engine.submit(\n            noop_task,\n            generate_data(task_data_bytes),\n            output_size=task_data_bytes,\n            sleep=task_sleep,\n            task_id=uuid.uuid4(),\n        )\n        for _ in range(task_count)\n    ]\n    logger.log(APP_LOG_LEVEL, f'Submitted {task_count} initial tasks')\n\n    reduce_task = engine.submit(\n        noop_task,\n        *map_tasks,\n        output_size=task_data_bytes,\n        sleep=task_sleep,\n        task_id=uuid.uuid4(),\n    )\n    logger.log(APP_LOG_LEVEL, 'Submitted reduce task')\n\n    reduce_task.result()\n    logger.log(APP_LOG_LEVEL, 'Reduce task completed')\n</code></pre>"},{"location":"api/apps/synthetic/#taps.apps.synthetic.run_sequential","title":"run_sequential()","text":"<pre><code>run_sequential(\n    engine: Engine,\n    task_count: int,\n    task_data_bytes: int,\n    task_sleep: float,\n) -&gt; None\n</code></pre> <p>Run sequential workflow.</p> Source code in <code>taps/apps/synthetic.py</code> <pre><code>def run_sequential(\n    engine: Engine,\n    task_count: int,\n    task_data_bytes: int,\n    task_sleep: float,\n) -&gt; None:\n    \"\"\"Run sequential workflow.\"\"\"\n    start = time.monotonic()\n    initial_data = generate_data(task_data_bytes)\n    tasks: list[TaskFuture[Data]] = []\n\n    for i in range(task_count):\n        input_data = initial_data if i == 0 else tasks[-1]\n        task = engine.submit(\n            noop_task,\n            input_data,\n            output_size=task_data_bytes,\n            sleep=task_sleep,\n            task_id=uuid.uuid4(),\n        )\n        tasks.append(task)\n        logger.log(\n            APP_LOG_LEVEL,\n            f'Submitted task {i+1}/{task_count} '\n            f'(task_id={task.info.task_id})',\n        )\n\n    for i, task in enumerate(as_completed(tasks)):\n        assert task.done()\n        logger.log(\n            APP_LOG_LEVEL,\n            f'Received task {i+1}/{task_count} (task_id: {task.info.task_id})',\n        )\n\n    # Validate the final result in the sequence\n    assert len(tasks[-1].result().raw) &gt;= 0\n\n    rate = task_count / (time.monotonic() - start)\n    logger.log(APP_LOG_LEVEL, f'Task completion rate: {rate:.3f} tasks/s')\n</code></pre>"},{"location":"api/apps/configs/","title":"taps.apps.configs","text":"<code>taps/apps/configs/__init__.py</code>"},{"location":"api/apps/configs/cholesky/","title":"taps.apps.configs.cholesky","text":"<code>taps/apps/configs/cholesky.py</code>"},{"location":"api/apps/configs/cholesky/#taps.apps.configs.cholesky.CholeskyConfig","title":"CholeskyConfig","text":"<p>             Bases: <code>AppConfig</code></p> <p>Cholesky application configuration.</p>"},{"location":"api/apps/configs/cholesky/#taps.apps.configs.cholesky.CholeskyConfig.get_app","title":"get_app()","text":"<pre><code>get_app() -&gt; App\n</code></pre> <p>Create an application instance from the config.</p> Source code in <code>taps/apps/configs/cholesky.py</code> <pre><code>def get_app(self) -&gt; App:\n    \"\"\"Create an application instance from the config.\"\"\"\n    from taps.apps.cholesky import CholeskyApp\n\n    return CholeskyApp(\n        matrix_size=self.matrix_size,\n        block_size=self.block_size,\n    )\n</code></pre>"},{"location":"api/apps/configs/docking/","title":"taps.apps.configs.docking","text":"<code>taps/apps/configs/docking.py</code>"},{"location":"api/apps/configs/docking/#taps.apps.configs.docking.DockingConfig","title":"DockingConfig","text":"<p>             Bases: <code>AppConfig</code></p> <p>Docking application configuration.</p>"},{"location":"api/apps/configs/docking/#taps.apps.configs.docking.DockingConfig.get_app","title":"get_app()","text":"<pre><code>get_app() -&gt; App\n</code></pre> <p>Create an application instance from the config.</p> Source code in <code>taps/apps/configs/docking.py</code> <pre><code>def get_app(self) -&gt; App:\n    \"\"\"Create an application instance from the config.\"\"\"\n    from taps.apps.docking.app import DockingApp\n\n    return DockingApp(\n        smi_file_name_ligand_path=pathlib.Path(self.smi_file_name_ligand),\n        receptor_path=pathlib.Path(self.receptor),\n        tcl_path=pathlib.Path(self.tcl_path),\n        initial_simulations=self.initial_simulations,\n        num_iterations=self.num_iterations,\n        batch_size=self.batch_size,\n        seed=self.seed,\n    )\n</code></pre>"},{"location":"api/apps/configs/failures/","title":"taps.apps.configs.failures","text":"<code>taps/apps/configs/failures.py</code>"},{"location":"api/apps/configs/failures/#taps.apps.configs.failures.FailureInjectionConfig","title":"FailureInjectionConfig","text":"<p>             Bases: <code>AppConfig</code></p> <p>Failure injection configuration.</p>"},{"location":"api/apps/configs/failures/#taps.apps.configs.failures.FailureInjectionConfig.get_app","title":"get_app()","text":"<pre><code>get_app() -&gt; App\n</code></pre> <p>Create an application instance from the config.</p> Source code in <code>taps/apps/configs/failures.py</code> <pre><code>def get_app(self) -&gt; App:\n    \"\"\"Create an application instance from the config.\"\"\"\n    from taps.apps.failures.app import FailureInjectionApp\n\n    return FailureInjectionApp(\n        base_config=self._get_app_config(),\n        failure_rate=self.failure_rate,\n        # Because use_enum_values=True, self.failure_type is actually\n        # a string and we need to convert it back.\n        failure_type=FailureType(self.failure_type),\n    )\n</code></pre>"},{"location":"api/apps/configs/fedlearn/","title":"taps.apps.configs.fedlearn","text":"<code>taps/apps/configs/fedlearn.py</code>"},{"location":"api/apps/configs/fedlearn/#taps.apps.configs.fedlearn.FedlearnConfig","title":"FedlearnConfig","text":"<p>             Bases: <code>AppConfig</code></p> <p>Federated learning application configuration.</p>"},{"location":"api/apps/configs/fedlearn/#taps.apps.configs.fedlearn.FedlearnConfig.get_app","title":"get_app()","text":"<pre><code>get_app() -&gt; App\n</code></pre> <p>Create an application instance from the config.</p> Source code in <code>taps/apps/configs/fedlearn.py</code> <pre><code>def get_app(self) -&gt; App:\n    \"\"\"Create an application instance from the config.\"\"\"\n    from taps.apps.fedlearn.app import FedlearnApp\n    from taps.apps.fedlearn.types import DataChoices\n\n    return FedlearnApp(\n        clients=self.clients,\n        rounds=self.rounds,\n        device=self.device,\n        epochs=self.batch_size,\n        batch_size=self.batch_size,\n        lr=self.lr,\n        dataset=DataChoices(self.dataset),\n        data_dir=self.data_dir,\n        train=self.train,\n        test=self.test,\n        participation=self.participation,\n        seed=self.seed,\n    )\n</code></pre>"},{"location":"api/apps/configs/mapreduce/","title":"taps.apps.configs.mapreduce","text":"<code>taps/apps/configs/mapreduce.py</code>"},{"location":"api/apps/configs/mapreduce/#taps.apps.configs.mapreduce.MapreduceConfig","title":"MapreduceConfig","text":"<p>             Bases: <code>AppConfig</code></p> <p>Mapreduce application configuration.</p>"},{"location":"api/apps/configs/mapreduce/#taps.apps.configs.mapreduce.MapreduceConfig.get_app","title":"get_app()","text":"<pre><code>get_app() -&gt; App\n</code></pre> <p>Create an application instance from the config.</p> Source code in <code>taps/apps/configs/mapreduce.py</code> <pre><code>def get_app(self) -&gt; App:\n    \"\"\"Create an application instance from the config.\"\"\"\n    from taps.apps.mapreduce import MapreduceApp\n\n    return MapreduceApp(\n        data_dir=pathlib.Path(self.data_dir),\n        map_tasks=self.map_tasks,\n        generate=self.generate,\n        generated_files=self.generated_files,\n        generated_words=self.generated_words,\n    )\n</code></pre>"},{"location":"api/apps/configs/moldesign/","title":"taps.apps.configs.moldesign","text":"<code>taps/apps/configs/moldesign.py</code>"},{"location":"api/apps/configs/moldesign/#taps.apps.configs.moldesign.MoldesignConfig","title":"MoldesignConfig","text":"<p>             Bases: <code>AppConfig</code></p> <p>Moldesign application configuration.</p>"},{"location":"api/apps/configs/moldesign/#taps.apps.configs.moldesign.MoldesignConfig.get_app","title":"get_app()","text":"<pre><code>get_app() -&gt; App\n</code></pre> <p>Create an application instance from the config.</p> Source code in <code>taps/apps/configs/moldesign.py</code> <pre><code>def get_app(self) -&gt; App:\n    \"\"\"Create an application instance from the config.\"\"\"\n    from taps.apps.moldesign.app import MoldesignApp\n\n    return MoldesignApp(\n        dataset=self.dataset,\n        initial_count=self.initial_count,\n        search_count=self.search_count,\n        batch_size=self.batch_size,\n        seed=self.seed,\n    )\n</code></pre>"},{"location":"api/apps/configs/montage/","title":"taps.apps.configs.montage","text":"<code>taps/apps/configs/montage.py</code>"},{"location":"api/apps/configs/montage/#taps.apps.configs.montage.MontageConfig","title":"MontageConfig","text":"<p>             Bases: <code>AppConfig</code></p> <p>Montage application configuration.</p>"},{"location":"api/apps/configs/montage/#taps.apps.configs.montage.MontageConfig.get_app","title":"get_app()","text":"<pre><code>get_app() -&gt; App\n</code></pre> <p>Create an application instance from the config.</p> Source code in <code>taps/apps/configs/montage.py</code> <pre><code>def get_app(self) -&gt; App:\n    \"\"\"Create an application instance from the config.\"\"\"\n    from taps.apps.montage import MontageApp\n\n    return MontageApp(\n        img_folder=pathlib.Path(self.img_folder),\n        img_tbl=self.img_tbl,\n        img_hdr=self.img_hdr,\n        output_dir=self.output_dir,\n    )\n</code></pre>"},{"location":"api/apps/configs/synthetic/","title":"taps.apps.configs.synthetic","text":"<code>taps/apps/configs/synthetic.py</code>"},{"location":"api/apps/configs/synthetic/#taps.apps.configs.synthetic.SyntheticConfig","title":"SyntheticConfig","text":"<p>             Bases: <code>AppConfig</code></p> <p>Synthetic application configuration.</p>"},{"location":"api/apps/configs/synthetic/#taps.apps.configs.synthetic.SyntheticConfig.get_app","title":"get_app()","text":"<pre><code>get_app() -&gt; App\n</code></pre> <p>Create an application instance from the config.</p> Source code in <code>taps/apps/configs/synthetic.py</code> <pre><code>def get_app(self) -&gt; App:\n    \"\"\"Create an application instance from the config.\"\"\"\n    from taps.apps.synthetic import SyntheticApp\n    from taps.apps.synthetic import WorkflowStructure\n\n    return SyntheticApp(\n        structure=WorkflowStructure(self.structure),\n        task_count=self.task_count,\n        task_data_bytes=self.task_data_bytes,\n        task_sleep=self.task_sleep,\n        bag_max_running=self.bag_max_running,\n        warmup_task=self.warmup_task,\n    )\n</code></pre>"},{"location":"api/apps/docking/","title":"taps.apps.docking","text":"<code>taps/apps/docking/__init__.py</code>"},{"location":"api/apps/docking/app/","title":"taps.apps.docking.app","text":"<code>taps/apps/docking/app.py</code>"},{"location":"api/apps/docking/app/#taps.apps.docking.app.DockingApp","title":"DockingApp","text":"<pre><code>DockingApp(\n    smi_file_name_ligand_path: Path,\n    receptor_path: Path,\n    tcl_path: Path,\n    initial_simulations: int = 8,\n    num_iterations: int = 3,\n    batch_size: int = 8,\n    seed: int = 0,\n)\n</code></pre> <p>Protein docking application.</p> <p>Based on the Parsl Docking Tutorial.</p> <p>Parameters:</p> <ul> <li> <code>smi_file_name_ligand_path</code>             (<code>Path</code>)         \u2013          <p>Path to ligand SMILES string.</p> </li> <li> <code>receptor_path</code>             (<code>Path</code>)         \u2013          <p>Path to target receptor PDBQT file.</p> </li> <li> <code>tcl_path</code>             (<code>Path</code>)         \u2013          <p>Path to TCL script.</p> </li> <li> <code>initial_simulations</code>             (<code>int</code>, default:                 <code>8</code> )         \u2013          <p>Initial number of simulations to perform.</p> </li> <li> <code>num_iterations</code>             (<code>int</code>, default:                 <code>3</code> )         \u2013          <p>Number of infer-simulate-train loops to perform.</p> </li> <li> <code>batch_size</code>             (<code>int</code>, default:                 <code>8</code> )         \u2013          <p>Number of simulations per iteration.</p> </li> <li> <code>seed</code>             (<code>int</code>, default:                 <code>0</code> )         \u2013          <p>Random seed for sampling.</p> </li> </ul> Source code in <code>taps/apps/docking/app.py</code> <pre><code>def __init__(\n    self,\n    smi_file_name_ligand_path: pathlib.Path,\n    receptor_path: pathlib.Path,\n    tcl_path: pathlib.Path,\n    initial_simulations: int = 8,\n    num_iterations: int = 3,\n    batch_size: int = 8,\n    seed: int = 0,\n) -&gt; None:\n    self.smi_file_name_ligand = smi_file_name_ligand_path\n    self.receptor = receptor_path\n    self.tcl_path = tcl_path\n    self.initial_simulations = initial_simulations\n    self.num_iterations = num_iterations\n    self.batch_size = batch_size\n    self.seed = seed\n</code></pre>"},{"location":"api/apps/docking/app/#taps.apps.docking.app.DockingApp.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the application.</p> Source code in <code>taps/apps/docking/app.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close the application.\"\"\"\n    pass\n</code></pre>"},{"location":"api/apps/docking/app/#taps.apps.docking.app.DockingApp.run","title":"run()","text":"<pre><code>run(engine: Engine, run_dir: Path) -&gt; None\n</code></pre> <p>Run the application.</p> <p>Parameters:</p> <ul> <li> <code>engine</code>             (<code>Engine</code>)         \u2013          <p>Application execution engine.</p> </li> <li> <code>run_dir</code>             (<code>Path</code>)         \u2013          <p>Run directory.</p> </li> </ul> Source code in <code>taps/apps/docking/app.py</code> <pre><code>def run(self, engine: Engine, run_dir: pathlib.Path) -&gt; None:\n    \"\"\"Run the application.\n\n    Args:\n        engine: Application execution engine.\n        run_dir: Run directory.\n    \"\"\"\n    docking_futures: list[TaskFuture[tuple[str, float]]] = []\n    train_data = []\n    smiles_simulated = []\n\n    train_output_file = run_dir / 'training-results.json'\n    task_data_dir = run_dir / 'tasks'\n    task_data_dir.mkdir(parents=True, exist_ok=True)\n\n    search_space = pd.read_csv(self.smi_file_name_ligand)\n    search_space = search_space[['TITLE', 'SMILES']]\n\n    # start with an initial set of random smiles\n    selected_smiles = search_space.sample(\n        self.initial_simulations,\n        random_state=self.seed,\n    )\n    logger.log(\n        APP_LOG_LEVEL,\n        f'Submitting {self.initial_simulations} initial simulations',\n    )\n    for i in range(self.initial_simulations):\n        smiles = selected_smiles.iloc[i]['SMILES']\n        working_dir = task_data_dir / uuid.uuid4().hex\n        working_dir.mkdir()\n        future = self._submit_task_for_smiles(engine, smiles, working_dir)\n        docking_futures.append(future)\n        logger.log(APP_LOG_LEVEL, f'Submitted computations for {smiles}')\n\n    for future in as_completed(docking_futures):\n        smiles, score = future.result()\n        logger.log(\n            APP_LOG_LEVEL,\n            f'Computation for {smiles} succeeded with score = {score}',\n        )\n\n        train_data.append(\n            {'smiles': smiles, 'score': score, 'time': monotonic()},\n        )\n        smiles_simulated.append(smiles)\n\n    training_df = pd.DataFrame(train_data)\n\n    # train model, run inference, and run more simulations\n    for i in range(self.num_iterations):\n        logger.log(\n            APP_LOG_LEVEL,\n            f'Starting iteration {i+1}/{self.num_iterations}',\n        )\n\n        model = train_model(training_df)\n        logger.log(APP_LOG_LEVEL, 'Model training finished')\n\n        predictions = run_model(model, search_space['SMILES'])\n        predictions.sort_values('score', ascending=True, inplace=True)\n        logger.log(APP_LOG_LEVEL, 'Model inference finished')\n\n        train_data = []\n        futures = []\n        batch_count = 0\n        for smiles in predictions['smiles']:\n            if smiles not in smiles_simulated:\n                working_dir = task_data_dir / uuid.uuid4().hex\n                working_dir.mkdir()\n                future = self._submit_task_for_smiles(\n                    engine,\n                    smiles,\n                    working_dir,\n                )\n                futures.append(future)\n                batch_count += 1\n                logger.log(\n                    APP_LOG_LEVEL,\n                    f'Submitted computations for {smiles}',\n                )\n\n            if batch_count &gt;= self.batch_size:\n                break\n\n        for future in as_completed(futures):\n            smiles, score = future.result()\n            logger.log(\n                APP_LOG_LEVEL,\n                f'Computation for {smiles} succeeded with score = {score}',\n            )\n\n            train_data.append(\n                {'smiles': smiles, 'score': score, 'time': monotonic()},\n            )\n            smiles_simulated.append(smiles)\n\n        training_df = pd.concat(\n            (training_df, pd.DataFrame(train_data)),\n            ignore_index=True,\n        )\n\n    training_df.to_json(train_output_file)\n    logger.log(\n        APP_LOG_LEVEL,\n        f'Training data saved to {train_output_file}',\n    )\n    shutil.rmtree(task_data_dir)\n</code></pre>"},{"location":"api/apps/docking/app/#taps.apps.docking.app.smi_to_pdb","title":"smi_to_pdb()","text":"<pre><code>smi_to_pdb(smiles: str, pdb_file: Path) -&gt; Path\n</code></pre> <p>Convert SMILES string to PDB representation.</p> <p>The conversion to PDB file will contain atomic coordinates that will be used for docking.</p> <p>Parameters:</p> <ul> <li> <code>smiles</code>             (<code>str</code>)         \u2013          <p>Molecule representation in SMILES format.</p> </li> <li> <code>pdb_file</code>             (<code>Path</code>)         \u2013          <p>Path of the PDB file to create.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Path</code>         \u2013          <p>The created PDB file.</p> </li> </ul> Source code in <code>taps/apps/docking/app.py</code> <pre><code>def smi_to_pdb(smiles: str, pdb_file: pathlib.Path) -&gt; pathlib.Path:\n    \"\"\"Convert SMILES string to PDB representation.\n\n    The conversion to PDB file will contain atomic coordinates\n    that will be used for docking.\n\n    Args:\n        smiles: Molecule representation in SMILES format.\n        pdb_file: Path of the PDB file to create.\n\n    Returns:\n        The created PDB file.\n    \"\"\"\n    from rdkit import Chem\n    from rdkit.Chem import AllChem\n\n    # Convert SMILES to RDKit molecule object\n    mol = Chem.MolFromSmiles(smiles)\n    # Add hydrogens to the molecule\n    mol = Chem.AddHs(mol)\n    # Generate a 3D conformation for the molecule\n    AllChem.EmbedMolecule(mol)\n    AllChem.MMFFOptimizeMolecule(mol)\n\n    # Write the molecule to a PDB file\n    writer = Chem.PDBWriter(pdb_file)\n    writer.write(mol)\n    writer.close()\n\n    return pdb_file\n</code></pre>"},{"location":"api/apps/docking/app/#taps.apps.docking.app.set_element","title":"set_element()","text":"<pre><code>set_element(\n    input_pdb: Path, output_pdb: Path, tcl_path: Path\n) -&gt; Path\n</code></pre> <p>Add coordinated to the PDB file using VMD.</p> <p>Parameters:</p> <ul> <li> <code>input_pdb</code>             (<code>Path</code>)         \u2013          <p>Path of input PDB file.</p> </li> <li> <code>output_pdb</code>             (<code>Path</code>)         \u2013          <p>Path to PDB file with atomic coordinates.</p> </li> <li> <code>tcl_path</code>             (<code>Path</code>)         \u2013          <p>Path to TCL script.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Path</code>         \u2013          <p>The newly created PDB file path.</p> </li> </ul> Source code in <code>taps/apps/docking/app.py</code> <pre><code>def set_element(\n    input_pdb: pathlib.Path,\n    output_pdb: pathlib.Path,\n    tcl_path: pathlib.Path,\n) -&gt; pathlib.Path:\n    \"\"\"Add coordinated to the PDB file using VMD.\n\n    Args:\n        input_pdb: Path of input PDB file.\n        output_pdb: Path to PDB file with atomic coordinates.\n        tcl_path: Path to TCL script.\n\n    Returns:\n        The newly created PDB file path.\n    \"\"\"\n    command = f'vmd -dispdev text -e {tcl_path} -args {input_pdb} {output_pdb}'\n\n    subprocess.check_output(command.split())\n    return output_pdb\n</code></pre>"},{"location":"api/apps/docking/app/#taps.apps.docking.app.pdb_to_pdbqt","title":"pdb_to_pdbqt()","text":"<pre><code>pdb_to_pdbqt(\n    pdb_file: Path, pdbqt_file: Path, ligand: bool = True\n) -&gt; Path\n</code></pre> <p>Convert PDB file to PDBQT format.</p> <p>PDBQT files are similar to the PDB format, but also includes connectivity information.</p> <p>Parameters:</p> <ul> <li> <code>pdb_file</code>             (<code>Path</code>)         \u2013          <p>input PDB file to convert.</p> </li> <li> <code>pdbqt_file</code>             (<code>Path</code>)         \u2013          <p>output converted PDBQT file.</p> </li> <li> <code>ligand</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>If the molecule is a ligand or not.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Path</code>         \u2013          <p>The path to the created PDBQT file.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>RuntimeError</code>           \u2013          <p>If <code>MGLTOOLS_HOME</code> is not set.</p> </li> </ul> Source code in <code>taps/apps/docking/app.py</code> <pre><code>def pdb_to_pdbqt(\n    pdb_file: pathlib.Path,\n    pdbqt_file: pathlib.Path,\n    ligand: bool = True,\n) -&gt; pathlib.Path:\n    \"\"\"Convert PDB file to PDBQT format.\n\n    PDBQT files are similar to the PDB format, but also includes connectivity\n    information.\n\n    Args:\n        pdb_file: input PDB file to convert.\n        pdbqt_file: output converted PDBQT file.\n        ligand: If the molecule is a ligand or not.\n\n    Returns:\n        The path to the created PDBQT file.\n\n    Raises:\n        RuntimeError: If `MGLTOOLS_HOME` is not set.\n    \"\"\"\n    autodocktools_path = os.getenv(MGLTOOLS_HOME_ENV)\n    if autodocktools_path is None:\n        raise RuntimeError(f'{MGLTOOLS_HOME_ENV} is not set.')\n\n    script, flag = (\n        ('prepare_ligand4.py', 'l')\n        if ligand\n        else ('prepare_receptor4.py', 'r')\n    )\n\n    script_path = (\n        pathlib.Path(autodocktools_path)\n        / 'MGLToolsPckgs/AutoDockTools/Utilities24'\n        / script\n    )\n    command = (\n        f'python2.7 {script_path} -{flag} {pdb_file} -o {pdbqt_file} '\n        '-U nphs_lps_waters'\n    )\n    subprocess.check_output(\n        command.split(),\n        cwd=pdb_file.parent,\n        encoding='utf-8',\n    )\n\n    return pdbqt_file\n</code></pre>"},{"location":"api/apps/docking/app/#taps.apps.docking.app.make_autodock_config","title":"make_autodock_config()","text":"<pre><code>make_autodock_config(\n    input_receptor_pdbqt_file: Path,\n    input_ligand_pdbqt_file: Path,\n    output_conf_file: Path,\n    output_ligand_pdbqt_file: Path,\n    center: tuple[float, float, float] = (\n        15.614,\n        53.38,\n        15.455,\n    ),\n    size: tuple[int, int, int] = (20, 20, 20),\n    exhaustiveness: int = 20,\n    num_modes: int = 20,\n    energy_range: int = 10,\n) -&gt; Path\n</code></pre> <p>Create configuration for AutoDock Vina.</p> <p>Create a configuration file for AutoDock Vina by describing the target receptor and setting coordinate bounds for the docking experiment.</p> <p>Parameters:</p> <ul> <li> <code>input_receptor_pdbqt_file</code>             (<code>Path</code>)         \u2013          <p>Target receptor PDBQT file.</p> </li> <li> <code>input_ligand_pdbqt_file</code>             (<code>Path</code>)         \u2013          <p>Target ligand PDBQT file.</p> </li> <li> <code>output_conf_file</code>             (<code>Path</code>)         \u2013          <p>The generated Vina conf file.</p> </li> <li> <code>output_ligand_pdbqt_file</code>             (<code>Path</code>)         \u2013          <p>Output ligand PDBQT file path.</p> </li> <li> <code>center</code>             (<code>tuple[float, float, float]</code>, default:                 <code>(15.614, 53.38, 15.455)</code> )         \u2013          <p>Center coordinates.</p> </li> <li> <code>size</code>             (<code>tuple[int, int, int]</code>, default:                 <code>(20, 20, 20)</code> )         \u2013          <p>Size of the search space.</p> </li> <li> <code>exhaustiveness</code>             (<code>int</code>, default:                 <code>20</code> )         \u2013          <p>Number of monte carlo simulations.</p> </li> <li> <code>num_modes</code>             (<code>int</code>, default:                 <code>20</code> )         \u2013          <p>Number of binding modes.</p> </li> <li> <code>energy_range</code>             (<code>int</code>, default:                 <code>10</code> )         \u2013          <p>Maximum energy difference between the best binding mode and the worst one displayed (kcal/mol).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Path</code>         \u2013          <p>Path of created output configuration file</p> </li> </ul> Source code in <code>taps/apps/docking/app.py</code> <pre><code>def make_autodock_config(\n    input_receptor_pdbqt_file: pathlib.Path,\n    input_ligand_pdbqt_file: pathlib.Path,\n    output_conf_file: pathlib.Path,\n    output_ligand_pdbqt_file: pathlib.Path,\n    center: tuple[float, float, float] = (15.614, 53.380, 15.455),\n    size: tuple[int, int, int] = (20, 20, 20),\n    exhaustiveness: int = 20,\n    num_modes: int = 20,\n    energy_range: int = 10,\n) -&gt; pathlib.Path:\n    \"\"\"Create configuration for AutoDock Vina.\n\n    Create a configuration file for AutoDock Vina by describing\n    the target receptor and setting coordinate bounds for the\n    docking experiment.\n\n    Args:\n        input_receptor_pdbqt_file: Target receptor PDBQT file.\n        input_ligand_pdbqt_file: Target ligand PDBQT file.\n        output_conf_file: The generated Vina conf file.\n        output_ligand_pdbqt_file: Output ligand PDBQT file path.\n        center: Center coordinates.\n        size: Size of the search space.\n        exhaustiveness: Number of monte carlo simulations.\n        num_modes: Number of binding modes.\n        energy_range: Maximum energy difference between\n            the best binding mode and the worst one displayed (kcal/mol).\n\n    Returns:\n        Path of created output configuration file\n    \"\"\"\n    # Format configuration file\n    file_contents = (\n        f'receptor = {input_receptor_pdbqt_file}\\n'\n        f'ligand = {input_ligand_pdbqt_file}\\n'\n        f'center_x = {center[0]}\\n'\n        f'center_y = {center[1]}\\n'\n        f'center_z = {center[2]}\\n'\n        f'size_x = {size[0]}\\n'\n        f'size_y = {size[1]}\\n'\n        f'size_z = {size[2]}\\n'\n        f'exhaustiveness = {exhaustiveness}\\n'\n        f'num_modes = {num_modes}\\n'\n        f'energy_range = {energy_range}\\n'\n        f'out = {output_ligand_pdbqt_file}\\n'\n    )\n    # Write configuration file\n    with open(output_conf_file, 'w') as f:\n        f.write(file_contents)\n\n    return output_conf_file\n</code></pre>"},{"location":"api/apps/docking/app/#taps.apps.docking.app.autodock_vina","title":"autodock_vina()","text":"<pre><code>autodock_vina(\n    config_file: Path, smiles: str, num_cpu: int = 1\n) -&gt; tuple[str, float]\n</code></pre> <p>Compute the docking score.</p> <p>The docking score captures the potential energy change when the protein and ligand are docked. A strong binding is represented by a negative score, weaker (or no) binders are represented by positive scores.</p> <p>Parameters:</p> <ul> <li> <code>config_file</code>             (<code>Path</code>)         \u2013          <p>Vina configuration file.</p> </li> <li> <code>smiles</code>             (<code>str</code>)         \u2013          <p>The SMILES string of molecule.</p> </li> <li> <code>num_cpu</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Number of CPUs to use.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[str, float]</code>         \u2013          <p>A tuple containing the SMILES string.</p> </li> </ul> Source code in <code>taps/apps/docking/app.py</code> <pre><code>def autodock_vina(\n    config_file: pathlib.Path,\n    smiles: str,\n    num_cpu: int = 1,\n) -&gt; tuple[str, float]:\n    \"\"\"Compute the docking score.\n\n    The docking score captures the potential energy change when the protein\n    and ligand are docked. A strong binding is represented by a negative score,\n    weaker (or no) binders are represented by positive scores.\n\n    Args:\n        config_file: Vina configuration file.\n        smiles: The SMILES string of molecule.\n        num_cpu: Number of CPUs to use.\n\n    Returns:\n        A tuple containing the SMILES string.\n    \"\"\"\n    command = ['vina', '--config', str(config_file), '--cpu', str(num_cpu)]\n    result = subprocess.check_output(command, encoding='utf-8')\n\n    # find the last row of the table and extract the affinity score\n    result_list = result.split('\\n')\n    last_row = result_list[-3]\n    score = last_row.split()\n    return (smiles, float(score[1]))\n</code></pre>"},{"location":"api/apps/docking/data/","title":"taps.apps.docking.data","text":"<code>taps/apps/docking/data.py</code> <p>Data download CLI for the docking app.</p>"},{"location":"api/apps/docking/data/#taps.apps.docking.data.download","title":"download()","text":"<pre><code>download(directory: Path | str) -&gt; None\n</code></pre> <p>Download docking app files.</p> Source code in <code>taps/apps/docking/data.py</code> <pre><code>def download(directory: pathlib.Path | str) -&gt; None:\n    \"\"\"Download docking app files.\"\"\"\n    directory = pathlib.Path(directory)\n    directory.mkdir(parents=True, exist_ok=True)\n    for name, source in FILES.items():\n        output = directory / name\n        with open(output, 'wb') as f:\n            content = requests.get(source, stream=True).content\n            f.write(content)\n        print(f'Downloaded {output}')\n</code></pre>"},{"location":"api/apps/docking/data/#taps.apps.docking.data.main","title":"main()","text":"<pre><code>main(argv: Sequence[str] | None = None) -&gt; int\n</code></pre> <p>Data download CLI.</p> Source code in <code>taps/apps/docking/data.py</code> <pre><code>def main(argv: Sequence[str] | None = None) -&gt; int:\n    \"\"\"Data download CLI.\"\"\"\n    argv = argv if argv is not None else sys.argv[1:]\n    parser = argparse.ArgumentParser(\n        description='Protein docking data downloader',\n    )\n    parser.add_argument(\n        '-o',\n        '--output',\n        required=True,\n        help='Output directory for downloaded files',\n    )\n    args = parser.parse_args(argv)\n\n    download(args.output)\n\n    return 0\n</code></pre>"},{"location":"api/apps/docking/train/","title":"taps.apps.docking.train","text":"<code>taps/apps/docking/train.py</code> <p>Protein docking model training.</p> <p>Module adapted from ParslDock.</p>"},{"location":"api/apps/docking/train/#taps.apps.docking.train.MorganFingerprintTransformer","title":"MorganFingerprintTransformer","text":"<pre><code>MorganFingerprintTransformer(\n    length: int = 256, radius: int = 4\n)\n</code></pre> <p>             Bases: <code>BaseEstimator</code>, <code>TransformerMixin</code></p> <p>Class that converts SMILES strings to fingerprint vectors.</p> Source code in <code>taps/apps/docking/train.py</code> <pre><code>def __init__(self, length: int = 256, radius: int = 4):\n    self.length = length\n    self.radius = radius\n</code></pre>"},{"location":"api/apps/docking/train/#taps.apps.docking.train.MorganFingerprintTransformer.fit","title":"fit()","text":"<pre><code>fit(\n    X: list[str], y: array[int] | None = None\n) -&gt; MorganFingerprintTransformer\n</code></pre> <p>Train model.</p> <p>Parameters:</p> <ul> <li> <code>X</code>             (<code>list[str]</code>)         \u2013          <p>List of SMILES strings.</p> </li> <li> <code>y</code>             (<code>array[int] | None</code>, default:                 <code>None</code> )         \u2013          <p>Array of true fingerprints.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>MorganFingerprintTransformer</code>         \u2013          <p>The trained model.</p> </li> </ul> Source code in <code>taps/apps/docking/train.py</code> <pre><code>def fit(\n    self,\n    X: list[str],  # noqa: N803\n    y: np.array[int] | None = None,\n) -&gt; MorganFingerprintTransformer:\n    \"\"\"Train model.\n\n    Args:\n        X: List of SMILES strings.\n        y: Array of true fingerprints.\n\n    Returns:\n        The trained model.\n    \"\"\"\n    return self  # Don't need to do anything\n</code></pre>"},{"location":"api/apps/docking/train/#taps.apps.docking.train.MorganFingerprintTransformer.transform","title":"transform()","text":"<pre><code>transform(\n    X: list[str], y: array[int] | None = None\n) -&gt; array[int]\n</code></pre> <p>Compute the fingerprints.</p> <p>Parameters:</p> <ul> <li> <code>X</code>             (<code>list[str]</code>)         \u2013          <p>List of SMILES strings.</p> </li> <li> <code>y</code>             (<code>array[int] | None</code>, default:                 <code>None</code> )         \u2013          <p>Array of true fingerprints.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>array[int]</code>         \u2013          <p>Array of predicted fingerprints.</p> </li> </ul> Source code in <code>taps/apps/docking/train.py</code> <pre><code>def transform(\n    self,\n    X: list[str],  # noqa: N803\n    y: np.array[int] | None = None,\n) -&gt; np.array[int]:\n    \"\"\"Compute the fingerprints.\n\n    Args:\n        X: List of SMILES strings.\n        y: Array of true fingerprints.\n\n    Returns:\n        Array of predicted fingerprints.\n    \"\"\"\n    fps = []\n    for x in X:\n        fp = compute_morgan_fingerprints(x, self.length, self.radius)\n        fps.append(fp)\n\n    return fps\n</code></pre>"},{"location":"api/apps/docking/train/#taps.apps.docking.train.compute_morgan_fingerprints","title":"compute_morgan_fingerprints()","text":"<pre><code>compute_morgan_fingerprints(\n    smiles: str,\n    fingerprint_length: int,\n    fingerprint_radius: int,\n) -&gt; tuple[int, int]\n</code></pre> <p>Get Morgan Fingerprint of a specific SMILES string.</p> <p>Adapted from: https://github.com/google-research/google-research/blob/&gt; dfac417/mol_dqn/chemgraph/dqn/deep_q_networks.py#L750</p> <p>Parameters:</p> <ul> <li> <code>smiles</code>             (<code>str</code>)         \u2013          <p>The molecule as a SMILES string.</p> </li> <li> <code>fingerprint_length</code>             (<code>int</code>)         \u2013          <p>Bit-length of fingerprint.</p> </li> <li> <code>fingerprint_radius</code>             (<code>int</code>)         \u2013          <p>Radius used to compute fingerprint.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>int</code>         \u2013          <p>Array containing the Morgan fingerprint with shape</p> </li> <li> <code>int</code>         \u2013          <p><code>[hparams, fingerprint_length]</code>.</p> </li> </ul> Source code in <code>taps/apps/docking/train.py</code> <pre><code>def compute_morgan_fingerprints(\n    smiles: str,\n    fingerprint_length: int,\n    fingerprint_radius: int,\n) -&gt; tuple[int, int]:\n    \"\"\"Get Morgan Fingerprint of a specific SMILES string.\n\n    Adapted from: https://github.com/google-research/google-research/blob/&gt;\n    dfac4178ccf521e8d6eae45f7b0a33a6a5b691ee/mol_dqn/chemgraph/dqn/deep_q_networks.py#L750\n\n    Args:\n        smiles: The molecule as a SMILES string.\n        fingerprint_length: Bit-length of fingerprint.\n        fingerprint_radius: Radius used to compute fingerprint.\n\n    Returns:\n        Array containing the Morgan fingerprint with shape\n        `[hparams, fingerprint_length]`.\n    \"\"\"\n    from rdkit import Chem\n    from rdkit import DataStructs\n    from rdkit.Chem import rdFingerprintGenerator\n\n    # Parse the molecule\n    molecule = Chem.MolFromSmiles(smiles)\n\n    # Compute the fingerprint\n    mfpgen = rdFingerprintGenerator.GetMorganGenerator(\n        radius=fingerprint_radius,\n        fpSize=fingerprint_length,\n    )\n    fingerprint = mfpgen.GetFingerprint(\n        molecule,\n    )\n    arr = np.zeros((1,), dtype=bool)\n\n    # ConvertToNumpyArray takes ~ 0.19 ms, while\n    # np.asarray takes ~ 4.69 ms\n    DataStructs.ConvertToNumpyArray(fingerprint, arr)\n    return arr\n</code></pre>"},{"location":"api/apps/docking/train/#taps.apps.docking.train.train_model","title":"train_model()","text":"<pre><code>train_model(training_data: DataFrame) -&gt; Pipeline\n</code></pre> <p>Train a machine learning model using Morgan Fingerprints.</p> <p>Parameters:</p> <ul> <li> <code>training_data</code>             (<code>DataFrame</code>)         \u2013          <p>Dataframe with a 'smiles' and 'score' column that contains molecule structure and docking score, respectfully.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Pipeline</code>         \u2013          <p>A trained model.</p> </li> </ul> Source code in <code>taps/apps/docking/train.py</code> <pre><code>def train_model(training_data: pd.DataFrame) -&gt; Pipeline:\n    \"\"\"Train a machine learning model using Morgan Fingerprints.\n\n    Args:\n        training_data: Dataframe with a 'smiles' and 'score' column\n            that contains molecule structure and docking score, respectfully.\n\n    Returns:\n        A trained model.\n    \"\"\"\n    from sklearn.neighbors import KNeighborsRegressor\n    from sklearn.pipeline import Pipeline\n\n    model = Pipeline(\n        [\n            ('fingerprint', MorganFingerprintTransformer()),\n            (\n                'knn',\n                KNeighborsRegressor(\n                    n_neighbors=4,\n                    weights='distance',\n                    metric='jaccard',\n                    n_jobs=-1,\n                ),\n            ),\n        ],\n    )\n\n    return model.fit(training_data['smiles'], training_data['score'])\n</code></pre>"},{"location":"api/apps/docking/train/#taps.apps.docking.train.run_model","title":"run_model()","text":"<pre><code>run_model(model: Pipeline, smiles: list[str]) -&gt; DataFrame\n</code></pre> <p>Run a model on a list of smiles strings.</p> <p>Parameters:</p> <ul> <li> <code>model</code>             (<code>Pipeline</code>)         \u2013          <p>Trained model that takes SMILES strings as inputs.</p> </li> <li> <code>smiles</code>             (<code>list[str]</code>)         \u2013          <p>List of molecules to evaluate.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>         \u2013          <p>A dataframe with the molecules and their predicted outputs</p> </li> </ul> Source code in <code>taps/apps/docking/train.py</code> <pre><code>def run_model(model: Pipeline, smiles: list[str]) -&gt; pd.DataFrame:\n    \"\"\"Run a model on a list of smiles strings.\n\n    Args:\n        model: Trained model that takes SMILES strings as inputs.\n        smiles: List of molecules to evaluate.\n\n    Returns:\n        A dataframe with the molecules and their predicted outputs\n    \"\"\"\n    import pandas as pd\n\n    pred_y = model.predict(smiles)\n    return pd.DataFrame({'smiles': smiles, 'score': pred_y})\n</code></pre>"},{"location":"api/apps/failures/","title":"taps.apps.failures","text":"<code>taps/apps/failures/__init__.py</code>"},{"location":"api/apps/failures/app/","title":"taps.apps.failures.app","text":"<code>taps/apps/failures/app.py</code>"},{"location":"api/apps/failures/app/#taps.apps.failures.app.FailureInjectionApp","title":"FailureInjectionApp","text":"<pre><code>FailureInjectionApp(\n    base_config: AppConfig,\n    failure_rate: float,\n    failure_type: FailureType,\n)\n</code></pre> <p>Failure injection application.</p> <p>Parameters:</p> <ul> <li> <code>base_config</code>             (<code>AppConfig</code>)         \u2013          <p>Configuration for the base application to inject failures into.</p> </li> <li> <code>failure_type</code>             (<code>FailureType</code>)         \u2013          <p>The type of failure to inject.</p> </li> <li> <code>failure_rate</code>             (<code>float</code>)         \u2013          <p>The probability of injecting a failure into any given task.</p> </li> </ul> Source code in <code>taps/apps/failures/app.py</code> <pre><code>def __init__(\n    self,\n    base_config: AppConfig,\n    failure_rate: float,\n    failure_type: FailureType,\n) -&gt; None:\n    self.base = base_config.get_app()\n    self.base_config = base_config\n    self.failure_rate = failure_rate\n    self.failure_type = failure_type\n</code></pre>"},{"location":"api/apps/failures/app/#taps.apps.failures.app.FailureInjectionApp.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the application.</p> Source code in <code>taps/apps/failures/app.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close the application.\"\"\"\n    self.base.close()\n</code></pre>"},{"location":"api/apps/failures/app/#taps.apps.failures.app.FailureInjectionApp.run","title":"run()","text":"<pre><code>run(engine: Engine, run_dir: Path) -&gt; None\n</code></pre> <p>Run the application.</p> <p>Parameters:</p> <ul> <li> <code>engine</code>             (<code>Engine</code>)         \u2013          <p>Application execution engine.</p> </li> <li> <code>run_dir</code>             (<code>Path</code>)         \u2013          <p>Run directory.</p> </li> </ul> Source code in <code>taps/apps/failures/app.py</code> <pre><code>def run(self, engine: Engine, run_dir: pathlib.Path) -&gt; None:\n    \"\"\"Run the application.\n\n    Args:\n        engine: Application execution engine.\n        run_dir: Run directory.\n    \"\"\"\n    logger.log(\n        APP_LOG_LEVEL,\n        f'Injecting failures into the {self.base_config.name} app '\n        f'(type={self.failure_type.value}, rate={self.failure_rate})',\n    )\n\n    with _FailureInjectionEngine(\n        engine,\n        failure_rate=self.failure_rate,\n        failure_type=self.failure_type,\n    ) as failure_engine:\n        self.base.run(engine=failure_engine, run_dir=run_dir)\n</code></pre>"},{"location":"api/apps/failures/types/","title":"taps.apps.failures.types","text":"<code>taps/apps/failures/types.py</code>"},{"location":"api/apps/failures/types/#taps.apps.failures.types.FailureType","title":"FailureType","text":"<p>             Bases: <code>Enum</code></p> <p>Failure types.</p>"},{"location":"api/apps/failures/types/#taps.apps.failures.types.exception_failure","title":"exception_failure()","text":"<pre><code>exception_failure() -&gt; None\n</code></pre> <p>Raise an exception.</p> Source code in <code>taps/apps/failures/types.py</code> <pre><code>def exception_failure() -&gt; None:\n    \"\"\"Raise an exception.\"\"\"\n    raise Exception('Failure injection error.')\n</code></pre>"},{"location":"api/apps/failures/types/#taps.apps.failures.types.import_failure","title":"import_failure()","text":"<pre><code>import_failure() -&gt; None\n</code></pre> <p>Simulate an import error due to a bad environment.</p> Source code in <code>taps/apps/failures/types.py</code> <pre><code>def import_failure() -&gt; None:\n    \"\"\"Simulate an import error due to a bad environment.\"\"\"\n    raise ImportError('Failure injection error.')\n</code></pre>"},{"location":"api/apps/failures/types/#taps.apps.failures.types.manager_killed_failure","title":"manager_killed_failure()","text":"<pre><code>manager_killed_failure() -&gt; None\n</code></pre> <p>Kill the parent process (i.e., the manager).</p> Source code in <code>taps/apps/failures/types.py</code> <pre><code>def manager_killed_failure() -&gt; None:\n    \"\"\"Kill the parent process (i.e., the manager).\"\"\"\n    current_pid = os.getpid()\n    current_process = psutil.Process(current_pid)\n    parent_process = current_process.parent()\n\n    if parent_process is None:\n        logger.warning(\n            f'Task process (pid={current_process} has no parent process',\n        )\n        return\n\n    parent_pid = parent_process.pid\n    logger.info(f'Killing manager parent process (pid={parent_pid})')\n    try:\n        os.kill(parent_pid, signal.SIGTERM)\n        logger.info(f'Parent process terminated (pid={parent_pid})')\n    except psutil.NoSuchProcess:\n        logger.exception('Parent process does not exist')\n    except psutil.AccessDenied:\n        logger.exception(\n            'Insufficient permission to terminate parent process',\n        )\n</code></pre>"},{"location":"api/apps/failures/types/#taps.apps.failures.types.memory_failure","title":"memory_failure()","text":"<pre><code>memory_failure() -&gt; None\n</code></pre> <p>Force an out of memory error.</p> Source code in <code>taps/apps/failures/types.py</code> <pre><code>def memory_failure() -&gt; None:\n    \"\"\"Force an out of memory error.\"\"\"\n    huge_memory_list = []\n    while True:\n        huge_memory_list.append('x' * (1024**3))\n</code></pre>"},{"location":"api/apps/failures/types/#taps.apps.failures.types.node_killed_failure","title":"node_killed_failure()","text":"<pre><code>node_killed_failure() -&gt; None\n</code></pre> <p>Kill other processes in the node to simulate a node failure.</p> Warning <p>This is a very dangerous function. It will kill random processes on the node. Do not run this function in a process with sudo privileges.</p> Source code in <code>taps/apps/failures/types.py</code> <pre><code>def node_killed_failure() -&gt; None:\n    \"\"\"Kill other processes in the node to simulate a node failure.\n\n    Warning:\n        This is a very dangerous function. It will kill random processes\n        on the node. Do not run this function in a process with sudo\n        privileges.\n    \"\"\"\n    current_pid = os.getpid()\n\n    for proc in psutil.process_iter(attrs=['pid', 'name']):\n        pid = proc.info['pid']\n        if pid == current_pid:\n            continue\n        try:\n            p = psutil.Process(pid)\n            p.terminate()\n        except (\n            psutil.NoSuchProcess,\n            psutil.AccessDenied,\n            psutil.ZombieProcess,\n        ):\n            logger.exception(f'Exception when killing process (pid={pid})')\n\n    psutil.wait_procs(psutil.process_iter(), timeout=3, callback=None)\n</code></pre>"},{"location":"api/apps/failures/types/#taps.apps.failures.types.worker_killed_failure","title":"worker_killed_failure()","text":"<pre><code>worker_killed_failure() -&gt; None\n</code></pre> <p>Kill the current process.</p> Source code in <code>taps/apps/failures/types.py</code> <pre><code>def worker_killed_failure() -&gt; None:\n    \"\"\"Kill the current process.\"\"\"\n    pid = os.getpid()\n    try:\n        psutil.Process(pid).terminate()\n    except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):\n        logger.exception(f'Failed to kill current process (pid={pid})')\n</code></pre>"},{"location":"api/apps/failures/types/#taps.apps.failures.types.timeout_failure","title":"timeout_failure()","text":"<pre><code>timeout_failure() -&gt; None\n</code></pre> <p>Sleep forever to force walltime or timeout error.</p> Source code in <code>taps/apps/failures/types.py</code> <pre><code>def timeout_failure() -&gt; None:\n    \"\"\"Sleep forever to force walltime or timeout error.\"\"\"\n    import time\n\n    while True:\n        time.sleep(60)\n</code></pre>"},{"location":"api/apps/failures/types/#taps.apps.failures.types.ulimit_failure","title":"ulimit_failure()","text":"<pre><code>ulimit_failure() -&gt; None\n</code></pre> <p>Open 1M files to simulate ulimit exceeded error.</p> Source code in <code>taps/apps/failures/types.py</code> <pre><code>def ulimit_failure() -&gt; None:\n    \"\"\"Open 1M files to simulate ulimit exceeded error.\"\"\"\n    limit = 1_000_000\n    handles = []\n\n    with tempfile.TemporaryDirectory() as tmp_dir:\n        try:\n            for i in range(limit):\n                file = os.path.join(tmp_dir, f'{i}.txt')\n                handles.append(open(file, 'w'))  # noqa: SIM115\n        finally:\n            for handle in handles:\n                handle.close()\n</code></pre>"},{"location":"api/apps/failures/types/#taps.apps.failures.types.zero_division_failure","title":"zero_division_failure()","text":"<pre><code>zero_division_failure() -&gt; None\n</code></pre> <p>Raise divide by zero error.</p> Source code in <code>taps/apps/failures/types.py</code> <pre><code>def zero_division_failure() -&gt; None:\n    \"\"\"Raise divide by zero error.\"\"\"\n    raise ZeroDivisionError('Failure injection error.')\n</code></pre>"},{"location":"api/apps/fedlearn/","title":"taps.apps.fedlearn","text":"<code>taps/apps/fedlearn/__init__.py</code>"},{"location":"api/apps/fedlearn/app/","title":"taps.apps.fedlearn.app","text":"<code>taps/apps/fedlearn/app.py</code>"},{"location":"api/apps/fedlearn/app/#taps.apps.fedlearn.app.FedlearnApp","title":"FedlearnApp","text":"<pre><code>FedlearnApp(\n    clients: int,\n    rounds: int,\n    dataset: DataChoices,\n    batch_size: int,\n    epochs: int,\n    lr: float,\n    data_dir: Path,\n    device: str = \"cpu\",\n    download: bool = False,\n    train: bool = True,\n    test: bool = True,\n    alpha: float = 100000.0,\n    participation: float = 1.0,\n    seed: int | None = None,\n)\n</code></pre> <p>Federated learning application.</p> <p>Parameters:</p> <ul> <li> <code>clients</code>             (<code>int</code>)         \u2013          <p>Number of simulated clients.</p> </li> <li> <code>rounds</code>             (<code>int</code>)         \u2013          <p>Number of aggregation rounds to perform.</p> </li> <li> <code>dataset</code>             (<code>DataChoices</code>)         \u2013          <p>Dataset (and corresponding model) to use.</p> </li> <li> <code>batch_size</code>             (<code>int</code>)         \u2013          <p>Batch size used for local training across all clients.</p> </li> <li> <code>epochs</code>             (<code>int</code>)         \u2013          <p>Number of epochs used during local training on all the clients.</p> </li> <li> <code>lr</code>             (<code>float</code>)         \u2013          <p>Learning rate used during local training on all the clients.</p> </li> <li> <code>data_dir</code>             (<code>Path</code>)         \u2013          <p>Root directory where the dataset is stored or where you wish to download the data (i.e., <code>download=True</code>).</p> </li> <li> <code>device</code>             (<code>str</code>, default:                 <code>'cpu'</code> )         \u2013          <p>Device to use for model training (e.g., <code>'cuda'</code>, <code>'cpu'</code>, <code>'mps'</code>).</p> </li> <li> <code>train</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>If <code>True</code> (default), the local training will be run. If `False, then a no-op version of the application will be performed where no training is done. This is useful for debugging purposes.</p> </li> <li> <code>test</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>If <code>True</code> (default), model testing is done at the end of each aggregation round.</p> </li> <li> <code>alpha</code>             (<code>float</code>, default:                 <code>100000.0</code> )         \u2013          <p>The number of data samples across clients is defined by a Dirichlet distribution. This value is used to define the uniformity of the amount of data samples across all clients. When data alpha is large, then the number of data samples across clients is uniform (default). When the value is very small, then the sample distribution becomes more non-uniform. Note: this value must be greater than 0.</p> </li> <li> <code>participation</code>             (<code>float</code>, default:                 <code>1.0</code> )         \u2013          <p>The portion of clients that participate in an aggregation round. If set to 1.0, then all clients participate in each round; if 0.5 then half of the clients, and so on. At least one client will be selected regardless of this value and the number of clients.</p> </li> <li> <code>seed</code>             (<code>int | None</code>, default:                 <code>None</code> )         \u2013          <p>Seed for reproducibility.</p> </li> </ul> Source code in <code>taps/apps/fedlearn/app.py</code> <pre><code>def __init__(\n    self,\n    clients: int,\n    rounds: int,\n    dataset: DataChoices,\n    batch_size: int,\n    epochs: int,\n    lr: float,\n    data_dir: pathlib.Path,\n    device: str = 'cpu',\n    download: bool = False,\n    train: bool = True,\n    test: bool = True,\n    alpha: float = 1e5,\n    participation: float = 1.0,\n    seed: int | None = None,\n) -&gt; None:\n    self.rng = np.random.default_rng(seed)\n    if seed is not None:\n        torch.manual_seed(seed)\n\n    self.dataset = dataset\n    self.global_model = create_model(self.dataset)\n\n    self.train, self.test = train, test\n    self.train_data, self.test_data = None, None\n    root = pathlib.Path(data_dir)\n    if self.train:\n        self.train_data = load_data(\n            self.dataset,\n            root,\n            train=True,\n            download=True,\n        )\n    if self.test:\n        self.test_data = load_data(\n            self.dataset,\n            root,\n            train=False,\n            download=True,\n        )\n\n    self.device = torch.device(device)\n    self.epochs = epochs\n    self.batch_size = batch_size\n    self.lr = lr\n\n    self.participation = participation\n\n    self.rounds = rounds\n    if alpha &lt;= 0:\n        raise ValueError('Argument `alpha` must be greater than 0.')\n    self.alpha = alpha\n\n    self.clients = create_clients(\n        clients,\n        self.dataset,\n        self.train,\n        self.train_data,\n        self.alpha,\n        self.rng,\n    )\n    logger.log(APP_LOG_LEVEL, f'Created {len(self.clients)} clients')\n</code></pre>"},{"location":"api/apps/fedlearn/app/#taps.apps.fedlearn.app.FedlearnApp.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the application.</p> Source code in <code>taps/apps/fedlearn/app.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close the application.\"\"\"\n    pass\n</code></pre>"},{"location":"api/apps/fedlearn/app/#taps.apps.fedlearn.app.FedlearnApp.run","title":"run()","text":"<pre><code>run(engine: Engine, run_dir: Path) -&gt; None\n</code></pre> <p>Run the application.</p> <p>Parameters:</p> <ul> <li> <code>engine</code>             (<code>Engine</code>)         \u2013          <p>Application execution engine.</p> </li> <li> <code>run_dir</code>             (<code>Path</code>)         \u2013          <p>Directory for run outputs.</p> </li> </ul> Source code in <code>taps/apps/fedlearn/app.py</code> <pre><code>def run(self, engine: Engine, run_dir: pathlib.Path) -&gt; None:\n    \"\"\"Run the application.\n\n    Args:\n        engine: Application execution engine.\n        run_dir: Directory for run outputs.\n    \"\"\"\n    results = []\n    for round_idx in range(self.rounds):\n        preface = f'({round_idx+1}/{self.rounds})'\n        logger.log(\n            APP_LOG_LEVEL,\n            f'{preface} Starting local training for this round',\n        )\n\n        train_result = self._federated_round(round_idx, engine, run_dir)\n        results.extend(train_result)\n\n        if self.test_data is not None:\n            logger.log(\n                APP_LOG_LEVEL,\n                f'{preface} Starting the test for the global model',\n            )\n            test_result = engine.submit(\n                test_model,\n                self.global_model,\n                self.test_data,\n                round_idx,\n                self.device,\n            ).result()\n            logger.log(\n                APP_LOG_LEVEL,\n                f\"{preface} Finished testing with test_loss=\"\n                f\"{test_result['test_loss']:.3f}\",\n            )\n</code></pre>"},{"location":"api/apps/fedlearn/modules/","title":"taps.apps.fedlearn.modules","text":"<code>taps/apps/fedlearn/modules.py</code>"},{"location":"api/apps/fedlearn/modules/#taps.apps.fedlearn.modules.CifarModule","title":"CifarModule","text":"<pre><code>CifarModule(num_classes: int)\n</code></pre> <p>             Bases: <code>Module</code></p> <p>Cifar model.</p> <p>Source: https://www.kaggle.com/code/shadabhussain/cifar-10-cnn-using-pytorch</p> Source code in <code>taps/apps/fedlearn/modules.py</code> <pre><code>def __init__(self, num_classes: int):\n    super().__init__()\n    self.num_classes = num_classes\n    self.network = nn.Sequential(\n        nn.Conv2d(3, 32, kernel_size=3, padding=1),\n        nn.ReLU(),\n        nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n        nn.ReLU(),\n        nn.MaxPool2d(2, 2),  # output: 64 x 16 x 16\n        nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n        nn.ReLU(),\n        nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n        nn.ReLU(),\n        nn.MaxPool2d(2, 2),  # output: 128 x 8 x 8\n        nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n        nn.ReLU(),\n        nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n        nn.ReLU(),\n        nn.MaxPool2d(2, 2),  # output: 256 x 4 x 4\n        nn.Flatten(),\n        nn.Linear(256 * 4 * 4, 1024),\n        nn.ReLU(),\n        nn.Linear(1024, 512),\n        nn.ReLU(),\n        nn.Linear(512, num_classes),\n    )\n</code></pre>"},{"location":"api/apps/fedlearn/modules/#taps.apps.fedlearn.modules.CifarModule.forward","title":"forward()","text":"<pre><code>forward(x: Tensor) -&gt; Tensor\n</code></pre> <p>Forward pass.</p> Source code in <code>taps/apps/fedlearn/modules.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Forward pass.\"\"\"\n    return self.network(x)\n</code></pre>"},{"location":"api/apps/fedlearn/modules/#taps.apps.fedlearn.modules.MnistModule","title":"MnistModule","text":"<pre><code>MnistModule()\n</code></pre> <p>             Bases: <code>Module</code></p> <p>Model for MNIST and FashionMNIST data.</p> Source code in <code>taps/apps/fedlearn/modules.py</code> <pre><code>def __init__(self) -&gt; None:\n    super().__init__()\n    self.flattener = nn.Flatten()\n    self.fc1 = nn.Linear(28 * 28, 56 * 56)\n    self.fc2 = nn.Linear(56 * 56, 28 * 28)\n    self.fc3 = nn.Linear(28 * 28, 14 * 14)\n    self.classifier = nn.Linear(14 * 14, 10)\n</code></pre>"},{"location":"api/apps/fedlearn/modules/#taps.apps.fedlearn.modules.MnistModule.forward","title":"forward()","text":"<pre><code>forward(x: Tensor) -&gt; Tensor\n</code></pre> <p>Forward pass.</p> Source code in <code>taps/apps/fedlearn/modules.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Forward pass.\"\"\"\n    x = self.flattener(x)\n    x = F.relu(self.fc1(x))\n    x = F.relu(self.fc2(x))\n    x = F.relu(self.fc3(x))\n    x = self.classifier(x)\n    return x\n</code></pre>"},{"location":"api/apps/fedlearn/modules/#taps.apps.fedlearn.modules.create_model","title":"create_model()","text":"<pre><code>create_model(data: DataChoices) -&gt; Module\n</code></pre> <p>Create a model suitable for the dataset choice.</p> Note <p>The currently supported dataset options are <code>MNIST</code>, <code>FashionMNIST</code>, <code>CIFAR10</code>, and <code>CIFAR100</code>.</p> <p>Parameters:</p> <ul> <li> <code>data</code>             (<code>DataChoices</code>)         \u2013          <p>Name of dataset that will be used for training (and testing).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Module</code>         \u2013          <p>PyTorch model.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013          <p>If an unsupported value for <code>data</code> is provided.</p> </li> </ul> Source code in <code>taps/apps/fedlearn/modules.py</code> <pre><code>def create_model(data: DataChoices) -&gt; nn.Module:\n    \"\"\"Create a model suitable for the dataset choice.\n\n    Note:\n        The currently supported dataset options are `MNIST`, `FashionMNIST`,\n        `CIFAR10`, and `CIFAR100`.\n\n    Args:\n        data: Name of dataset that will be used for training (and testing).\n\n    Returns:\n        PyTorch model.\n\n    Raises:\n        ValueError: If an unsupported value for `data` is provided.\n    \"\"\"\n    name = data.value.lower()\n\n    if name == 'cifar10':\n        return CifarModule(10)\n    elif name == 'cifar100':\n        return CifarModule(100)\n    elif name in ('fmnist', 'mnist'):\n        return MnistModule()\n    else:\n        raise ValueError(\n            f'Unknown dataset \"{data.value}\". Supported options are '\n            \"'cifar10', 'cifar100', 'fmnist', and 'mnist'.\",\n        )\n</code></pre>"},{"location":"api/apps/fedlearn/modules/#taps.apps.fedlearn.modules.load_data","title":"load_data()","text":"<pre><code>load_data(\n    data_name: DataChoices,\n    root: Path,\n    train: bool,\n    download: bool = False,\n) -&gt; Dataset\n</code></pre> <p>Load dataset for training.</p> <p>Parameters:</p> <ul> <li> <code>data_name</code>             (<code>DataChoices</code>)         \u2013          <p>Dataset choice.</p> </li> <li> <code>root</code>             (<code>Path</code>)         \u2013          <p>Root dataset directory.</p> </li> <li> <code>train</code>             (<code>bool</code>)         \u2013          <p>Flag for if training.</p> </li> <li> <code>download</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Should the dataset be downloaded.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code> (            <code>Dataset</code> )        \u2013          <p>description</p> </li> </ul> Source code in <code>taps/apps/fedlearn/modules.py</code> <pre><code>def load_data(\n    data_name: DataChoices,\n    root: pathlib.Path,\n    train: bool,\n    download: bool = False,\n) -&gt; Dataset:\n    \"\"\"Load dataset for training.\n\n    Args:\n        data_name: Dataset choice.\n        root: Root dataset directory.\n        train: Flag for if training.\n        download: Should the dataset be downloaded.\n\n    Returns:\n        Dataset: _description_\n    \"\"\"\n    kwargs = {\n        'root': root,\n        'train': train,\n        'transform': transforms.ToTensor(),\n        'download': download,\n    }\n    name = data_name.value.lower()\n    if name == 'cifar10':\n        return torchvision.datasets.CIFAR10(**kwargs)\n    elif name == 'cifar100':\n        return torchvision.datasets.CIFAR100(**kwargs)\n    elif name == 'fmnist':\n        return torchvision.datasets.FashionMNIST(**kwargs)\n    elif name == 'mnist':\n        return torchvision.datasets.MNIST(**kwargs)\n    else:\n        raise ValueError(f'Unknown dataset: {data_name}.')\n</code></pre>"},{"location":"api/apps/fedlearn/tasks/","title":"taps.apps.fedlearn.tasks","text":"<code>taps/apps/fedlearn/tasks.py</code>"},{"location":"api/apps/fedlearn/tasks/#taps.apps.fedlearn.tasks.no_local_train","title":"no_local_train()","text":"<pre><code>no_local_train(\n    client: Client,\n    round_idx: int,\n    epochs: int,\n    batch_size: int,\n    lr: float,\n    device: device,\n) -&gt; list[Result]\n</code></pre> <p>No-op version of local_train.</p> <p>Returns:</p> <ul> <li> <code>list[Result]</code>         \u2013          <p>Empty result list.</p> </li> </ul> Source code in <code>taps/apps/fedlearn/tasks.py</code> <pre><code>def no_local_train(\n    client: Client,\n    round_idx: int,\n    epochs: int,\n    batch_size: int,\n    lr: float,\n    device: torch.device,\n) -&gt; list[Result]:\n    \"\"\"No-op version of [local_train][taps.apps.fedlearn.tasks.local_train].\n\n    Returns:\n        Empty result list.\n    \"\"\"\n    return []\n</code></pre>"},{"location":"api/apps/fedlearn/tasks/#taps.apps.fedlearn.tasks.local_train","title":"local_train()","text":"<pre><code>local_train(\n    client: Client,\n    round_idx: int,\n    epochs: int,\n    batch_size: int,\n    lr: float,\n    device: device,\n) -&gt; list[Result]\n</code></pre> <p>Local training job.</p> <p>Parameters:</p> <ul> <li> <code>client</code>             (<code>Client</code>)         \u2013          <p>The client to train.</p> </li> <li> <code>round_idx</code>             (<code>int</code>)         \u2013          <p>The current round number.</p> </li> <li> <code>epochs</code>             (<code>int</code>)         \u2013          <p>Number of epochs.</p> </li> <li> <code>batch_size</code>             (<code>int</code>)         \u2013          <p>Batch size when iterating through data.</p> </li> <li> <code>lr</code>             (<code>float</code>)         \u2013          <p>Learning rate.</p> </li> <li> <code>device</code>             (<code>device</code>)         \u2013          <p>Backend hardware to train with.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[Result]</code>         \u2013          <p>List of results that record the training history.</p> </li> </ul> Source code in <code>taps/apps/fedlearn/tasks.py</code> <pre><code>def local_train(\n    client: Client,\n    round_idx: int,\n    epochs: int,\n    batch_size: int,\n    lr: float,\n    device: torch.device,\n) -&gt; list[Result]:\n    \"\"\"Local training job.\n\n    Args:\n        client: The client to train.\n        round_idx: The current round number.\n        epochs: Number of epochs.\n        batch_size: Batch size when iterating through data.\n        lr: Learning rate.\n        device: Backend hardware to train with.\n\n    Returns:\n        List of results that record the training history.\n    \"\"\"\n    from datetime import datetime\n\n    results: list[Result] = []\n    client.model.to(device)\n    client.model.train()\n    optimizer = torch.optim.SGD(client.model.parameters(), lr=lr)\n    loader = DataLoader(client.data, batch_size=batch_size)\n\n    for epoch in range(epochs):\n        epoch_results = []\n        log_every_n_batches = 100\n        running_loss = 0.0\n\n        for batch_idx, batch in enumerate(loader):\n            inputs, targets = batch\n            inputs, targets = inputs.to(device), targets.to(device)\n            preds = client.model(inputs)\n            loss = F.cross_entropy(preds, targets)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            if batch_idx % log_every_n_batches == (log_every_n_batches - 1):\n                epoch_results.append(\n                    {\n                        'time': datetime.now(),\n                        'client_idx': client.idx,\n                        'round_idx': round_idx,\n                        'epoch': epoch,\n                        'batch_idx': batch_idx,\n                        'train_loss': running_loss / log_every_n_batches,\n                    },\n                )\n                running_loss = 0.0\n\n        results.extend(epoch_results)\n\n    return results\n</code></pre>"},{"location":"api/apps/fedlearn/tasks/#taps.apps.fedlearn.tasks.test_model","title":"test_model()","text":"<pre><code>test_model(\n    model: Module,\n    data: Dataset,\n    round_idx: int,\n    device: device,\n) -&gt; Result\n</code></pre> <p>Evaluate a model.</p> Source code in <code>taps/apps/fedlearn/tasks.py</code> <pre><code>def test_model(\n    model: nn.Module,\n    data: Dataset,\n    round_idx: int,\n    device: torch.device,\n) -&gt; Result:\n    \"\"\"Evaluate a model.\"\"\"\n    from datetime import datetime\n\n    model.eval()\n    with torch.no_grad():\n        model.to(device)\n        loader = DataLoader(data, batch_size=1)\n        total_loss, n_batches = 0.0, 0\n        for batch in loader:\n            inputs, targets = batch\n            inputs, targets = inputs.to(device), targets.to(device)\n            preds = model(inputs)\n            loss = F.cross_entropy(preds, targets)\n\n            total_loss += loss.item()\n            n_batches += 1\n\n    res: Result = {\n        'time': datetime.now(),\n        'round_idx': round_idx,\n        'test_loss': total_loss / n_batches,\n    }\n    return res\n</code></pre>"},{"location":"api/apps/fedlearn/types/","title":"taps.apps.fedlearn.types","text":"<code>taps/apps/fedlearn/types.py</code>"},{"location":"api/apps/fedlearn/types/#taps.apps.fedlearn.types.ClientID","title":"ClientID  <code>module-attribute</code>","text":"<pre><code>ClientID: TypeAlias = int\n</code></pre> <p>Integer IDs for <code>Client</code> instances.</p>"},{"location":"api/apps/fedlearn/types/#taps.apps.fedlearn.types.Result","title":"Result  <code>module-attribute</code>","text":"<pre><code>Result: TypeAlias = Dict[str, Any]\n</code></pre> <p>Result type for each FL epoch, round, and task.</p>"},{"location":"api/apps/fedlearn/types/#taps.apps.fedlearn.types.DataChoices","title":"DataChoices","text":"<p>             Bases: <code>Enum</code></p> <p>Dataset options.</p>"},{"location":"api/apps/fedlearn/types/#taps.apps.fedlearn.types.DataChoices.CIFAR10","title":"CIFAR10  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>CIFAR10 = 'cifar10'\n</code></pre> <p>Cifar10 dataset.</p>"},{"location":"api/apps/fedlearn/types/#taps.apps.fedlearn.types.DataChoices.CIFAR100","title":"CIFAR100  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>CIFAR100 = 'cifar100'\n</code></pre> <p>Cifar100 dataset.</p>"},{"location":"api/apps/fedlearn/types/#taps.apps.fedlearn.types.DataChoices.FMNIST","title":"FMNIST  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>FMNIST = 'fmnist'\n</code></pre> <p>FMNIST dataset.</p>"},{"location":"api/apps/fedlearn/types/#taps.apps.fedlearn.types.DataChoices.MNIST","title":"MNIST  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MNIST = 'mnist'\n</code></pre> <p>MNIST dataset.</p>"},{"location":"api/apps/fedlearn/types/#taps.apps.fedlearn.types.Client","title":"Client","text":"<p>             Bases: <code>BaseModel</code></p> <p>Client class.</p>"},{"location":"api/apps/fedlearn/types/#taps.apps.fedlearn.types.Client.idx","title":"idx  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>idx: ClientID = Field(description='Client ID')\n</code></pre> <p>Client ID.</p>"},{"location":"api/apps/fedlearn/types/#taps.apps.fedlearn.types.Client.model","title":"model  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model: Module = Field(description=\"Client's local model\")\n</code></pre> <p>Client's local model.</p>"},{"location":"api/apps/fedlearn/types/#taps.apps.fedlearn.types.Client.data","title":"data  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>data: Optional[Subset] = Field(\n    description=\"The subset of data this client will train on.\"\n)\n</code></pre> <p>The subset of data this client will train on.</p>"},{"location":"api/apps/fedlearn/utils/","title":"taps.apps.fedlearn.utils","text":"<code>taps/apps/fedlearn/utils.py</code>"},{"location":"api/apps/fedlearn/utils/#taps.apps.fedlearn.utils.create_clients","title":"create_clients()","text":"<pre><code>create_clients(\n    num_clients: int,\n    data_name: DataChoices,\n    train: bool,\n    train_data: Dataset,\n    data_alpha: float,\n    rng: Generator,\n) -&gt; list[Client]\n</code></pre> <p>Create many clients with disjoint sets of data.</p> <p>Parameters:</p> <ul> <li> <code>num_clients</code>             (<code>int</code>)         \u2013          <p>Number of clients to create.</p> </li> <li> <code>data_name</code>             (<code>DataChoices</code>)         \u2013          <p>The name of the data used. Used for initializing the corresponding model.</p> </li> <li> <code>train</code>             (<code>bool</code>)         \u2013          <p>If the application is using the no-op training task, then this function skips the step for giving each client their own subset of data.</p> </li> <li> <code>train_data</code>             (<code>Dataset</code>)         \u2013          <p>The original dataset that will be split across the clients.</p> </li> <li> <code>data_alpha</code>             (<code>float</code>)         \u2013          <p>The Dirichlet distribution alpha value for the number of samples across clients.</p> </li> <li> <code>rng</code>             (<code>Generator</code>)         \u2013          <p>Random number generator.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[Client]</code>         \u2013          <p>List of clients.</p> </li> </ul> Source code in <code>taps/apps/fedlearn/utils.py</code> <pre><code>def create_clients(\n    num_clients: int,\n    data_name: DataChoices,\n    train: bool,\n    train_data: Dataset,\n    data_alpha: float,\n    rng: Generator,\n) -&gt; list[Client]:\n    \"\"\"Create many clients with disjoint sets of data.\n\n    Args:\n        num_clients: Number of clients to create.\n        data_name: The name of the data used. Used for initializing the\n            corresponding model.\n        train: If the application is using the no-op training task, then this\n            function skips the step for giving each client their own subset\n            of data.\n        train_data: The original dataset that will be split across the clients.\n        data_alpha: The\n            [Dirichlet](https://en.wikipedia.org/wiki/Dirichlet_distribution)\n            distribution alpha value for the number of samples across clients.\n        rng: Random number generator.\n\n    Returns:\n        List of clients.\n    \"\"\"\n    client_ids = list(range(num_clients))\n\n    if train:\n        client_indices: dict[int, list[int]] = {idx: [] for idx in client_ids}\n\n        alpha = [data_alpha] * num_clients\n        client_popularity = rng.dirichlet(alpha)\n\n        for data_idx, _ in enumerate(train_data):\n            selected_client: ClientID = rng.choice(\n                client_ids,\n                size=1,\n                p=client_popularity,\n            )[0]\n            client_indices[selected_client].append(data_idx)\n\n        client_subsets = {\n            idx: Subset(train_data, client_indices[idx]) for idx in client_ids\n        }\n    else:\n        client_subsets = {idx: None for idx in client_ids}\n\n    clients = []\n    for idx in client_ids:\n        client = Client(\n            idx=idx,\n            model=create_model(data_name),\n            data=client_subsets[idx],\n        )\n        clients.append(client)\n\n    return clients\n</code></pre>"},{"location":"api/apps/fedlearn/utils/#taps.apps.fedlearn.utils.unweighted_module_avg","title":"unweighted_module_avg()","text":"<pre><code>unweighted_module_avg(\n    selected_clients: list[Client],\n) -&gt; OrderedDict[str, Tensor]\n</code></pre> <p>Compute the unweighted average of models.</p> Source code in <code>taps/apps/fedlearn/utils.py</code> <pre><code>def unweighted_module_avg(\n    selected_clients: list[Client],\n) -&gt; OrderedDict[str, torch.Tensor]:\n    \"\"\"Compute the unweighted average of models.\"\"\"\n    models = [client.model for client in selected_clients]\n    w = 1 / len(selected_clients)\n\n    with torch.no_grad():\n        avg_weights = OrderedDict()\n        for model in models:\n            for name, value in model.state_dict().items():\n                partial = w * torch.clone(value)\n                if name not in avg_weights:\n                    avg_weights[name] = partial\n                else:\n                    avg_weights[name] += partial\n\n    return avg_weights\n</code></pre>"},{"location":"api/apps/moldesign/","title":"taps.apps.moldesign","text":"<code>taps/apps/moldesign/__init__.py</code>"},{"location":"api/apps/moldesign/app/","title":"taps.apps.moldesign.app","text":"<code>taps/apps/moldesign/app.py</code>"},{"location":"api/apps/moldesign/app/#taps.apps.moldesign.app.MoldesignApp","title":"MoldesignApp","text":"<pre><code>MoldesignApp(\n    dataset: Path,\n    initial_count: int = 8,\n    search_count: int = 64,\n    batch_size: int = 4,\n    seed: int = 0,\n)\n</code></pre> <p>Molecular design application.</p> <p>Parameters:</p> <ul> <li> <code>dataset</code>             (<code>Path</code>)         \u2013          <p>Molecule search space dataset.</p> </li> <li> <code>initial_count</code>             (<code>int</code>, default:                 <code>8</code> )         \u2013          <p>Number of initial calculations.</p> </li> <li> <code>search_count</code>             (<code>int</code>, default:                 <code>64</code> )         \u2013          <p>Number of molecules to evaluate in total.</p> </li> <li> <code>batch_size</code>             (<code>int</code>, default:                 <code>4</code> )         \u2013          <p>Number of molecules to evaluate in each batch of simulations.</p> </li> <li> <code>seed</code>             (<code>int</code>, default:                 <code>0</code> )         \u2013          <p>Random seed.</p> </li> </ul> Source code in <code>taps/apps/moldesign/app.py</code> <pre><code>def __init__(\n    self,\n    dataset: pathlib.Path,\n    initial_count: int = 8,\n    search_count: int = 64,\n    batch_size: int = 4,\n    seed: int = 0,\n) -&gt; None:\n    self.dataset = dataset\n    self.initial_count = initial_count\n    self.search_count = search_count\n    self.batch_size = batch_size\n    self.seed = seed\n</code></pre>"},{"location":"api/apps/moldesign/app/#taps.apps.moldesign.app.MoldesignApp.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the application.</p> Source code in <code>taps/apps/moldesign/app.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close the application.\"\"\"\n    pass\n</code></pre>"},{"location":"api/apps/moldesign/app/#taps.apps.moldesign.app.MoldesignApp.run","title":"run()","text":"<pre><code>run(engine: Engine, run_dir: Path) -&gt; None\n</code></pre> <p>Run the application.</p> <p>Parameters:</p> <ul> <li> <code>engine</code>             (<code>Engine</code>)         \u2013          <p>Application execution engine.</p> </li> <li> <code>run_dir</code>             (<code>Path</code>)         \u2013          <p>Run directory.</p> </li> </ul> Source code in <code>taps/apps/moldesign/app.py</code> <pre><code>def run(self, engine: Engine, run_dir: pathlib.Path) -&gt; None:  # noqa: PLR0915\n    \"\"\"Run the application.\n\n    Args:\n        engine: Application execution engine.\n        run_dir: Run directory.\n    \"\"\"\n    start_time = time.monotonic()\n\n    search_space = pd.read_csv(self.dataset, sep='\\\\s+')\n    logger.log(\n        APP_LOG_LEVEL,\n        f'Loaded search space (size={len(search_space):,})',\n    )\n\n    # Submit with some random guesses\n    train_data_list = []\n    init_mols = list(\n        search_space.sample(\n            self.initial_count,\n            random_state=self.seed,\n        )['smiles'],\n    )\n    sim_futures: dict[TaskFuture[float], str] = {\n        engine.submit(compute_vertical, mol): mol for mol in init_mols\n    }\n    logger.log(APP_LOG_LEVEL, 'Submitted initial computations')\n    logger.info(f'Initial set: {init_mols}')\n    already_ran = set()\n\n    # Loop until you finish populating the initial set\n    while len(sim_futures) &gt; 0:\n        # First, get the next completed computation from the list\n        future: TaskFuture[float] = next(\n            as_completed(list(sim_futures.keys())),\n        )\n\n        # Remove it from the list of still-running task and get the input\n        smiles = sim_futures.pop(future)\n        already_ran.add(smiles)\n\n        # Check if the run completed successfully\n        if future.exception() is not None:\n            # If it failed, pick a new SMILES string at random and submit\n            smiles = search_space.sample(\n                1,\n                random_state=self.seed,\n            ).iloc[0]['smiles']\n            new_future = engine.submit(\n                compute_vertical,\n                smiles,\n            )\n            sim_futures[new_future] = smiles\n        else:\n            # If it succeeded, store the result\n            train_data_list.append(\n                {\n                    'smiles': smiles,\n                    'ie': future.result(),\n                    'batch': 0,\n                    'time': time.monotonic() - start_time,\n                },\n            )\n\n    logger.log(APP_LOG_LEVEL, 'Done computing initial set')\n\n    # Create the initial training set as a\n    train_data = pd.DataFrame(train_data_list)\n    logger.log(\n        APP_LOG_LEVEL,\n        f'Created initial training set (size={len(train_data)})',\n    )\n\n    # Loop until complete\n    batch = 1\n    while len(train_data) &lt; self.search_count:\n        # Train and predict as show in the previous section.\n        train_future = engine.submit(train_model, train_data)\n        logger.log(APP_LOG_LEVEL, 'Submitting inference tasks')\n        inference_futures = [\n            engine.submit(run_model, train_future, chunk)\n            for chunk in np.array_split(search_space['smiles'], 64)\n        ]\n        predictions = engine.submit(\n            combine_inferences,\n            *inference_futures,\n        ).result()\n        logger.log(\n            APP_LOG_LEVEL,\n            f'Inference results received (size={len(predictions)})',\n        )\n\n        # Sort the predictions in descending order, and submit new\n        # molecules from them.\n        predictions.sort_values('ie', ascending=False, inplace=True)\n        sim_futures = {}\n        for smiles in predictions['smiles']:\n            if smiles not in already_ran:\n                new_future = engine.submit(compute_vertical, smiles)\n                sim_futures[new_future] = smiles\n                already_ran.add(smiles)\n                if len(sim_futures) &gt;= self.batch_size:\n                    break\n        logger.log(\n            APP_LOG_LEVEL,\n            f'Submitted new computations (size={len(sim_futures)})',\n        )\n\n        # Wait for every task in the current batch to complete, and store\n        # successful results.\n        new_results = []\n        for future in as_completed(list(sim_futures.keys())):\n            if future.exception() is None:\n                new_results.append(\n                    {\n                        'smiles': sim_futures[future],\n                        'ie': future.result(),\n                        'batch': batch,\n                        'time': time.monotonic() - start_time,\n                    },\n                )\n\n        # Update the training data and repeat\n        batch += 1\n        train_data = pd.concat(\n            (train_data, pd.DataFrame(new_results)),\n            ignore_index=True,\n        )\n\n    fig, ax = plt.subplots(figsize=(4.5, 3.0))\n    ax.scatter(train_data['time'], train_data['ie'])\n    ax.step(train_data['time'], train_data['ie'].cummax(), 'k--')\n    ax.set_xlabel('Walltime (s)')\n    ax.set_ylabel('Ion. Energy (Ha)')\n    fig.tight_layout()\n\n    figure_path = run_dir / 'results.png'\n    fig.savefig(figure_path)\n    logger.log(APP_LOG_LEVEL, f'Saved figure to {figure_path}')\n\n    training_path = run_dir / 'results.csv'\n    train_data.to_csv(training_path, index=False)\n    logger.log(APP_LOG_LEVEL, f'Saved results to {training_path}')\n</code></pre>"},{"location":"api/apps/moldesign/chemfunctions/","title":"taps.apps.moldesign.chemfunctions","text":"<code>taps/apps/moldesign/chemfunctions.py</code>"},{"location":"api/apps/moldesign/chemfunctions/#taps.apps.moldesign.chemfunctions.MorganFingerprintTransformer","title":"MorganFingerprintTransformer","text":"<pre><code>MorganFingerprintTransformer(\n    length: int = 256, radius: int = 4\n)\n</code></pre> <p>             Bases: <code>BaseEstimator</code>, <code>TransformerMixin</code></p> <p>Class that converts SMILES strings to fingerprint vectors.</p> Source code in <code>taps/apps/moldesign/chemfunctions.py</code> <pre><code>def __init__(self, length: int = 256, radius: int = 4) -&gt; None:\n    self.length = length\n    self.radius = radius\n</code></pre>"},{"location":"api/apps/moldesign/chemfunctions/#taps.apps.moldesign.chemfunctions.MorganFingerprintTransformer.fit","title":"fit()","text":"<pre><code>fit(X: Any, y: Any = None) -&gt; Self\n</code></pre> <p>Fit the transformer.</p> Source code in <code>taps/apps/moldesign/chemfunctions.py</code> <pre><code>def fit(self, X: Any, y: Any = None) -&gt; Self:  # noqa: N803\n    \"\"\"Fit the transformer.\"\"\"\n    return self  # Do need to do anything\n</code></pre>"},{"location":"api/apps/moldesign/chemfunctions/#taps.apps.moldesign.chemfunctions.MorganFingerprintTransformer.transform","title":"transform()","text":"<pre><code>transform(X: Any, y: Any = None) -&gt; Any\n</code></pre> <p>Compute the fingerprints.</p> <p>Parameters:</p> <ul> <li> <code>X</code>             (<code>Any</code>)         \u2013          <p>List of SMILES strings.</p> </li> <li> <code>y</code>             (<code>Any</code>, default:                 <code>None</code> )         \u2013          <p>Ignored.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Any</code>         \u2013          <p>Array of fingerprints.</p> </li> </ul> Source code in <code>taps/apps/moldesign/chemfunctions.py</code> <pre><code>def transform(self, X: Any, y: Any = None) -&gt; Any:  # noqa: N803\n    \"\"\"Compute the fingerprints.\n\n    Args:\n        X: List of SMILES strings.\n        y: Ignored.\n\n    Returns:\n        Array of fingerprints.\n    \"\"\"\n    my_func = partial(\n        compute_morgan_fingerprints,\n        fingerprint_length=self.length,\n        fingerprint_radius=self.radius,\n    )\n    with ProcessPoolExecutor(max_workers=n_workers) as pool:\n        fing = list(pool.map(my_func, X, chunksize=2048))\n    return np.vstack(fing)\n</code></pre>"},{"location":"api/apps/moldesign/chemfunctions/#taps.apps.moldesign.chemfunctions.generate_initial_xyz","title":"generate_initial_xyz()","text":"<pre><code>generate_initial_xyz(mol_string: str) -&gt; str\n</code></pre> <p>Generate the XYZ coordinates for a molecule.</p> <p>Parameters:</p> <ul> <li> <code>mol_string</code>             (<code>str</code>)         \u2013          <p>SMILES string.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>         \u2013          <p>XYZ coordinates for the molecule.</p> </li> </ul> Source code in <code>taps/apps/moldesign/chemfunctions.py</code> <pre><code>def generate_initial_xyz(mol_string: str) -&gt; str:\n    \"\"\"Generate the XYZ coordinates for a molecule.\n\n    Args:\n        mol_string: SMILES string.\n\n    Returns:\n        XYZ coordinates for the molecule.\n    \"\"\"\n    # Generate 3D coordinates for the molecule\n    mol = Chem.MolFromSmiles(mol_string)\n    if mol is None:\n        raise ValueError(f'Parse failure for {mol_string}')\n    mol = Chem.AddHs(mol)\n    AllChem.EmbedMolecule(mol, randomSeed=1)\n    AllChem.MMFFOptimizeMolecule(mol)\n\n    # Save geometry as 3D coordinates\n    xyz = f'{mol.GetNumAtoms()}\\n'\n    xyz += mol_string + '\\n'\n    conf = mol.GetConformer()\n    for i, a in enumerate(mol.GetAtoms()):\n        s = a.GetSymbol()\n        c = conf.GetAtomPosition(i)\n        xyz += f'{s} {c[0]} {c[1]} {c[2]}\\n'\n\n    return xyz\n</code></pre>"},{"location":"api/apps/moldesign/chemfunctions/#taps.apps.moldesign.chemfunctions.compute_vertical","title":"compute_vertical()","text":"<pre><code>compute_vertical(smiles: str) -&gt; float\n</code></pre> <p>Run the ionization potential computation.</p> <p>Parameters:</p> <ul> <li> <code>smiles</code>             (<code>str</code>)         \u2013          <p>SMILES string to evaluate.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>         \u2013          <p>Ionization energy in Ha.</p> </li> </ul> Source code in <code>taps/apps/moldesign/chemfunctions.py</code> <pre><code>def compute_vertical(smiles: str) -&gt; float:\n    \"\"\"Run the ionization potential computation.\n\n    Args:\n        smiles: SMILES string to evaluate.\n\n    Returns:\n        Ionization energy in Ha.\n    \"\"\"\n    # Make the initial geometry\n    xyz = generate_initial_xyz(smiles)\n\n    # Make the XTB calculator\n    calc = XTB(accuracy=0.05)\n\n    # Parse the molecule\n    atoms = read(StringIO(xyz), format='xyz')\n\n    # Compute the neutral geometry. Uses QCEngine\n    # (https://github.com/MolSSI/QCEngine) to handle interfaces to XTB.\n    atoms.calc = calc\n    dyn = LBFGSLineSearch(atoms, logfile=None)\n    dyn.run(fmax=0.02, steps=250)\n\n    neutral_energy = atoms.get_potential_energy()\n\n    # Compute the energy of the relaxed geometry in charged form\n    charges = np.ones((len(atoms),)) * (1 / len(atoms))\n    atoms.set_initial_charges(charges)\n    charged_energy = atoms.get_potential_energy()\n\n    return charged_energy - neutral_energy\n</code></pre>"},{"location":"api/apps/moldesign/chemfunctions/#taps.apps.moldesign.chemfunctions.compute_morgan_fingerprints","title":"compute_morgan_fingerprints()","text":"<pre><code>compute_morgan_fingerprints(\n    smiles: str,\n    fingerprint_length: int,\n    fingerprint_radius: int,\n) -&gt; ndarray\n</code></pre> <p>Get Morgan Fingerprint of a specific SMILES string.</p> <p>Adapted from: https://github.com/google-research/google-research/blob/dfac4178ccf521e8d6eae45f7b0a33a6a5b691ee/mol_dqn/chemgraph/dqn/deep_q_networks.py#L750</p> <p>Parameters:</p> <ul> <li> <code>smiles</code>             (<code>str</code>)         \u2013          <p>The molecule as a SMILES string.</p> </li> <li> <code>fingerprint_length</code>             (<code>int</code>)         \u2013          <p>Bit-length of fingerprint.</p> </li> <li> <code>fingerprint_radius</code>             (<code>int</code>)         \u2013          <p>Radius used to compute fingerprint.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>         \u2013          <p>Array with shape <code>[hparams, fingerprint_length]</code> of the Morgan         fingerprint.</p> </li> </ul> Source code in <code>taps/apps/moldesign/chemfunctions.py</code> <pre><code>def compute_morgan_fingerprints(\n    smiles: str,\n    fingerprint_length: int,\n    fingerprint_radius: int,\n) -&gt; np.ndarray:\n    \"\"\"Get Morgan Fingerprint of a specific SMILES string.\n\n    Adapted from:\n    https://github.com/google-research/google-research/blob/dfac4178ccf521e8d6eae45f7b0a33a6a5b691ee/mol_dqn/chemgraph/dqn/deep_q_networks.py#L750\n\n    Args:\n        smiles: The molecule as a SMILES string.\n        fingerprint_length: Bit-length of fingerprint.\n        fingerprint_radius: Radius used to compute fingerprint.\n\n    Returns:\n        Array with shape `[hparams, fingerprint_length]` of the Morgan \\\n        fingerprint.\n    \"\"\"\n    # Parse the molecule\n    molecule = Chem.MolFromSmiles(smiles)\n\n    # Compute the fingerprint\n    fingerprint = AllChem.GetMorganFingerprintAsBitVect(\n        molecule,\n        fingerprint_radius,\n        fingerprint_length,\n    )\n    arr = np.zeros((1,), dtype=np.bool_)\n\n    # ConvertToNumpyArray takes ~ 0.19 ms, while\n    # np.asarray takes ~ 4.69 ms\n    DataStructs.ConvertToNumpyArray(fingerprint, arr)\n    return arr\n</code></pre>"},{"location":"api/apps/moldesign/chemfunctions/#taps.apps.moldesign.chemfunctions.train_model","title":"train_model()","text":"<pre><code>train_model(\n    smiles: list[str], properties: list[float]\n) -&gt; Pipeline\n</code></pre> <p>Train a machine learning model using Morgan Fingerprints.</p> <p>Parameters:</p> <ul> <li> <code>smiles</code>             (<code>list[str]</code>)         \u2013          <p>SMILES strings for each molecule</p> </li> <li> <code>properties</code>             (<code>list[float]</code>)         \u2013          <p>List of a property for each molecule</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Pipeline</code>         \u2013          <p>A trained model.</p> </li> </ul> Source code in <code>taps/apps/moldesign/chemfunctions.py</code> <pre><code>def train_model(smiles: list[str], properties: list[float]) -&gt; Pipeline:\n    \"\"\"Train a machine learning model using Morgan Fingerprints.\n\n    Args:\n        smiles: SMILES strings for each molecule\n        properties: List of a property for each molecule\n\n    Returns:\n        A trained model.\n    \"\"\"\n    model = Pipeline(\n        [\n            ('fingerprint', MorganFingerprintTransformer()),\n            (\n                'knn',\n                KNeighborsRegressor(\n                    n_neighbors=4,\n                    weights='distance',\n                    metric='jaccard',\n                    n_jobs=-1,\n                ),\n            ),\n        ],\n    )\n\n    return model.fit(smiles, properties)\n</code></pre>"},{"location":"api/apps/moldesign/chemfunctions/#taps.apps.moldesign.chemfunctions.run_model","title":"run_model()","text":"<pre><code>run_model(model: Any, smiles: list[str]) -&gt; DataFrame\n</code></pre> <p>Run a model on a list of smiles strings.</p> <p>Parameters:</p> <ul> <li> <code>model</code>             (<code>Any</code>)         \u2013          <p>Trained model that takes SMILES strings as inputs.</p> </li> <li> <code>smiles</code>             (<code>list[str]</code>)         \u2013          <p>List of molecules to evaluate.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>         \u2013          <p>A dataframe with the molecules and their predicted outputs.</p> </li> </ul> Source code in <code>taps/apps/moldesign/chemfunctions.py</code> <pre><code>def run_model(model: Any, smiles: list[str]) -&gt; pd.DataFrame:\n    \"\"\"Run a model on a list of smiles strings.\n\n    Args:\n        model: Trained model that takes SMILES strings as inputs.\n        smiles: List of molecules to evaluate.\n\n    Returns:\n        A dataframe with the molecules and their predicted outputs.\n    \"\"\"\n    pred_y = model.predict(smiles)\n    return pd.DataFrame({'smiles': smiles, 'ie': pred_y})\n</code></pre>"},{"location":"api/apps/moldesign/tasks/","title":"taps.apps.moldesign.tasks","text":"<code>taps/apps/moldesign/tasks.py</code>"},{"location":"api/apps/moldesign/tasks/#taps.apps.moldesign.tasks.train_model","title":"train_model()","text":"<pre><code>train_model(train_data: DataFrame) -&gt; Pipeline\n</code></pre> <p>Train a machine learning model using Morgan Fingerprints.</p> <p>Parameters:</p> <ul> <li> <code>train_data</code>             (<code>DataFrame</code>)         \u2013          <p>Dataframe with a 'smiles' and 'ie' column that contains molecule structure and property, respectfully.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Pipeline</code>         \u2013          <p>A trained model.</p> </li> </ul> Source code in <code>taps/apps/moldesign/tasks.py</code> <pre><code>def train_model(train_data: pd.DataFrame) -&gt; Pipeline:\n    \"\"\"Train a machine learning model using Morgan Fingerprints.\n\n    Args:\n        train_data: Dataframe with a 'smiles' and 'ie' column\n            that contains molecule structure and property, respectfully.\n\n    Returns:\n        A trained model.\n    \"\"\"\n    # Imports for python functions run remotely must be defined inside the\n    # function\n    from sklearn.neighbors import KNeighborsRegressor\n    from sklearn.pipeline import Pipeline\n\n    from taps.apps.moldesign.chemfunctions import MorganFingerprintTransformer\n\n    model = Pipeline(\n        [\n            ('fingerprint', MorganFingerprintTransformer()),\n            (\n                'knn',\n                KNeighborsRegressor(\n                    n_neighbors=4,\n                    weights='distance',\n                    metric='jaccard',\n                    n_jobs=-1,\n                ),\n            ),\n        ],\n    )\n\n    # Ray arrays are immutable so need to clone.\n    return model.fit(train_data['smiles'].copy(), train_data['ie'].copy())\n</code></pre>"},{"location":"api/apps/moldesign/tasks/#taps.apps.moldesign.tasks.run_model","title":"run_model()","text":"<pre><code>run_model(model: Pipeline, smiles: list[str]) -&gt; DataFrame\n</code></pre> <p>Run a model on a list of smiles strings.</p> <p>Parameters:</p> <ul> <li> <code>model</code>             (<code>Pipeline</code>)         \u2013          <p>Trained model that takes SMILES strings as inputs.</p> </li> <li> <code>smiles</code>             (<code>list[str]</code>)         \u2013          <p>List of molecules to evaluate.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>         \u2013          <p>A dataframe with the molecules and their predicted outputs.</p> </li> </ul> Source code in <code>taps/apps/moldesign/tasks.py</code> <pre><code>def run_model(model: Pipeline, smiles: list[str]) -&gt; pd.DataFrame:\n    \"\"\"Run a model on a list of smiles strings.\n\n    Args:\n        model: Trained model that takes SMILES strings as inputs.\n        smiles: List of molecules to evaluate.\n\n    Returns:\n        A dataframe with the molecules and their predicted outputs.\n    \"\"\"\n    pred_y = model.predict(smiles)\n    return pd.DataFrame({'smiles': smiles, 'ie': pred_y})\n</code></pre>"},{"location":"api/apps/moldesign/tasks/#taps.apps.moldesign.tasks.combine_inferences","title":"combine_inferences()","text":"<pre><code>combine_inferences(*inputs: DataFrame) -&gt; DataFrame\n</code></pre> <p>Concatenate a series of inferences into a single DataFrame.</p> <p>Parameters:</p> <ul> <li> <code>inputs</code>             (<code>DataFrame</code>, default:                 <code>()</code> )         \u2013          <p>A list of the component DataFrames.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>         \u2013          <p>A single DataFrame containing the same inferences.</p> </li> </ul> Source code in <code>taps/apps/moldesign/tasks.py</code> <pre><code>def combine_inferences(*inputs: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Concatenate a series of inferences into a single DataFrame.\n\n    Args:\n        inputs: A list of the component DataFrames.\n\n    Returns:\n        A single DataFrame containing the same inferences.\n    \"\"\"\n    return pd.concat(inputs, ignore_index=True)\n</code></pre>"},{"location":"api/engine/","title":"taps.engine","text":"<code>taps/engine/__init__.py</code>"},{"location":"api/engine/config/","title":"taps.engine.config","text":"<code>taps/engine/config.py</code>"},{"location":"api/engine/config/#taps.engine.config.EngineConfig","title":"EngineConfig","text":"<p>             Bases: <code>BaseModel</code></p> <p>App engine configuration.</p> <p>Attributes:</p> <ul> <li> <code>executor</code>             (<code>ExecutorConfig</code>)         \u2013          <p>Executor configuration.</p> </li> <li> <code>filter</code>             (<code>FilterConfig</code>)         \u2013          <p>Filter configuration.</p> </li> <li> <code>transformer</code>             (<code>TransformerConfig</code>)         \u2013          <p>Transformer configuration.</p> </li> <li> <code>task_record_file_name</code>             (<code>Optional[str]</code>)         \u2013          <p>Name of line-delimited JSON file that task records are logged to.</p> </li> </ul>"},{"location":"api/engine/config/#taps.engine.config.EngineConfig.get_engine","title":"get_engine()","text":"<pre><code>get_engine() -&gt; Engine\n</code></pre> <p>Create an engine from the configuration.</p> Source code in <code>taps/engine/config.py</code> <pre><code>def get_engine(self) -&gt; Engine:\n    \"\"\"Create an engine from the configuration.\"\"\"\n    record_logger = (\n        JSONRecordLogger(self.task_record_file_name)\n        if self.task_record_file_name is not None\n        else None\n    )\n\n    return Engine(\n        executor=self.executor.get_executor(),\n        data_filter=self.filter.get_filter(),\n        data_transformer=self.transformer.get_transformer(),\n        record_logger=record_logger,\n    )\n</code></pre>"},{"location":"api/engine/engine/","title":"taps.engine.engine","text":"<code>taps/engine/engine.py</code>"},{"location":"api/engine/engine/#taps.engine.engine.ExceptionInfo","title":"ExceptionInfo  <code>dataclass</code>","text":"<pre><code>ExceptionInfo(type: str, message: str, traceback: str)\n</code></pre> <p>Task exception information.</p>"},{"location":"api/engine/engine/#taps.engine.engine.ExecutionInfo","title":"ExecutionInfo  <code>dataclass</code>","text":"<pre><code>ExecutionInfo(\n    hostname: str,\n    execution_start_time: float,\n    execution_end_time: float,\n    task_start_time: float,\n    task_end_time: float,\n    input_transform_start_time: float,\n    input_transform_end_time: float,\n    result_transform_start_time: float,\n    result_transform_end_time: float,\n)\n</code></pre> <p>Task execution information.</p>"},{"location":"api/engine/engine/#taps.engine.engine.TaskInfo","title":"TaskInfo  <code>dataclass</code>","text":"<pre><code>TaskInfo(\n    task_id: str,\n    function_name: str,\n    parent_task_ids: list[str],\n    submit_time: float,\n    received_time: float | None = None,\n    success: bool | None = None,\n    exception: ExceptionInfo | None = None,\n    execution: ExecutionInfo | None = None,\n)\n</code></pre> <p>Task information.</p>"},{"location":"api/engine/engine/#taps.engine.engine.TaskFuture","title":"TaskFuture","text":"<pre><code>TaskFuture(\n    future: Future[_TaskResult[T]],\n    info: TaskInfo,\n    data_transformer: TaskTransformer[Any],\n)\n</code></pre> <p>             Bases: <code>Generic[T]</code></p> <p>Task future.</p> Note <p>This class should not be instantiated by clients.</p> <p>Attributes:</p> <ul> <li> <code>info</code>         \u2013          <p>Task information and metadata.</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>future</code>             (<code>Future[_TaskResult[T]]</code>)         \u2013          <p>Underlying future returned by the compute executor.</p> </li> <li> <code>info</code>             (<code>TaskInfo</code>)         \u2013          <p>Task information and metadata.</p> </li> <li> <code>data_transformer</code>             (<code>TaskTransformer[Any]</code>)         \u2013          <p>Data transformer used to resolve the task result.</p> </li> </ul> Source code in <code>taps/engine/engine.py</code> <pre><code>def __init__(\n    self,\n    future: Future[_TaskResult[T]],\n    info: TaskInfo,\n    data_transformer: TaskTransformer[Any],\n) -&gt; None:\n    self.info = info\n    self._future = future\n    self._data_transformer = data_transformer\n</code></pre>"},{"location":"api/engine/engine/#taps.engine.engine.TaskFuture.cancel","title":"cancel()","text":"<pre><code>cancel() -&gt; bool\n</code></pre> <p>Attempt to cancel the task.</p> <p>If the call is currently being executed or finished running and cannot be cancelled then the method will return <code>False</code>, otherwise the call will be cancelled and the method will return <code>True</code>.</p> Source code in <code>taps/engine/engine.py</code> <pre><code>def cancel(self) -&gt; bool:\n    \"\"\"Attempt to cancel the task.\n\n    If the call is currently being executed or finished running and\n    cannot be cancelled then the method will return `False`, otherwise\n    the call will be cancelled and the method will return `True`.\n    \"\"\"\n    return self._future.cancel()\n</code></pre>"},{"location":"api/engine/engine/#taps.engine.engine.TaskFuture.done","title":"done()","text":"<pre><code>done() -&gt; bool\n</code></pre> <p>Return <code>True</code> is the call was successfully cancelled or finished.</p> Source code in <code>taps/engine/engine.py</code> <pre><code>def done(self) -&gt; bool:\n    \"\"\"Return `True` is the call was successfully cancelled or finished.\"\"\"\n    return self._future.done()\n</code></pre>"},{"location":"api/engine/engine/#taps.engine.engine.TaskFuture.exception","title":"exception()","text":"<pre><code>exception() -&gt; BaseException | None\n</code></pre> <p>Get the exception raised by the task or <code>None</code> if successful.</p> Source code in <code>taps/engine/engine.py</code> <pre><code>def exception(self) -&gt; BaseException | None:\n    \"\"\"Get the exception raised by the task or `None` if successful.\"\"\"\n    return self._future.exception()\n</code></pre>"},{"location":"api/engine/engine/#taps.engine.engine.TaskFuture.result","title":"result()","text":"<pre><code>result(timeout: float | None = None) -&gt; T\n</code></pre> <p>Get the result of the task.</p> <p>Parameters:</p> <ul> <li> <code>timeout</code>             (<code>float | None</code>, default:                 <code>None</code> )         \u2013          <p>If the task has not finished, wait up to <code>timeout</code> seconds.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>T</code>         \u2013          <p>Task result if the task completed successfully.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>TimeoutError</code>           \u2013          <p>If <code>timeout</code> is specified and the task does not complete within <code>timeout</code> seconds.</p> </li> </ul> Source code in <code>taps/engine/engine.py</code> <pre><code>def result(self, timeout: float | None = None) -&gt; T:\n    \"\"\"Get the result of the task.\n\n    Args:\n        timeout: If the task has not finished, wait up to `timeout`\n            seconds.\n\n    Returns:\n        Task result if the task completed successfully.\n\n    Raises:\n        TimeoutError: If `timeout` is specified and the task does not\n            complete within `timeout` seconds.\n    \"\"\"\n    task_result = self._future.result(timeout=timeout)\n    result = self._data_transformer.resolve(task_result.result)\n    return result\n</code></pre>"},{"location":"api/engine/engine/#taps.engine.engine.Engine","title":"Engine","text":"<pre><code>Engine(\n    executor: Executor,\n    *,\n    data_filter: Filter | None = None,\n    data_transformer: Transformer[Any] | None = None,\n    record_logger: RecordLogger | None = None\n)\n</code></pre> <p>Application execution engine.</p> <p>Parameters:</p> <ul> <li> <code>executor</code>             (<code>Executor</code>)         \u2013          <p>Task compute executor.</p> </li> <li> <code>data_filter</code>             (<code>Filter | None</code>, default:                 <code>None</code> )         \u2013          <p>Data filter.</p> </li> <li> <code>data_transformer</code>             (<code>Transformer[Any] | None</code>, default:                 <code>None</code> )         \u2013          <p>Data transformer.</p> </li> <li> <code>record_logger</code>             (<code>RecordLogger | None</code>, default:                 <code>None</code> )         \u2013          <p>Task record logger.</p> </li> </ul> Source code in <code>taps/engine/engine.py</code> <pre><code>def __init__(\n    self,\n    executor: Executor,\n    *,\n    data_filter: Filter | None = None,\n    data_transformer: Transformer[Any] | None = None,\n    record_logger: RecordLogger | None = None,\n) -&gt; None:\n    self.executor = executor\n    self.data_transformer: TaskTransformer[Any] = TaskTransformer(\n        NullTransformer()\n        if data_transformer is None\n        else data_transformer,\n        NullFilter() if data_filter is None else data_filter,\n    )\n    self.record_logger = (\n        record_logger if record_logger is not None else NullRecordLogger()\n    )\n\n    # Maps user provided functions to the wrapped function.\n    # This is tricky to type, so we just use Any.\n    self._registered_tasks: dict[\n        Callable[[Any], Any],\n        _TaskWrapper[Any, Any],\n    ] = {}\n\n    # Internal bookkeeping\n    self._running_tasks: dict[Future[Any], TaskFuture[Any]] = {}\n    self._total_tasks = 0\n</code></pre>"},{"location":"api/engine/engine/#taps.engine.engine.Engine.tasks_executed","title":"tasks_executed  <code>property</code>","text":"<pre><code>tasks_executed: int\n</code></pre> <p>Total number of tasks submitted for execution.</p>"},{"location":"api/engine/engine/#taps.engine.engine.Engine.submit","title":"submit()","text":"<pre><code>submit(\n    function: Callable[P, T], /, *args: Any, **kwargs: Any\n) -&gt; TaskFuture[T]\n</code></pre> <p>Schedule the callable to be executed.</p> <p>This function can also accept <code>TaskFuture</code> objects as input to denote dependencies between a parent and this child task.</p> <p>Parameters:</p> <ul> <li> <code>function</code>             (<code>Callable[P, T]</code>)         \u2013          <p>Callable to execute.</p> </li> <li> <code>args</code>             (<code>Any</code>, default:                 <code>()</code> )         \u2013          <p>Positional arguments.</p> </li> <li> <code>kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>Keyword arguments.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>TaskFuture[T]</code>         \u2013          <p><code>TaskFuture</code> object representing the             result of the execution of the callable accessible via             <code>TaskFuture.result()</code>.</p> </li> </ul> Source code in <code>taps/engine/engine.py</code> <pre><code>def submit(\n    self,\n    function: Callable[P, T],\n    /,\n    *args: Any,\n    **kwargs: Any,\n) -&gt; TaskFuture[T]:\n    \"\"\"Schedule the callable to be executed.\n\n    This function can also accept\n    [`TaskFuture`][taps.engine.TaskFuture] objects as input\n    to denote dependencies between a parent and this child task.\n\n    Args:\n        function: Callable to execute.\n        args: Positional arguments.\n        kwargs: Keyword arguments.\n\n    Returns:\n        [`TaskFuture`][taps.engine.TaskFuture] object representing the \\\n        result of the execution of the callable accessible via \\\n        [`TaskFuture.result()`][taps.engine.TaskFuture.result].\n    \"\"\"\n    task_id = uuid.uuid4()\n\n    if function not in self._registered_tasks:\n        self._registered_tasks[function] = _TaskWrapper(\n            function,\n            task_id=task_id,\n            data_transformer=self.data_transformer,\n        )\n\n    task = cast(\n        Callable[P, _TaskResult[T]],\n        self._registered_tasks[function],\n    )\n\n    parents = [\n        str(arg.info.task_id)\n        for arg in (*args, *kwargs.values())\n        if isinstance(arg, TaskFuture)\n    ]\n    info = TaskInfo(\n        task_id=str(task_id),\n        function_name=function.__name__,\n        parent_task_ids=parents,\n        submit_time=time.time(),\n    )\n\n    # Extract executor futures from inside TaskFuture objects\n    args = tuple(\n        arg._future if isinstance(arg, TaskFuture) else arg for arg in args\n    )\n    kwargs = {\n        k: v._future if isinstance(v, TaskFuture) else v\n        for k, v in kwargs.items()\n    }\n\n    args = self.data_transformer.transform_iterable(args)\n    kwargs = self.data_transformer.transform_mapping(kwargs)\n\n    future = self.executor.submit(task, *args, **kwargs)\n    self._total_tasks += 1\n\n    task_future = TaskFuture(future, info, self.data_transformer)\n    self._running_tasks[future] = task_future\n    future.add_done_callback(self._task_done_callback)\n\n    return task_future\n</code></pre>"},{"location":"api/engine/engine/#taps.engine.engine.Engine.map","title":"map()","text":"<pre><code>map(\n    function: Callable[P, T],\n    *iterables: Iterable[args],\n    timeout: float | None = None,\n    chunksize: int = 1\n) -&gt; Iterator[T]\n</code></pre> <p>Map a function onto iterables of arguments.</p> <p>Parameters:</p> <ul> <li> <code>function</code>             (<code>Callable[P, T]</code>)         \u2013          <p>A callable that will take as many arguments as there are passed iterables.</p> </li> <li> <code>iterables</code>             (<code>Iterable[args]</code>, default:                 <code>()</code> )         \u2013          <p>Variable number of iterables.</p> </li> <li> <code>timeout</code>             (<code>float | None</code>, default:                 <code>None</code> )         \u2013          <p>The maximum number of seconds to wait. If None, then there is no limit on the wait time.</p> </li> <li> <code>chunksize</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Currently no supported. If greater than one, the iterables will be chopped into chunks of size chunksize and submitted to the executor. If set to one, the items in the list will be sent one at a time.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Iterator[T]</code>         \u2013          <p>An iterator equivalent to: <code>map(func, *iterables)</code> but the calls             may be evaluated out-of-order.</p> </li> </ul> Source code in <code>taps/engine/engine.py</code> <pre><code>def map(\n    self,\n    function: Callable[P, T],\n    *iterables: Iterable[P.args],\n    timeout: float | None = None,\n    chunksize: int = 1,\n) -&gt; Iterator[T]:\n    \"\"\"Map a function onto iterables of arguments.\n\n    Args:\n        function: A callable that will take as many arguments as there are\n            passed iterables.\n        iterables: Variable number of iterables.\n        timeout: The maximum number of seconds to wait. If None, then there\n            is no limit on the wait time.\n        chunksize: Currently no supported. If greater than one, the\n            iterables will be chopped into chunks of size chunksize\n            and submitted to the executor. If set to one, the items in the\n            list will be sent one at a time.\n\n    Returns:\n        An iterator equivalent to: `map(func, *iterables)` but the calls \\\n        may be evaluated out-of-order.\n    \"\"\"\n    # Source: https://github.com/python/cpython/blob/ec1398e117fb142cc830495503dbdbb1ddafe941/Lib/concurrent/futures/_base.py#L583-L625\n    if timeout is not None:\n        end_time = timeout + time.monotonic()\n\n    tasks = [self.submit(function, *args) for args in zip(*iterables)]\n\n    # Yield must be hidden in closure so that the futures are submitted\n    # before the first iterator value is required.\n    def _result_iterator() -&gt; Generator[T, None, None]:\n        # reverse to keep finishing order\n        tasks.reverse()\n        while tasks:\n            # Careful not to keep a reference to the popped future\n            if timeout is None:\n                yield _result_or_cancel(tasks.pop())\n            else:\n                yield _result_or_cancel(\n                    tasks.pop(),\n                    end_time - time.monotonic(),\n                )\n\n    return _result_iterator()\n</code></pre>"},{"location":"api/engine/engine/#taps.engine.engine.Engine.shutdown","title":"shutdown()","text":"<pre><code>shutdown(\n    wait: bool = True, *, cancel_futures: bool = False\n) -&gt; None\n</code></pre> <p>Shutdown the executor.</p> <p>Parameters:</p> <ul> <li> <code>wait</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Wait on all pending futures to complete.</p> </li> <li> <code>cancel_futures</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Cancel all pending futures that the executor has not started running. Only used in Python 3.9 and later.</p> </li> </ul> Source code in <code>taps/engine/engine.py</code> <pre><code>def shutdown(\n    self,\n    wait: bool = True,\n    *,\n    cancel_futures: bool = False,\n) -&gt; None:\n    \"\"\"Shutdown the executor.\n\n    Args:\n        wait: Wait on all pending futures to complete.\n        cancel_futures: Cancel all pending futures that the executor\n            has not started running. Only used in Python 3.9 and later.\n    \"\"\"\n    if sys.version_info &gt;= (3, 9):  # pragma: &gt;=3.9 cover\n        self.executor.shutdown(\n            wait=wait,\n            cancel_futures=cancel_futures,\n        )\n    else:  # pragma: &lt;3.9 cover\n        self.executor.shutdown(wait=wait)\n    self.data_transformer.close()\n    self.record_logger.close()\n</code></pre>"},{"location":"api/engine/engine/#taps.engine.engine.as_completed","title":"as_completed()","text":"<pre><code>as_completed(\n    tasks: Sequence[TaskFuture[T]],\n    timeout: float | None = None,\n) -&gt; Generator[TaskFuture[T], None, None]\n</code></pre> <p>Return an iterator which yields tasks as they complete.</p> <p>Parameters:</p> <ul> <li> <code>tasks</code>             (<code>Sequence[TaskFuture[T]]</code>)         \u2013          <p>Sequence of tasks.</p> </li> <li> <code>timeout</code>             (<code>float | None</code>, default:                 <code>None</code> )         \u2013          <p>Seconds to wait for a task to complete. If no task completes in that time, a <code>TimeoutError</code> is raised. If timeout is <code>None</code>, there is no limit to the wait time.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Generator[TaskFuture[T], None, None]</code>         \u2013          <p>Iterator which yields futures as they complete (finished or cancelled         futures).</p> </li> </ul> Source code in <code>taps/engine/engine.py</code> <pre><code>def as_completed(\n    tasks: Sequence[TaskFuture[T]],\n    timeout: float | None = None,\n) -&gt; Generator[TaskFuture[T], None, None]:\n    \"\"\"Return an iterator which yields tasks as they complete.\n\n    Args:\n        tasks: Sequence of tasks.\n        timeout: Seconds to wait for a task to complete. If no task completes\n            in that time, a `TimeoutError` is raised. If timeout is `None`,\n            there is no limit to the wait time.\n\n    Returns:\n        Iterator which yields futures as they complete (finished or cancelled \\\n        futures).\n    \"\"\"\n    futures = {task._future: task for task in tasks}\n\n    kwargs = {'timeout': timeout}\n    if len(tasks) == 0 or isinstance(tasks[0]._future, Future):\n        _as_completed = as_completed_python\n    elif isinstance(tasks[0]._future, DaskFuture):\n        _as_completed = as_completed_dask\n        if sys.version_info &lt; (3, 9):  # pragma: &lt;3.9 cover\n            kwargs = {}\n    else:  # pragma: no cover\n        raise ValueError(f'Unsupported future type {type(tasks[0])}.')\n\n    for completed in _as_completed(futures.keys(), **kwargs):\n        yield futures[completed]\n</code></pre>"},{"location":"api/engine/engine/#taps.engine.engine.wait","title":"wait()","text":"<pre><code>wait(\n    tasks: Sequence[TaskFuture[T]],\n    timeout: float | None = None,\n    return_when: str = \"ALL_COMPLETED\",\n) -&gt; tuple[set[TaskFuture[T]], set[TaskFuture[T]]]\n</code></pre> <p>Wait for tasks to finish.</p> <p>Parameters:</p> <ul> <li> <code>tasks</code>             (<code>Sequence[TaskFuture[T]]</code>)         \u2013          <p>Sequence of tasks to wait on.</p> </li> <li> <code>timeout</code>             (<code>float | None</code>, default:                 <code>None</code> )         \u2013          <p>Maximum number of seconds to wait on tasks. Can be <code>None</code> to wait indefinitely.</p> </li> <li> <code>return_when</code>             (<code>str</code>, default:                 <code>'ALL_COMPLETED'</code> )         \u2013          <p>Either <code>\"ALL_COMPLETED\"</code> or <code>\"FIRST_COMPLETED\"</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[set[TaskFuture[T]], set[TaskFuture[T]]]</code>         \u2013          <p>Tuple containing the set of completed tasks and the set of not         completed tasks.</p> </li> </ul> Source code in <code>taps/engine/engine.py</code> <pre><code>def wait(\n    tasks: Sequence[TaskFuture[T]],\n    timeout: float | None = None,\n    return_when: str = 'ALL_COMPLETED',\n) -&gt; tuple[set[TaskFuture[T]], set[TaskFuture[T]]]:\n    \"\"\"Wait for tasks to finish.\n\n    Args:\n        tasks: Sequence of tasks to wait on.\n        timeout: Maximum number of seconds to wait on tasks. Can be `None` to\n            wait indefinitely.\n        return_when: Either `\"ALL_COMPLETED\"` or `\"FIRST_COMPLETED\"`.\n\n    Returns:\n        Tuple containing the set of completed tasks and the set of not \\\n        completed tasks.\n    \"\"\"\n    futures = {task._future: task for task in tasks}\n\n    if len(tasks) == 0 or isinstance(tasks[0]._future, Future):\n        _wait = wait_python\n    elif isinstance(tasks[0]._future, DaskFuture):\n        _wait = wait_dask\n    else:  # pragma: no cover\n        raise ValueError(f'Unsupported future type {type(tasks[0])}.')\n\n    completed_futures, not_completed_futures = _wait(\n        list(futures.keys()),\n        timeout=timeout,\n        return_when=return_when,\n    )\n\n    completed_tasks = {futures[f] for f in completed_futures}\n    not_completed_tasks = {futures[f] for f in not_completed_futures}\n\n    return (completed_tasks, not_completed_tasks)\n</code></pre>"},{"location":"api/engine/transform/","title":"taps.engine.transform","text":"<code>taps/engine/transform.py</code>"},{"location":"api/engine/transform/#taps.engine.transform.TaskTransformer","title":"TaskTransformer","text":"<pre><code>TaskTransformer(\n    transformer: Transformer[IdentifierT], filter_: Filter\n)\n</code></pre> <p>             Bases: <code>Generic[IdentifierT]</code></p> <p>Task data transformer.</p> <p>This class combines a simple object <code>Transformer</code> and a <code>Filter</code> into useful methods for transforming the positional arguments, keyword arguments, and results of tasks.</p> <p>Parameters:</p> <ul> <li> <code>transformer</code>             (<code>Transformer[IdentifierT]</code>)         \u2013          <p>Object transformer.</p> </li> <li> <code>filter_</code>             (<code>Filter</code>)         \u2013          <p>A filter which when called on an object returns <code>True</code> if the object should be transformed.</p> </li> </ul> Source code in <code>taps/engine/transform.py</code> <pre><code>def __init__(\n    self,\n    transformer: Transformer[IdentifierT],\n    filter_: Filter,\n) -&gt; None:\n    self.transformer = transformer\n    self.filter_ = filter_\n</code></pre>"},{"location":"api/engine/transform/#taps.engine.transform.TaskTransformer.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the transformer.</p> Source code in <code>taps/engine/transform.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close the transformer.\"\"\"\n    self.transformer.close()\n</code></pre>"},{"location":"api/engine/transform/#taps.engine.transform.TaskTransformer.transform","title":"transform()","text":"<pre><code>transform(obj: T) -&gt; T | IdentifierT\n</code></pre> <p>Transform an object.</p> <p>Transforms <code>obj</code> into an identifier if it passes the filter check. The identifier can later be used to resolve the object.</p> Source code in <code>taps/engine/transform.py</code> <pre><code>def transform(self, obj: T) -&gt; T | IdentifierT:\n    \"\"\"Transform an object.\n\n    Transforms `obj` into an identifier if it passes the filter check.\n    The identifier can later be used to resolve the object.\n    \"\"\"\n    if self.filter_(obj) and not isinstance(obj, Future):\n        return self.transformer.transform(obj)\n    else:\n        return obj\n</code></pre>"},{"location":"api/engine/transform/#taps.engine.transform.TaskTransformer.transform_iterable","title":"transform_iterable()","text":"<pre><code>transform_iterable(\n    iterable: Iterable[T],\n) -&gt; tuple[T | IdentifierT, ...]\n</code></pre> <p>Transform each object in an iterable.</p> Source code in <code>taps/engine/transform.py</code> <pre><code>def transform_iterable(\n    self,\n    iterable: Iterable[T],\n) -&gt; tuple[T | IdentifierT, ...]:\n    \"\"\"Transform each object in an iterable.\"\"\"\n    return tuple(self.transform(obj) for obj in iterable)\n</code></pre>"},{"location":"api/engine/transform/#taps.engine.transform.TaskTransformer.transform_mapping","title":"transform_mapping()","text":"<pre><code>transform_mapping(\n    mapping: Mapping[K, T]\n) -&gt; dict[K, Any]\n</code></pre> <p>Transform each value in a mapping.</p> Source code in <code>taps/engine/transform.py</code> <pre><code>def transform_mapping(self, mapping: Mapping[K, T]) -&gt; dict[K, Any]:\n    \"\"\"Transform each value in a mapping.\"\"\"\n    return {k: self.transform(v) for k, v in mapping.items()}\n</code></pre>"},{"location":"api/engine/transform/#taps.engine.transform.TaskTransformer.resolve","title":"resolve()","text":"<pre><code>resolve(obj: Any) -&gt; Any\n</code></pre> <p>Resolve an object.</p> <p>Resolves the object if it is an identifier, otherwise returns the passed object.</p> Source code in <code>taps/engine/transform.py</code> <pre><code>def resolve(self, obj: Any) -&gt; Any:\n    \"\"\"Resolve an object.\n\n    Resolves the object if it is an identifier, otherwise returns the\n    passed object.\n    \"\"\"\n    if self.transformer.is_identifier(obj):\n        return self.transformer.resolve(obj)\n    else:\n        return obj\n</code></pre>"},{"location":"api/engine/transform/#taps.engine.transform.TaskTransformer.resolve_iterable","title":"resolve_iterable()","text":"<pre><code>resolve_iterable(\n    iterable: Iterable[Any],\n) -&gt; tuple[Any, ...]\n</code></pre> <p>Resolve each object in an iterable.</p> Source code in <code>taps/engine/transform.py</code> <pre><code>def resolve_iterable(self, iterable: Iterable[Any]) -&gt; tuple[Any, ...]:\n    \"\"\"Resolve each object in an iterable.\"\"\"\n    return tuple(self.resolve(obj) for obj in iterable)\n</code></pre>"},{"location":"api/engine/transform/#taps.engine.transform.TaskTransformer.resolve_mapping","title":"resolve_mapping()","text":"<pre><code>resolve_mapping(mapping: Mapping[K, Any]) -&gt; dict[K, Any]\n</code></pre> <p>Resolve each value in a mapping.</p> Source code in <code>taps/engine/transform.py</code> <pre><code>def resolve_mapping(self, mapping: Mapping[K, Any]) -&gt; dict[K, Any]:\n    \"\"\"Resolve each value in a mapping.\"\"\"\n    return {k: self.resolve(v) for k, v in mapping.items()}\n</code></pre>"},{"location":"api/executor/","title":"taps.executor","text":"<code>taps/executor/__init__.py</code>"},{"location":"api/executor/config/","title":"taps.executor.config","text":"<code>taps/executor/config.py</code>"},{"location":"api/executor/config/#taps.executor.config.ExecutorConfig","title":"ExecutorConfig","text":"<p>             Bases: <code>BaseModel</code>, <code>ABC</code></p> <p>Abstract executor configuration.</p>"},{"location":"api/executor/config/#taps.executor.config.ExecutorConfig.get_executor","title":"get_executor()  <code>abstractmethod</code>","text":"<pre><code>get_executor() -&gt; Executor\n</code></pre> <p>Create an executor from the configuration.</p> Source code in <code>taps/executor/config.py</code> <pre><code>@abc.abstractmethod\ndef get_executor(self) -&gt; Executor:\n    \"\"\"Create an executor from the configuration.\"\"\"\n    ...\n</code></pre>"},{"location":"api/executor/dask/","title":"taps.executor.dask","text":"<code>taps/executor/dask.py</code>"},{"location":"api/executor/dask/#taps.executor.dask.DaskDistributedExecutor","title":"DaskDistributedExecutor","text":"<pre><code>DaskDistributedExecutor(client: Client)\n</code></pre> <p>             Bases: <code>Executor</code></p> <p>Dask task execution engine.</p> <p>Parameters:</p> <ul> <li> <code>client</code>             (<code>Client</code>)         \u2013          <p>Dask distributed client.</p> </li> </ul> Source code in <code>taps/executor/dask.py</code> <pre><code>def __init__(self, client: Client) -&gt; None:\n    self.client = client\n</code></pre>"},{"location":"api/executor/dask/#taps.executor.dask.DaskDistributedExecutor.submit","title":"submit()","text":"<pre><code>submit(\n    function: Callable[P, T],\n    /,\n    *args: args,\n    **kwargs: kwargs,\n) -&gt; Future[T]\n</code></pre> <p>Schedule the callable to be executed.</p> <p>Parameters:</p> <ul> <li> <code>function</code>             (<code>Callable[P, T]</code>)         \u2013          <p>Callable to execute.</p> </li> <li> <code>args</code>             (<code>args</code>, default:                 <code>()</code> )         \u2013          <p>Positional arguments.</p> </li> <li> <code>kwargs</code>             (<code>kwargs</code>, default:                 <code>{}</code> )         \u2013          <p>Keyword arguments.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Future[T]</code>         \u2013          <p><code>Future</code>-like object representing             the result of the execution of the callable.</p> </li> </ul> Source code in <code>taps/executor/dask.py</code> <pre><code>def submit(\n    self,\n    function: Callable[P, T],\n    /,\n    *args: P.args,\n    **kwargs: P.kwargs,\n) -&gt; Future[T]:\n    \"\"\"Schedule the callable to be executed.\n\n    Args:\n        function: Callable to execute.\n        args: Positional arguments.\n        kwargs: Keyword arguments.\n\n    Returns:\n        [`Future`][concurrent.futures.Future]-like object representing \\\n        the result of the execution of the callable.\n    \"\"\"\n    return self.client.submit(function, *args, **kwargs)\n</code></pre>"},{"location":"api/executor/dask/#taps.executor.dask.DaskDistributedExecutor.map","title":"map()","text":"<pre><code>map(\n    function: Callable[P, T],\n    *iterables: Iterable[args],\n    timeout: float | None = None,\n    chunksize: int = 1\n) -&gt; Iterator[T]\n</code></pre> <p>Map a function onto iterables of arguments.</p> <p>Parameters:</p> <ul> <li> <code>function</code>             (<code>Callable[P, T]</code>)         \u2013          <p>A callable that will take as many arguments as there are passed iterables.</p> </li> <li> <code>iterables</code>             (<code>Iterable[args]</code>, default:                 <code>()</code> )         \u2013          <p>Variable number of iterables.</p> </li> <li> <code>timeout</code>             (<code>float | None</code>, default:                 <code>None</code> )         \u2013          <p>The maximum number of seconds to wait. If None, then there is no limit on the wait time.</p> </li> <li> <code>chunksize</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Sets the Dask batch size.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Iterator[T]</code>         \u2013          <p>An iterator equivalent to: <code>map(func, *iterables)</code> but the calls             may be evaluated out-of-order.</p> </li> </ul> Source code in <code>taps/executor/dask.py</code> <pre><code>def map(\n    self,\n    function: Callable[P, T],\n    *iterables: Iterable[P.args],\n    timeout: float | None = None,\n    chunksize: int = 1,\n) -&gt; Iterator[T]:\n    \"\"\"Map a function onto iterables of arguments.\n\n    Args:\n        function: A callable that will take as many arguments as there are\n            passed iterables.\n        iterables: Variable number of iterables.\n        timeout: The maximum number of seconds to wait. If None, then there\n            is no limit on the wait time.\n        chunksize: Sets the Dask batch size.\n\n    Returns:\n        An iterator equivalent to: `map(func, *iterables)` but the calls \\\n        may be evaluated out-of-order.\n    \"\"\"\n    # Based on the Parsl implementation.\n    # https://github.com/Parsl/parsl/blob/7fba7d634ccade76618ee397d3c951c5cbf2cd49/parsl/concurrent/__init__.py#L58\n    futures = self.client.map(function, *iterables, batch_size=chunksize)\n\n    def _result_iterator() -&gt; Generator[T, None, None]:\n        futures.reverse()\n        while futures:\n            yield futures.pop().result(timeout)\n\n    return _result_iterator()\n</code></pre>"},{"location":"api/executor/dask/#taps.executor.dask.DaskDistributedExecutor.shutdown","title":"shutdown()","text":"<pre><code>shutdown(\n    wait: bool = True, *, cancel_futures: bool = False\n) -&gt; None\n</code></pre> <p>Shutdown the client.</p> Source code in <code>taps/executor/dask.py</code> <pre><code>def shutdown(\n    self,\n    wait: bool = True,\n    *,\n    cancel_futures: bool = False,\n) -&gt; None:\n    \"\"\"Shutdown the client.\"\"\"\n    if DaskFuture._cb_executor is not None:\n        # Dask runs future callbacks in threads of a ThreadPoolExecutor\n        # that is a class attributed of Dask's future. Shutting down\n        # the client causes all futures to get cancelled, which can\n        # cause a currently executing callback to raise a CancelledError\n        # if the callback accesses the future's result.\n        DaskFuture._cb_executor.shutdown(wait=wait)\n        DaskFuture._cb_executor = None\n\n    # Note: wait and cancel_futures are not implemented.\n    self.client.close()\n</code></pre>"},{"location":"api/executor/dask/#taps.executor.dask.DaskDistributedConfig","title":"DaskDistributedConfig","text":"<p>             Bases: <code>ExecutorConfig</code></p> <p>Dask Distributed configuration.</p> <p>Attributes:</p> <ul> <li> <code>dask_scheduler_address</code>         \u2013          <p>Dask scheduler address.</p> </li> <li> <code>dask_use_threads</code>         \u2013          <p>Use threads rather than processes for local clusters.</p> </li> <li> <code>dask_workers</code>         \u2013          <p>Number of Dask workers for local clusters.</p> </li> </ul>"},{"location":"api/executor/dask/#taps.executor.dask.DaskDistributedConfig.get_executor","title":"get_executor()","text":"<pre><code>get_executor() -&gt; DaskDistributedExecutor\n</code></pre> <p>Create an executor instance from the config.</p> Source code in <code>taps/executor/dask.py</code> <pre><code>def get_executor(self) -&gt; DaskDistributedExecutor:\n    \"\"\"Create an executor instance from the config.\"\"\"\n    if self.scheduler is not None:\n        client = Client(self.scheduler)\n    else:\n        dask.config.set(\n            {'distributed.worker.daemon': self.daemon_workers},\n        )\n        client = Client(\n            n_workers=self.workers,\n            processes=not self.use_threads,\n            dashboard_address=None,\n        )\n    return DaskDistributedExecutor(client)\n</code></pre>"},{"location":"api/executor/globus/","title":"taps.executor.globus","text":"<code>taps/executor/globus.py</code>"},{"location":"api/executor/globus/#taps.executor.globus.GlobusComputeConfig","title":"GlobusComputeConfig","text":"<p>             Bases: <code>ExecutorConfig</code></p> <p>Globus Compute configuration.</p> <p>Attributes:</p> <ul> <li> <code>endpoint</code>             (<code>str</code>)         \u2013          <p>Globus Compute endpoint UUID.</p> </li> </ul>"},{"location":"api/executor/globus/#taps.executor.globus.GlobusComputeConfig.get_executor","title":"get_executor()","text":"<pre><code>get_executor() -&gt; FutureDependencyExecutor\n</code></pre> <p>Create an executor instance from the config.</p> Source code in <code>taps/executor/globus.py</code> <pre><code>def get_executor(self) -&gt; FutureDependencyExecutor:\n    \"\"\"Create an executor instance from the config.\"\"\"\n    executor = globus_compute_sdk.Executor(\n        self.endpoint,\n        batch_size=self.batch_size,\n    )\n    return FutureDependencyExecutor(executor)\n</code></pre>"},{"location":"api/executor/parsl/","title":"taps.executor.parsl","text":"<code>taps/executor/parsl.py</code>"},{"location":"api/executor/parsl/#taps.executor.parsl.ParslConfig","title":"ParslConfig","text":"<p>             Bases: <code>ExecutorConfig</code></p> <p>Parsl configuration.</p> <p>Attributes:</p> <ul> <li> <code>endpoint</code>         \u2013          <p>Globus Compute endpoint UUID.</p> </li> </ul>"},{"location":"api/executor/parsl/#taps.executor.parsl.ParslConfig.get_executor_config","title":"get_executor_config()","text":"<pre><code>get_executor_config() -&gt; Config\n</code></pre> <p>Create a Parsl config from this config.</p> Source code in <code>taps/executor/parsl.py</code> <pre><code>def get_executor_config(self) -&gt; Config:\n    \"\"\"Create a Parsl config from this config.\"\"\"\n    workers = (\n        self.workers\n        if self.workers is not None\n        else multiprocessing.cpu_count()\n    )\n\n    if self.use_threads:\n        executor = ThreadPoolExecutor(max_threads=workers)\n    else:\n        executor = HighThroughputExecutor(\n            label='htex-local',\n            max_workers_per_node=workers,\n            address=address_by_hostname(),\n            cores_per_worker=1,\n            provider=LocalProvider(\n                channel=LocalChannel(),\n                init_blocks=1,\n                max_blocks=1,\n            ),\n        )\n\n    return Config(executors=[executor], run_dir=self.run_dir)\n</code></pre>"},{"location":"api/executor/parsl/#taps.executor.parsl.ParslConfig.get_executor","title":"get_executor()","text":"<pre><code>get_executor() -&gt; Executor\n</code></pre> <p>Create an executor instance from the config.</p> Source code in <code>taps/executor/parsl.py</code> <pre><code>def get_executor(self) -&gt; globus_compute_sdk.Executor:\n    \"\"\"Create an executor instance from the config.\"\"\"\n    return ParslPoolExecutor(self.get_executor_config())\n</code></pre>"},{"location":"api/executor/python/","title":"taps.executor.python","text":"<code>taps/executor/python.py</code>"},{"location":"api/executor/python/#taps.executor.python.ProcessPoolConfig","title":"ProcessPoolConfig","text":"<p>             Bases: <code>ExecutorConfig</code></p> <p>Process pool executor configuration.</p> <p>Attributes:</p> <ul> <li> <code>max_processes</code>             (<code>int</code>)         \u2013          <p>Maximum number of processes.</p> </li> </ul>"},{"location":"api/executor/python/#taps.executor.python.ProcessPoolConfig.get_executor","title":"get_executor()","text":"<pre><code>get_executor() -&gt; FutureDependencyExecutor\n</code></pre> <p>Create an executor instance from the config.</p> Source code in <code>taps/executor/python.py</code> <pre><code>def get_executor(self) -&gt; FutureDependencyExecutor:\n    \"\"\"Create an executor instance from the config.\"\"\"\n    context = multiprocessing.get_context(self.context)\n    return FutureDependencyExecutor(\n        ProcessPoolExecutor(self.max_processes, mp_context=context),\n    )\n</code></pre>"},{"location":"api/executor/python/#taps.executor.python.ThreadPoolConfig","title":"ThreadPoolConfig","text":"<p>             Bases: <code>ExecutorConfig</code></p> <p>Thread pool executor configuration.</p> <p>Attributes:</p> <ul> <li> <code>max_threads</code>             (<code>int</code>)         \u2013          <p>Maximum number of threads.</p> </li> </ul>"},{"location":"api/executor/python/#taps.executor.python.ThreadPoolConfig.get_executor","title":"get_executor()","text":"<pre><code>get_executor() -&gt; FutureDependencyExecutor\n</code></pre> <p>Create an executor instance from the config.</p> Source code in <code>taps/executor/python.py</code> <pre><code>def get_executor(self) -&gt; FutureDependencyExecutor:\n    \"\"\"Create an executor instance from the config.\"\"\"\n    return FutureDependencyExecutor(ThreadPoolExecutor(self.max_threads))\n</code></pre>"},{"location":"api/executor/ray/","title":"taps.executor.ray","text":"<code>taps/executor/ray.py</code>"},{"location":"api/executor/ray/#taps.executor.ray.RayExecutor","title":"RayExecutor","text":"<pre><code>RayExecutor(\n    address: str | None = \"local\",\n    num_cpus: int | None = None,\n)\n</code></pre> <p>             Bases: <code>Executor</code></p> <p>Ray execution engine.</p> Note <p>Ray will raise a serialization error if a <code>Proxy[bytes]</code> is passed to or returned by a function. This is because Ray skips serializing <code>bytes</code> instances. Ray works with all other types of proxies, so if you need to send <code>bytes</code> data, wrap the data in another type.</p> <p>Parameters:</p> <ul> <li> <code>address</code>             (<code>str | None</code>, default:                 <code>'local'</code> )         \u2013          <p>Address to pass to <code>ray.init()</code>.</p> </li> <li> <code>num_cpus</code>             (<code>int | None</code>, default:                 <code>None</code> )         \u2013          <p>Number of CPUs to use.</p> </li> </ul> Source code in <code>taps/executor/ray.py</code> <pre><code>def __init__(\n    self,\n    address: str | None = 'local',\n    num_cpus: int | None = None,\n) -&gt; None:\n    if RAY_IMPORT_ERROR is not None:  # pragma: no cover\n        raise RAY_IMPORT_ERROR\n\n    ray.init(address=address, configure_logging=False, num_cpus=num_cpus)\n    # Mapping of Python callables to Ray RemoteFunction types\n    self._remote: dict[Any, Any] = {}\n</code></pre>"},{"location":"api/executor/ray/#taps.executor.ray.RayExecutor.submit","title":"submit()","text":"<pre><code>submit(\n    function: Callable[P, T],\n    /,\n    *args: args,\n    **kwargs: kwargs,\n) -&gt; Future[T]\n</code></pre> <p>Schedule the callable to be executed.</p> <p>Parameters:</p> <ul> <li> <code>function</code>             (<code>Callable[P, T]</code>)         \u2013          <p>Callable to execute.</p> </li> <li> <code>args</code>             (<code>args</code>, default:                 <code>()</code> )         \u2013          <p>Positional arguments.</p> </li> <li> <code>kwargs</code>             (<code>kwargs</code>, default:                 <code>{}</code> )         \u2013          <p>Keyword arguments.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Future[T]</code>         \u2013          <p><code>Future</code>-like object representing             the result of the execution of the callable.</p> </li> </ul> Source code in <code>taps/executor/ray.py</code> <pre><code>def submit(\n    self,\n    function: Callable[P, T],\n    /,\n    *args: P.args,\n    **kwargs: P.kwargs,\n) -&gt; Future[T]:\n    \"\"\"Schedule the callable to be executed.\n\n    Args:\n        function: Callable to execute.\n        args: Positional arguments.\n        kwargs: Keyword arguments.\n\n    Returns:\n        [`Future`][concurrent.futures.Future]-like object representing \\\n        the result of the execution of the callable.\n    \"\"\"\n    args = cast(P.args, _parse_args(args))\n    kwargs = cast(P.kwargs, _parse_kwargs(kwargs))\n\n    if function in self._remote:\n        remote = self._remote[function]\n    else:\n        wrapped = _wrap_function(function)\n        remote = ray.remote(wrapped)\n        self._remote[function] = remote\n\n    object_ref = remote.remote(*args, **kwargs)\n\n    return object_ref.future()\n</code></pre>"},{"location":"api/executor/ray/#taps.executor.ray.RayExecutor.shutdown","title":"shutdown()","text":"<pre><code>shutdown(\n    wait: bool = True, *, cancel_futures: bool = False\n) -&gt; None\n</code></pre> <p>Shutdown the client.</p> Source code in <code>taps/executor/ray.py</code> <pre><code>def shutdown(\n    self,\n    wait: bool = True,\n    *,\n    cancel_futures: bool = False,\n) -&gt; None:\n    \"\"\"Shutdown the client.\"\"\"\n    ray.shutdown()\n</code></pre>"},{"location":"api/executor/ray/#taps.executor.ray.RayConfig","title":"RayConfig","text":"<p>             Bases: <code>ExecutorConfig</code></p> <p>Ray configuration.</p> <p>Attributes:</p> <ul> <li> <code>ray_address</code>         \u2013          <p>Address of the Ray cluster to run on.</p> </li> <li> <code>processes</code>         \u2013          <p>Number of actor processes to start in the pool. Defaults to the number of cores in the Ray cluster, or the number of cores on this machine.</p> </li> </ul>"},{"location":"api/executor/ray/#taps.executor.ray.RayConfig.get_executor","title":"get_executor()","text":"<pre><code>get_executor() -&gt; RayExecutor\n</code></pre> <p>Create an executor instance from the config.</p> Source code in <code>taps/executor/ray.py</code> <pre><code>def get_executor(self) -&gt; RayExecutor:\n    \"\"\"Create an executor instance from the config.\"\"\"\n    return RayExecutor(address=self.address, num_cpus=self.num_cpus)\n</code></pre>"},{"location":"api/executor/utils/","title":"taps.executor.utils","text":"<code>taps/executor/utils.py</code>"},{"location":"api/executor/utils/#taps.executor.utils.FutureDependencyExecutor","title":"FutureDependencyExecutor","text":"<pre><code>FutureDependencyExecutor(executor: Executor)\n</code></pre> <p>             Bases: <code>Executor</code></p> <p>Executor wrapper that adds DAG-like features.</p> <p>An <code>Executor</code> implementation that wraps another executor with logic for delaying task submission until all <code>Future</code> instances which are args or kwargs of a task have completed. In other words, child tasks will not be scheduled until the results of the child's parent tasks are available.</p> <p>Parameters:</p> <ul> <li> <code>executor</code>             (<code>Executor</code>)         \u2013          <p>Executor to wrap.</p> </li> </ul> Source code in <code>taps/executor/utils.py</code> <pre><code>def __init__(self, executor: Executor) -&gt; None:\n    self.executor = executor\n    self._tasks: dict[Future[Any], _Task[Any, Any]] = {}\n</code></pre>"},{"location":"api/executor/utils/#taps.executor.utils.FutureDependencyExecutor.submit","title":"submit()","text":"<pre><code>submit(\n    function: Callable[P, T],\n    /,\n    *args: args,\n    **kwargs: kwargs,\n) -&gt; Future[T]\n</code></pre> <p>Schedule the callable to be executed.</p> <p>Parameters:</p> <ul> <li> <code>function</code>             (<code>Callable[P, T]</code>)         \u2013          <p>Callable to execute.</p> </li> <li> <code>args</code>             (<code>args</code>, default:                 <code>()</code> )         \u2013          <p>Positional arguments.</p> </li> <li> <code>kwargs</code>             (<code>kwargs</code>, default:                 <code>{}</code> )         \u2013          <p>Keyword arguments.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Future[T]</code>         \u2013          <p><code>Future</code> object representing the             result of the execution of the callable.</p> </li> </ul> Source code in <code>taps/executor/utils.py</code> <pre><code>def submit(\n    self,\n    function: Callable[P, T],\n    /,\n    *args: P.args,\n    **kwargs: P.kwargs,\n) -&gt; Future[T]:\n    \"\"\"Schedule the callable to be executed.\n\n    Args:\n        function: Callable to execute.\n        args: Positional arguments.\n        kwargs: Keyword arguments.\n\n    Returns:\n        [`Future`][concurrent.futures.Future] object representing the \\\n        result of the execution of the callable.\n    \"\"\"\n    client_future: Future[T] = Future()\n    task = _Task(self.executor, function, args, kwargs, client_future)\n    self._tasks[client_future] = task\n    client_future.add_done_callback(self._task_future_callback)\n    return client_future\n</code></pre>"},{"location":"api/executor/utils/#taps.executor.utils.FutureDependencyExecutor.map","title":"map()","text":"<pre><code>map(\n    function: Callable[P, T],\n    *iterables: Iterable[args],\n    timeout: float | None = None,\n    chunksize: int = 1\n) -&gt; Iterator[T]\n</code></pre> <p>Map a function onto iterables of arguments.</p> <p>Parameters:</p> <ul> <li> <code>function</code>             (<code>Callable[P, T]</code>)         \u2013          <p>A callable that will take as many arguments as there are passed iterables.</p> </li> <li> <code>iterables</code>             (<code>Iterable[args]</code>, default:                 <code>()</code> )         \u2013          <p>Variable number of iterables.</p> </li> <li> <code>timeout</code>             (<code>float | None</code>, default:                 <code>None</code> )         \u2013          <p>The maximum number of seconds to wait. If None, then there is no limit on the wait time.</p> </li> <li> <code>chunksize</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>If greater than one, the iterables will be chopped into chunks of size chunksize and submitted to the executor. If set to one, the items in the list will be sent one at a time.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Iterator[T]</code>         \u2013          <p>An iterator equivalent to: <code>map(func, *iterables)</code> but the calls             may be evaluated out-of-order.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013          <p>if chunksize is less than one.</p> </li> </ul> Source code in <code>taps/executor/utils.py</code> <pre><code>def map(\n    self,\n    function: Callable[P, T],\n    *iterables: Iterable[P.args],\n    timeout: float | None = None,\n    chunksize: int = 1,\n) -&gt; Iterator[T]:\n    \"\"\"Map a function onto iterables of arguments.\n\n    Args:\n        function: A callable that will take as many arguments as there are\n            passed iterables.\n        iterables: Variable number of iterables.\n        timeout: The maximum number of seconds to wait. If None, then there\n            is no limit on the wait time.\n        chunksize: If greater than one, the iterables will be chopped into\n            chunks of size chunksize and submitted to the executor. If set\n            to one, the items in the list will be sent one at a time.\n\n    Returns:\n        An iterator equivalent to: `map(func, *iterables)` but the calls \\\n        may be evaluated out-of-order.\n\n    Raises:\n        ValueError: if chunksize is less than one.\n    \"\"\"\n    # Based on concurrent.futures.ProcessPoolExecutor.map()\n    # https://github.com/python/cpython/blob/37959e25cbbe1d207c660b5bc9583b9bd1403f1a/Lib/concurrent/futures/process.py\n    if chunksize &lt; 1:\n        raise ValueError('chunksize must be &gt;= 1.')\n\n    results = super().map(\n        functools.partial(_process_chunk, function),\n        _get_chunks(*iterables, chunksize=chunksize),\n        timeout=timeout,\n    )\n\n    def _result_iterator(\n        iterable: Iterator[list[T]],\n    ) -&gt; Generator[T, None, None]:\n        for element in iterable:\n            element.reverse()\n            while element:\n                yield element.pop()\n\n    return _result_iterator(results)\n</code></pre>"},{"location":"api/executor/utils/#taps.executor.utils.FutureDependencyExecutor.shutdown","title":"shutdown()","text":"<pre><code>shutdown(\n    wait: bool = True, *, cancel_futures: bool = False\n) -&gt; None\n</code></pre> <p>Shutdown the executor.</p> <p>Parameters:</p> <ul> <li> <code>wait</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Wait on all pending futures to complete.</p> </li> <li> <code>cancel_futures</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Cancel all pending futures that the executor has not started running. Only used in Python 3.9 and later.</p> </li> </ul> Source code in <code>taps/executor/utils.py</code> <pre><code>def shutdown(\n    self,\n    wait: bool = True,\n    *,\n    cancel_futures: bool = False,\n) -&gt; None:\n    \"\"\"Shutdown the executor.\n\n    Args:\n        wait: Wait on all pending futures to complete.\n        cancel_futures: Cancel all pending futures that the executor\n            has not started running. Only used in Python 3.9 and later.\n    \"\"\"\n    if sys.version_info &gt;= (3, 9):  # pragma: &gt;=3.9 cover\n        self.executor.shutdown(wait=wait, cancel_futures=cancel_futures)\n    else:  # pragma: &lt;3.9 cover\n        self.executor.shutdown(wait=wait)\n</code></pre>"},{"location":"api/filter/","title":"taps.filter","text":"<code>taps/filter/__init__.py</code>"},{"location":"api/filter/config/","title":"taps.filter.config","text":"<code>taps/filter/config.py</code>"},{"location":"api/filter/config/#taps.filter.config.FilterConfig","title":"FilterConfig","text":"<p>             Bases: <code>BaseModel</code>, <code>ABC</code></p> <p>Abstract filter configuration.</p>"},{"location":"api/filter/config/#taps.filter.config.FilterConfig.get_filter","title":"get_filter()  <code>abstractmethod</code>","text":"<pre><code>get_filter() -&gt; Filter\n</code></pre> <p>Create a filter from the configuration.</p> Source code in <code>taps/filter/config.py</code> <pre><code>@abc.abstractmethod\ndef get_filter(self) -&gt; Filter:\n    \"\"\"Create a filter from the configuration.\"\"\"\n    ...\n</code></pre>"},{"location":"api/filter/config/#taps.filter.config.NullFilterConfig","title":"NullFilterConfig","text":"<p>             Bases: <code>FilterConfig</code></p> <p>Null filter configuration.</p>"},{"location":"api/filter/config/#taps.filter.config.NullFilterConfig.get_filter","title":"get_filter()","text":"<pre><code>get_filter() -&gt; Filter\n</code></pre> <p>Create a filter from the configuration.</p> Source code in <code>taps/filter/config.py</code> <pre><code>def get_filter(self) -&gt; Filter:\n    \"\"\"Create a filter from the configuration.\"\"\"\n    return NullFilter()\n</code></pre>"},{"location":"api/filter/config/#taps.filter.config.ObjectSizeConfig","title":"ObjectSizeConfig","text":"<p>             Bases: <code>FilterConfig</code></p> <p>Object size filter configuration.</p>"},{"location":"api/filter/config/#taps.filter.config.ObjectSizeConfig.get_filter","title":"get_filter()","text":"<pre><code>get_filter() -&gt; Filter\n</code></pre> <p>Create a filter from the configuration.</p> Source code in <code>taps/filter/config.py</code> <pre><code>def get_filter(self) -&gt; Filter:\n    \"\"\"Create a filter from the configuration.\"\"\"\n    return ObjectSizeFilter(\n        min_bytes=self.min_size,\n        max_bytes=self.max_size,\n    )\n</code></pre>"},{"location":"api/filter/config/#taps.filter.config.PickleSizeConfig","title":"PickleSizeConfig","text":"<p>             Bases: <code>FilterConfig</code></p> <p>Pickled object size filter configuration.</p>"},{"location":"api/filter/config/#taps.filter.config.PickleSizeConfig.get_filter","title":"get_filter()","text":"<pre><code>get_filter() -&gt; Filter\n</code></pre> <p>Create a filter from the configuration.</p> Source code in <code>taps/filter/config.py</code> <pre><code>def get_filter(self) -&gt; Filter:\n    \"\"\"Create a filter from the configuration.\"\"\"\n    return PickleSizeFilter(\n        min_bytes=self.min_size,\n        max_bytes=self.max_size,\n    )\n</code></pre>"},{"location":"api/filter/filters/","title":"taps.filter.filters","text":"<code>taps/filter/filters.py</code>"},{"location":"api/filter/filters/#taps.filter.filters.Filter","title":"Filter","text":"<p>             Bases: <code>Protocol</code></p> <p>Filter protocol.</p>"},{"location":"api/filter/filters/#taps.filter.filters.Filter.__call__","title":"__call__()","text":"<pre><code>__call__(obj: Any) -&gt; bool\n</code></pre> <p>Check if an abject passes through the filter.</p> Source code in <code>taps/filter/filters.py</code> <pre><code>def __call__(self, obj: Any) -&gt; bool:\n    \"\"\"Check if an abject passes through the filter.\"\"\"\n    ...\n</code></pre>"},{"location":"api/filter/filters/#taps.filter.filters.NullFilter","title":"NullFilter","text":"<p>Null filter that lets all objects pass through.</p>"},{"location":"api/filter/filters/#taps.filter.filters.NullFilter.__call__","title":"__call__()","text":"<pre><code>__call__(obj: Any) -&gt; bool\n</code></pre> <p>Check if an object passes through the filter.</p> Source code in <code>taps/filter/filters.py</code> <pre><code>def __call__(self, obj: Any) -&gt; bool:\n    \"\"\"Check if an object passes through the filter.\"\"\"\n    return True\n</code></pre>"},{"location":"api/filter/filters/#taps.filter.filters.ObjectSizeFilter","title":"ObjectSizeFilter","text":"<pre><code>ObjectSizeFilter(\n    *, min_bytes: int = 0, max_bytes: float = math.inf\n)\n</code></pre> <p>Object size filter.</p> <p>Checks if the size of an object (computed using <code>sys.getsizeof()</code>) is greater than a minimum size and less than a maximum size.</p> Warning <p><code>sys.getsizeof()</code> does not count the size of objects referred to by the main object.</p> <p>Parameters:</p> <ul> <li> <code>min_bytes</code>             (<code>int</code>, default:                 <code>0</code> )         \u2013          <p>Minimum size threshold (inclusive) to pass through the filter.</p> </li> <li> <code>max_bytes</code>             (<code>float</code>, default:                 <code>inf</code> )         \u2013          <p>Maximum size threshold (inclusive) to pass through the filter.</p> </li> </ul> Source code in <code>taps/filter/filters.py</code> <pre><code>def __init__(\n    self,\n    *,\n    min_bytes: int = 0,\n    max_bytes: float = math.inf,\n) -&gt; None:\n    self.min_bytes = min_bytes\n    self.max_bytes = max_bytes\n</code></pre>"},{"location":"api/filter/filters/#taps.filter.filters.ObjectSizeFilter.__call__","title":"__call__()","text":"<pre><code>__call__(obj: Any) -&gt; bool\n</code></pre> <p>Check if an object passes through the filter.</p> Source code in <code>taps/filter/filters.py</code> <pre><code>def __call__(self, obj: Any) -&gt; bool:\n    \"\"\"Check if an object passes through the filter.\"\"\"\n    size = sys.getsizeof(obj)\n    return self.min_bytes &lt;= size &lt;= self.max_bytes\n</code></pre>"},{"location":"api/filter/filters/#taps.filter.filters.ObjectTypeFilter","title":"ObjectTypeFilter","text":"<pre><code>ObjectTypeFilter(*types: type)\n</code></pre> <p>Object type filter.</p> <p>Checks if an object is of a certain type.</p> <p>Parameters:</p> <ul> <li> <code>types</code>             (<code>type</code>, default:                 <code>()</code> )         \u2013          <p>Types to check.</p> </li> </ul> Source code in <code>taps/filter/filters.py</code> <pre><code>def __init__(self, *types: type) -&gt; None:\n    self.types = types\n</code></pre>"},{"location":"api/filter/filters/#taps.filter.filters.ObjectTypeFilter.__call__","title":"__call__()","text":"<pre><code>__call__(obj: Any) -&gt; bool\n</code></pre> <p>Check if an object passes through the filter.</p> Source code in <code>taps/filter/filters.py</code> <pre><code>def __call__(self, obj: Any) -&gt; bool:\n    \"\"\"Check if an object passes through the filter.\"\"\"\n    return isinstance(obj, self.types)\n</code></pre>"},{"location":"api/filter/filters/#taps.filter.filters.PickleSizeFilter","title":"PickleSizeFilter","text":"<pre><code>PickleSizeFilter(\n    *, min_bytes: int = 0, max_bytes: float = math.inf\n)\n</code></pre> <p>Object size filter.</p> <p>Checks if the size of an object (computed using size of the pickled object) is greater than a minimum size and less than a maximum size.</p> Warning <p>Pickling large objects can take significant time.</p> <p>Parameters:</p> <ul> <li> <code>min_bytes</code>             (<code>int</code>, default:                 <code>0</code> )         \u2013          <p>Minimum size threshold (inclusive) to pass through the filter.</p> </li> <li> <code>max_bytes</code>             (<code>float</code>, default:                 <code>inf</code> )         \u2013          <p>Maximum size threshold (inclusive) to pass through the filter.</p> </li> </ul> Source code in <code>taps/filter/filters.py</code> <pre><code>def __init__(\n    self,\n    *,\n    min_bytes: int = 0,\n    max_bytes: float = math.inf,\n) -&gt; None:\n    self.min_bytes = min_bytes\n    self.max_bytes = max_bytes\n</code></pre>"},{"location":"api/filter/filters/#taps.filter.filters.PickleSizeFilter.__call__","title":"__call__()","text":"<pre><code>__call__(obj: Any) -&gt; bool\n</code></pre> <p>Check if an object passes through the filter.</p> Source code in <code>taps/filter/filters.py</code> <pre><code>def __call__(self, obj: Any) -&gt; bool:\n    \"\"\"Check if an object passes through the filter.\"\"\"\n    size = len(pickle.dumps(obj))\n    return self.min_bytes &lt;= size &lt;= self.max_bytes\n</code></pre>"},{"location":"api/run/","title":"taps.run","text":"<code>taps/run/__init__.py</code>"},{"location":"api/run/config/","title":"taps.run.config","text":"<code>taps/run/config.py</code>"},{"location":"api/run/config/#taps.run.config.LoggingConfig","title":"LoggingConfig","text":"<p>             Bases: <code>BaseModel</code></p> <p>Logging configuration.</p> <p>Attributes:</p> <ul> <li> <code>level</code>             (<code>Union[int, str]</code>)         \u2013          <p>Logging level for <code>stdout</code>.</p> </li> <li> <code>file_level</code>             (<code>Union[int, str]</code>)         \u2013          <p>Logging level for the log file.</p> </li> <li> <code>file_name</code>             (<code>Optional[str]</code>)         \u2013          <p>Logging file name. If <code>None</code>, only logging to <code>stdout</code> is used.</p> </li> </ul>"},{"location":"api/run/config/#taps.run.config.RunConfig","title":"RunConfig","text":"<p>             Bases: <code>BaseModel</code></p> <p>Run configuration.</p> <p>Attributes:</p> <ul> <li> <code>dir_format</code>             (<code>str</code>)         \u2013          <p>Run directory format.</p> </li> </ul>"},{"location":"api/run/config/#taps.run.config.Config","title":"Config","text":"<p>             Bases: <code>BaseSettings</code></p> <p>Application benchmark configuration.</p> <p>Attributes:</p> <ul> <li> <code>app</code>             (<code>AppConfig</code>)         \u2013          <p>Application configuration.</p> </li> <li> <code>engine</code>             (<code>EngineConfig</code>)         \u2013          <p>Engine configuration.</p> </li> <li> <code>logging</code>             (<code>LoggingConfig</code>)         \u2013          <p>Logging configuration.</p> </li> <li> <code>run</code>             (<code>RunConfig</code>)         \u2013          <p>Run configuration.</p> </li> </ul>"},{"location":"api/run/config/#taps.run.config.Config.from_toml","title":"from_toml()  <code>classmethod</code>","text":"<pre><code>from_toml(filepath: str | Path) -&gt; Self\n</code></pre> <p>Load a configuration from a TOML file.</p> Source code in <code>taps/run/config.py</code> <pre><code>@classmethod\ndef from_toml(cls, filepath: str | pathlib.Path) -&gt; Self:\n    \"\"\"Load a configuration from a TOML file.\"\"\"\n    with open(filepath, 'rb') as f:\n        options = tomllib.load(f)\n\n    flat_options = flatten_mapping(options)\n    config_cls = _make_config_cls(flat_options)\n\n    return config_cls(**options)\n</code></pre>"},{"location":"api/run/config/#taps.run.config.Config.write_toml","title":"write_toml()","text":"<pre><code>write_toml(filepath: str | Path) -&gt; None\n</code></pre> <p>Write the configuration to a TOML file.</p> Source code in <code>taps/run/config.py</code> <pre><code>def write_toml(self, filepath: str | pathlib.Path) -&gt; None:\n    \"\"\"Write the configuration to a TOML file.\"\"\"\n    model = self.model_dump(\n        exclude_unset=False,\n        exclude_defaults=False,\n        exclude_none=True,\n    )\n\n    filepath = pathlib.Path(filepath)\n    filepath.parent.mkdir(parents=True, exist_ok=True)\n    with open(filepath, 'wb') as f:\n        tomli_w.dump(model, f)\n</code></pre>"},{"location":"api/run/config/#taps.run.config.make_run_dir","title":"make_run_dir()","text":"<pre><code>make_run_dir(config: Config) -&gt; Path\n</code></pre> <p>Create and return the run directory path created from the config.</p> Source code in <code>taps/run/config.py</code> <pre><code>def make_run_dir(config: Config) -&gt; pathlib.Path:\n    \"\"\"Create and return the run directory path created from the config.\"\"\"\n    timestamp = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n    run_dir = pathlib.Path(\n        config.run.dir_format.format(\n            executor=config.engine.executor.name,\n            name=config.app.name,\n            timestamp=timestamp,\n        ),\n    )\n    run_dir.mkdir(parents=True, exist_ok=True)\n    return run_dir\n</code></pre>"},{"location":"api/run/main/","title":"taps.run.main","text":"<code>taps/run/main.py</code>"},{"location":"api/run/main/#taps.run.main.run","title":"run()","text":"<pre><code>run(config: Config, run_dir: Path) -&gt; None\n</code></pre> <p>Run an application using the configuration.</p> <p>This function changes the current working directory to <code>config.run.run_dir</code> so that all paths are relative to the current working directory.</p> Source code in <code>taps/run/main.py</code> <pre><code>@_cwd_run_dir\ndef run(config: Config, run_dir: pathlib.Path) -&gt; None:\n    \"\"\"Run an application using the configuration.\n\n    This function changes the current working directory to\n    `config.run.run_dir` so that all paths are relative to the current\n    working directory.\n    \"\"\"\n    start = time.perf_counter()\n\n    logger.log(RUN_LOG_LEVEL, f'Starting app (name={config.app.name})')\n    logger.log(\n        RUN_LOG_LEVEL,\n        f'Configuration:\\n{prettify_mapping(config.model_dump())}',\n    )\n    logger.log(RUN_LOG_LEVEL, f'Runtime directory: {run_dir}')\n\n    config.write_toml('config.toml')\n\n    app = config.app.get_app()\n    engine = config.engine.get_engine()\n\n    with contextlib.closing(app), engine:\n        app.run(engine=engine, run_dir=run_dir)\n\n    runtime = time.perf_counter() - start\n    logger.log(\n        RUN_LOG_LEVEL,\n        f'Finished app (name={config.app.name}, '\n        f'runtime={runtime:.2f}s, tasks={engine.tasks_executed})',\n    )\n</code></pre>"},{"location":"api/run/parse/","title":"taps.run.parse","text":"<code>taps/run/parse.py</code>"},{"location":"api/run/parse/#taps.run.parse.parse_args_to_config","title":"parse_args_to_config()","text":"<pre><code>parse_args_to_config(argv: Sequence[str]) -&gt; Config\n</code></pre> <p>Construct an argument parser and parse string arguments to a config.</p> <p>Parameters:</p> <ul> <li> <code>argv</code>             (<code>Sequence[str]</code>)         \u2013          <p>Sequence of string arguments.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Config</code>         \u2013          <p>Configuration.</p> </li> </ul> Source code in <code>taps/run/parse.py</code> <pre><code>def parse_args_to_config(argv: Sequence[str]) -&gt; Config:\n    \"\"\"Construct an argument parser and parse string arguments to a config.\n\n    Args:\n        argv: Sequence of string arguments.\n\n    Returns:\n        Configuration.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        description=\"\"\"\\\nTask Performance Suite (TaPS) CLI.\n\nApplication benchmarks can be configured via CLI options, a TOML\nconfiguration file, or a mix of both. CLI options take precedence\nover configuration files.\n\nThe default behavior of -h/--help is to show only the minimally\nrelevant set of options. For example, only the process-pool\nexecutor options will be shown if --engine.executor process-pool\nis specified; the options for other executors will be suppressed.\nThis behavior applies to all plugin types.\n\"\"\",\n        prog='python -m taps.run',\n        formatter_class=_ArgparseFormatter,\n    )\n    parser.add_argument(\n        '--config',\n        '-c',\n        default=argparse.SUPPRESS,\n        help='base toml configuration file to load',\n    )\n\n    app_group = parser.add_argument_group('app options')\n    app_group.add_argument(\n        '--app',\n        choices=list(get_app_configs().keys()),\n        dest='app.name',\n        metavar='APP',\n        help='app choice {%(choices)s}',\n    )\n\n    engine_group = parser.add_argument_group('engine options')\n    engine_group.add_argument(\n        '--engine.executor',\n        '--executor',\n        choices=list(get_executor_configs().keys()),\n        default=argparse.SUPPRESS,\n        dest='engine.executor.name',\n        metavar='EXECUTOR',\n        help='executor choice {%(choices)s} (default: process-pool)',\n    )\n    engine_group.add_argument(\n        '--engine.filter',\n        '--filter',\n        choices=list(get_filter_configs().keys()),\n        default=argparse.SUPPRESS,\n        dest='engine.filter.name',\n        metavar='FILTER',\n        help='filter choice {%(choices)s} (default: null)',\n    )\n    engine_group.add_argument(\n        '--engine.transformer',\n        '--transformer',\n        choices=list(get_transformer_configs().keys()),\n        default=argparse.SUPPRESS,\n        dest='engine.transformer.name',\n        metavar='TRANSFORMER',\n        help='transformer choice {%(choices)s} (default: null)',\n    )\n\n    if len(argv) == 0 or argv[0] in ['-h', '--help']:\n        # Shortcut to print help output if no args or just -h/--help\n        # are provided.\n        parser.parse_args(['--help'])  # pragma: no cover\n\n    # Strip --help from argv so we can quickly parse the base options\n    # to figure out which config types we will need to use. --help\n    # will be parsed again by CliSettingsSource.\n    _argv = list(filter(lambda v: v not in ['-h', '--help'], argv))\n    base_options = vars(parser.parse_known_args(_argv)[0])\n    base_options = {k: v for k, v in base_options.items() if v is not None}\n    config_file = base_options.pop('config', None)\n    toml_options = flatten_mapping(_parse_toml_options(config_file))\n\n    # base_options takes precedence over toml_options if there are\n    # matching keys.\n    base_options = {**toml_options, **base_options}\n    if 'app.name' not in base_options or base_options['app.name'] is None:\n        raise ValueError(\n            'App name option is required. Either pass --app {APP} via the'\n            'CLI arguments or add the app.name attribute to the config '\n            'file with --config {PATH}.',\n        )\n\n    app_group.description = f'selected app: {base_options[\"app.name\"]}'\n\n    settings_cls = _make_config_cls(base_options)\n    base_namespace = argparse.Namespace(**base_options)\n\n    cli_settings = CliSettingsSource(\n        settings_cls,\n        cli_avoid_json=True,\n        cli_parse_args=argv,\n        cli_parse_none_str='none',\n        cli_use_class_docs_for_groups=False,\n        root_parser=parser,\n        add_argument_method=_add_argument,\n        add_argument_group_method=_add_argument_group,\n        parse_args_method=functools.partial(\n            argparse.ArgumentParser.parse_args,\n            namespace=base_namespace,\n        ),\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n    )\n\n    return settings_cls(_cli_settings_source=cli_settings)\n</code></pre>"},{"location":"api/run/utils/","title":"taps.run.utils","text":"<code>taps/run/utils.py</code>"},{"location":"api/run/utils/#taps.run.utils.flatten_mapping","title":"flatten_mapping()","text":"<pre><code>flatten_mapping(\n    mapping: MutableMapping[str, Any],\n    parent_key: str = \"\",\n    separator: str = \".\",\n) -&gt; dict[str, Any]\n</code></pre> <p>Flatten the keys of nested mappings/dicts.</p> <p>Parameters:</p> <ul> <li> <code>mapping</code>             (<code>MutableMapping[str, Any]</code>)         \u2013          <p>Nested mapping to flatten.</p> </li> <li> <code>parent_key</code>             (<code>str</code>, default:                 <code>''</code> )         \u2013          <p>Prefix of parent keys when this function is called recursively.</p> </li> <li> <code>separator</code>             (<code>str</code>, default:                 <code>'.'</code> )         \u2013          <p>Separator between key parts.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict[str, Any]</code>         \u2013          <p>Flattened dictionary.</p> </li> </ul> Source code in <code>taps/run/utils.py</code> <pre><code>def flatten_mapping(\n    mapping: MutableMapping[str, Any],\n    parent_key: str = '',\n    separator: str = '.',\n) -&gt; dict[str, Any]:\n    \"\"\"Flatten the keys of nested mappings/dicts.\n\n    Args:\n        mapping: Nested mapping to flatten.\n        parent_key: Prefix of parent keys when this function is called\n            recursively.\n        separator: Separator between key parts.\n\n    Returns:\n        Flattened dictionary.\n    \"\"\"\n    items: list[tuple[str, Any]] = []\n\n    for key, value in mapping.items():\n        new_key = parent_key + separator + key if parent_key else key\n        if isinstance(value, MutableMapping):\n            items.extend(\n                flatten_mapping(value, new_key, separator=separator).items(),\n            )\n        else:\n            items.append((new_key, value))\n    return dict(items)\n</code></pre>"},{"location":"api/run/utils/#taps.run.utils.prettify_mapping","title":"prettify_mapping()","text":"<pre><code>prettify_mapping(\n    mapping: Mapping[str, Any],\n    level: int = 0,\n    indent: int = 2,\n) -&gt; str\n</code></pre> <p>Turn a mapping into a nicely formatted string.</p> Example <pre><code>&gt;&gt;&gt; from taps.run.utils import prettify_mapping\n&gt;&gt;&gt; data = {'a': {'b': [1, 2, 3], 'name': 'foo'}, 'c': 'baz', 'b': 'bar'}\n&gt;&gt;&gt; print(prettify_mapping(data))\na:\n  name: 'foo'\n  b: [1, 2, 3]\nb: 'bar'\nc: 'baz'\n</code></pre> Source code in <code>taps/run/utils.py</code> <pre><code>def prettify_mapping(\n    mapping: Mapping[str, Any],\n    level: int = 0,\n    indent: int = 2,\n) -&gt; str:\n    \"\"\"Turn a mapping into a nicely formatted string.\n\n    Example:\n        ```python\n        &gt;&gt;&gt; from taps.run.utils import prettify_mapping\n        &gt;&gt;&gt; data = {'a': {'b': [1, 2, 3], 'name': 'foo'}, 'c': 'baz', 'b': 'bar'}\n        &gt;&gt;&gt; print(prettify_mapping(data))\n        a:\n          name: 'foo'\n          b: [1, 2, 3]\n        b: 'bar'\n        c: 'baz'\n        ```\n    \"\"\"  # noqa: E501\n    lines: list[str] = []\n    space = ' ' * indent * level\n\n    keys = sorted(mapping.keys())\n\n    # Move the 'name' key to the front\n    if 'name' in keys:\n        keys.remove('name')\n        keys = ['name', *keys]\n\n    for key in keys:\n        value = mapping[key]\n\n        if isinstance(value, Mapping):\n            lines.append(f'{space}{key}:')\n            lines.append(prettify_mapping(value, level + 1, indent))\n        else:\n            lines.append(f'{space}{key}: {value!r}')\n\n    return '\\n'.join(lines)\n</code></pre>"},{"location":"api/run/utils/#taps.run.utils.prettify_validation_error","title":"prettify_validation_error()","text":"<pre><code>prettify_validation_error(\n    error: ValidationError,\n    model: type[BaseModel] | None = None,\n) -&gt; ValueError\n</code></pre> <p>Parse a Pydantic validation error into a ValueError.</p> <p>Given a <code>ValidationError</code>, <pre><code>pydantic_core._pydantic_core.ValidationError: 2 validation errors for GeneratedConfig\napp.matrix_size\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='100x', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.7/v/int_parsing\nengine.executor.max_threads\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='1.5', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.7/v/int_parsing\n</code></pre> returns a <code>ValueError</code> with a more readable output. <pre><code>ValueError: Found 2 validation errors:\n  - Input should be a valid integer, unable to parse string as an integer\n    Attribute: app.matrix_size\n    Input (str): '100x'\n    Error type: int_parsing (https://errors.pydantic.dev/2.7/v/int_parsing)\n  - Input should be a valid integer, unable to parse string as an integer\n    Attribute: engine.executor.max_threads\n    Input (str): '1.5'\n    Error type: int_parsing (https://errors.pydantic.dev/2.7/v/int_parsing)\n</code></pre></p> Source code in <code>taps/run/utils.py</code> <pre><code>def prettify_validation_error(\n    error: ValidationError,\n    model: type[BaseModel] | None = None,\n) -&gt; ValueError:\n    \"\"\"Parse a Pydantic validation error into a ValueError.\n\n    Given a [`ValidationError`][pydantic_core.ValidationError],\n    ```\n    pydantic_core._pydantic_core.ValidationError: 2 validation errors for GeneratedConfig\n    app.matrix_size\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='100x', input_type=str]\n        For further information visit https://errors.pydantic.dev/2.7/v/int_parsing\n    engine.executor.max_threads\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='1.5', input_type=str]\n        For further information visit https://errors.pydantic.dev/2.7/v/int_parsing\n    ```\n    returns a [`ValueError`][ValueError] with a more readable output.\n    ```\n    ValueError: Found 2 validation errors:\n      - Input should be a valid integer, unable to parse string as an integer\n        Attribute: app.matrix_size\n        Input (str): '100x'\n        Error type: int_parsing (https://errors.pydantic.dev/2.7/v/int_parsing)\n      - Input should be a valid integer, unable to parse string as an integer\n        Attribute: engine.executor.max_threads\n        Input (str): '1.5'\n        Error type: int_parsing (https://errors.pydantic.dev/2.7/v/int_parsing)\n    ```\n    \"\"\"  # noqa: E501\n    errors: list[str] = []\n\n    for e in error.errors():\n        attribute = '.'.join(str(v) for v in e['loc'])\n        input_ = e['input']\n        message = e['msg']\n        type_ = e['type']\n        url = e.get(\n            'url',\n            'https://docs.pydantic.dev/latest/errors/validation_errors/',\n        )\n\n        errors.append(f\"\"\"\\\n  - {message}\n    Attribute: {attribute}\n    Input ({type(input_).__name__}): {input_!r}\n    Error type: {type_} ({url})\\\n\"\"\")\n\n    errors_str = '\\n'.join(errors)\n    count = error.error_count()\n\n    if model is not None:\n        model_str = f' for {model.__module__}.{model.__name__}'\n    else:\n        model_str = ''\n\n    return ValueError(f\"\"\"\\\nFound {count} validation error{\"\" if count == 1 else \"s\"}{model_str}\n{errors_str}\\\n\"\"\")\n</code></pre>"},{"location":"api/transformer/","title":"taps.transformer","text":"<code>taps/transformer/__init__.py</code>"},{"location":"api/transformer/config/","title":"taps.transformer.config","text":"<code>taps/transformer/config.py</code>"},{"location":"api/transformer/config/#taps.transformer.config.TransformerConfig","title":"TransformerConfig","text":"<p>             Bases: <code>BaseModel</code>, <code>ABC</code></p> <p>Abstract transformer configuration.</p>"},{"location":"api/transformer/config/#taps.transformer.config.TransformerConfig.get_transformer","title":"get_transformer()  <code>abstractmethod</code>","text":"<pre><code>get_transformer() -&gt; Transformer[Any]\n</code></pre> <p>Create a transformer from the configuration.</p> Source code in <code>taps/transformer/config.py</code> <pre><code>@abc.abstractmethod\ndef get_transformer(self) -&gt; Transformer[Any]:\n    \"\"\"Create a transformer from the configuration.\"\"\"\n    ...\n</code></pre>"},{"location":"api/transformer/file/","title":"taps.transformer.file","text":"<code>taps/transformer/file.py</code>"},{"location":"api/transformer/file/#taps.transformer.file.PickleFileTransformerConfig","title":"PickleFileTransformerConfig","text":"<p>             Bases: <code>TransformerConfig</code></p> <p>Pickle file transformer configuration.</p>"},{"location":"api/transformer/file/#taps.transformer.file.PickleFileTransformerConfig.get_transformer","title":"get_transformer()","text":"<pre><code>get_transformer() -&gt; PickleFileTransformer\n</code></pre> <p>Create a transformer from the configuration.</p> Source code in <code>taps/transformer/file.py</code> <pre><code>def get_transformer(self) -&gt; PickleFileTransformer:\n    \"\"\"Create a transformer from the configuration.\"\"\"\n    return PickleFileTransformer(self.file_dir)\n</code></pre>"},{"location":"api/transformer/file/#taps.transformer.file.Identifier","title":"Identifier","text":"<p>             Bases: <code>NamedTuple</code></p> <p>Object identifier.</p> <p>Attributes:</p> <ul> <li> <code>cache_dir</code>             (<code>Path</code>)         \u2013          <p>Object directory.</p> </li> <li> <code>obj_id</code>             (<code>UUID</code>)         \u2013          <p>Object ID.</p> </li> </ul>"},{"location":"api/transformer/file/#taps.transformer.file.Identifier.path","title":"path()","text":"<pre><code>path() -&gt; Path\n</code></pre> <p>Get path to the object.</p> Source code in <code>taps/transformer/file.py</code> <pre><code>def path(self) -&gt; pathlib.Path:\n    \"\"\"Get path to the object.\"\"\"\n    return self.cache_dir / str(self.obj_id)\n</code></pre>"},{"location":"api/transformer/file/#taps.transformer.file.PickleFileTransformer","title":"PickleFileTransformer","text":"<pre><code>PickleFileTransformer(cache_dir: Path | str)\n</code></pre> <p>Pickle file object transformer.</p> <p>Parameters:</p> <ul> <li> <code>cache_dir</code>             (<code>Path | str</code>)         \u2013          <p>Directory to store pickled objects in.</p> </li> </ul> Source code in <code>taps/transformer/file.py</code> <pre><code>def __init__(\n    self,\n    cache_dir: pathlib.Path | str,\n) -&gt; None:\n    self.cache_dir = pathlib.Path(cache_dir).resolve()\n</code></pre>"},{"location":"api/transformer/file/#taps.transformer.file.PickleFileTransformer.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the transformer.</p> Source code in <code>taps/transformer/file.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close the transformer.\"\"\"\n    shutil.rmtree(self.cache_dir, ignore_errors=True)\n</code></pre>"},{"location":"api/transformer/file/#taps.transformer.file.PickleFileTransformer.is_identifier","title":"is_identifier()","text":"<pre><code>is_identifier(obj: Any) -&gt; bool\n</code></pre> <p>Check if the object is an identifier instance.</p> Source code in <code>taps/transformer/file.py</code> <pre><code>def is_identifier(self, obj: Any) -&gt; bool:\n    \"\"\"Check if the object is an identifier instance.\"\"\"\n    return isinstance(obj, Identifier)\n</code></pre>"},{"location":"api/transformer/file/#taps.transformer.file.PickleFileTransformer.transform","title":"transform()","text":"<pre><code>transform(obj: T) -&gt; Identifier\n</code></pre> <p>Transform the object into an identifier.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>T</code>)         \u2013          <p>Object to transform.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Identifier</code>         \u2013          <p>Identifier object that can be used to resolve <code>obj</code>.</p> </li> </ul> Source code in <code>taps/transformer/file.py</code> <pre><code>def transform(self, obj: T) -&gt; Identifier:\n    \"\"\"Transform the object into an identifier.\n\n    Args:\n        obj: Object to transform.\n\n    Returns:\n        Identifier object that can be used to resolve `obj`.\n    \"\"\"\n    identifier = Identifier(self.cache_dir, uuid.uuid4())\n    filepath = identifier.path()\n    filepath.parent.mkdir(parents=True, exist_ok=True)\n\n    with open(filepath, 'wb', buffering=0) as f:\n        pickle.dump(obj, f)\n\n    return identifier\n</code></pre>"},{"location":"api/transformer/file/#taps.transformer.file.PickleFileTransformer.resolve","title":"resolve()","text":"<pre><code>resolve(identifier: Identifier) -&gt; Any\n</code></pre> <p>Resolve an object from an identifier.</p> <p>Parameters:</p> <ul> <li> <code>identifier</code>             (<code>Identifier</code>)         \u2013          <p>Identifier to an object.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Any</code>         \u2013          <p>The resolved object.</p> </li> </ul> Source code in <code>taps/transformer/file.py</code> <pre><code>def resolve(self, identifier: Identifier) -&gt; Any:\n    \"\"\"Resolve an object from an identifier.\n\n    Args:\n        identifier: Identifier to an object.\n\n    Returns:\n        The resolved object.\n    \"\"\"\n    filepath = identifier.path()\n    with open(filepath, 'rb') as f:\n        obj = pickle.load(f)\n    return obj\n</code></pre>"},{"location":"api/transformer/null/","title":"taps.transformer.null","text":"<code>taps/transformer/null.py</code>"},{"location":"api/transformer/null/#taps.transformer.null.NullTransformerConfig","title":"NullTransformerConfig","text":"<p>             Bases: <code>TransformerConfig</code></p> <p>Null transformer configuration.</p>"},{"location":"api/transformer/null/#taps.transformer.null.NullTransformerConfig.get_transformer","title":"get_transformer()","text":"<pre><code>get_transformer() -&gt; NullTransformer\n</code></pre> <p>Create a transformer from the configuration.</p> Source code in <code>taps/transformer/null.py</code> <pre><code>def get_transformer(self) -&gt; NullTransformer:\n    \"\"\"Create a transformer from the configuration.\"\"\"\n    return NullTransformer()\n</code></pre>"},{"location":"api/transformer/null/#taps.transformer.null.NullTransformer","title":"NullTransformer","text":"<p>Null transformer that does no transformations.</p>"},{"location":"api/transformer/null/#taps.transformer.null.NullTransformer.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the transformer.</p> Source code in <code>taps/transformer/null.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close the transformer.\"\"\"\n    pass\n</code></pre>"},{"location":"api/transformer/null/#taps.transformer.null.NullTransformer.is_identifier","title":"is_identifier()","text":"<pre><code>is_identifier(obj: Any) -&gt; bool\n</code></pre> <p>Check if the object is an identifier instance.</p> <p>Always <code>False</code> in this implementation.</p> Source code in <code>taps/transformer/null.py</code> <pre><code>def is_identifier(self, obj: Any) -&gt; bool:\n    \"\"\"Check if the object is an identifier instance.\n\n    Always `False` in this implementation.\n    \"\"\"\n    return False\n</code></pre>"},{"location":"api/transformer/null/#taps.transformer.null.NullTransformer.transform","title":"transform()","text":"<pre><code>transform(obj: T) -&gt; T\n</code></pre> <p>Transform the object into an identifier.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>T</code>)         \u2013          <p>Object to transform.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>T</code>         \u2013          <p>Identifier object that can be usd to resolve <code>obj</code>.</p> </li> </ul> Source code in <code>taps/transformer/null.py</code> <pre><code>def transform(self, obj: T) -&gt; T:\n    \"\"\"Transform the object into an identifier.\n\n    Args:\n        obj: Object to transform.\n\n    Returns:\n        Identifier object that can be usd to resolve `obj`.\n    \"\"\"\n    return obj\n</code></pre>"},{"location":"api/transformer/null/#taps.transformer.null.NullTransformer.resolve","title":"resolve()","text":"<pre><code>resolve(identifier: Any) -&gt; NoReturn\n</code></pre> <p>Resolve an object from an identifier.</p> <p>Parameters:</p> <ul> <li> <code>identifier</code>             (<code>Any</code>)         \u2013          <p>Identifier to an object.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NoReturn</code>         \u2013          <p>The resolved object.</p> </li> </ul> Source code in <code>taps/transformer/null.py</code> <pre><code>def resolve(self, identifier: Any) -&gt; NoReturn:\n    \"\"\"Resolve an object from an identifier.\n\n    Args:\n        identifier: Identifier to an object.\n\n    Returns:\n        The resolved object.\n    \"\"\"\n    raise NotImplementedError(\n        f'{self.__class__.__name__} does not support identifiers',\n    )\n</code></pre>"},{"location":"api/transformer/protocol/","title":"taps.transformer.protocol","text":"<code>taps/transformer/protocol.py</code>"},{"location":"api/transformer/protocol/#taps.transformer.protocol.Transformer","title":"Transformer","text":"<p>             Bases: <code>Protocol[IdentifierT]</code></p> <p>Object transformer protocol.</p>"},{"location":"api/transformer/protocol/#taps.transformer.protocol.Transformer.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the transformer.</p> <p>The transformer is only closed by the client once the application has finished executing (or raised an exception).</p> Source code in <code>taps/transformer/protocol.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close the transformer.\n\n    The transformer is only closed by the client once the application\n    has finished executing (or raised an exception).\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/transformer/protocol/#taps.transformer.protocol.Transformer.is_identifier","title":"is_identifier()","text":"<pre><code>is_identifier(obj: T) -&gt; bool\n</code></pre> <p>Check if the object is an identifier instance.</p> Source code in <code>taps/transformer/protocol.py</code> <pre><code>def is_identifier(self, obj: T) -&gt; bool:\n    \"\"\"Check if the object is an identifier instance.\"\"\"\n    ...\n</code></pre>"},{"location":"api/transformer/protocol/#taps.transformer.protocol.Transformer.transform","title":"transform()","text":"<pre><code>transform(obj: T) -&gt; IdentifierT\n</code></pre> <p>Transform the object into an identifier.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>T</code>)         \u2013          <p>Object to transform.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>IdentifierT</code>         \u2013          <p>Identifier object that can be used to resolve <code>obj</code>.</p> </li> </ul> Source code in <code>taps/transformer/protocol.py</code> <pre><code>def transform(self, obj: T) -&gt; IdentifierT:\n    \"\"\"Transform the object into an identifier.\n\n    Args:\n        obj: Object to transform.\n\n    Returns:\n        Identifier object that can be used to resolve `obj`.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/transformer/protocol/#taps.transformer.protocol.Transformer.resolve","title":"resolve()","text":"<pre><code>resolve(identifier: IdentifierT) -&gt; Any\n</code></pre> <p>Resolve an object from an identifier.</p> <p>Parameters:</p> <ul> <li> <code>identifier</code>             (<code>IdentifierT</code>)         \u2013          <p>Identifier to an object.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Any</code>         \u2013          <p>The resolved object.</p> </li> </ul> Source code in <code>taps/transformer/protocol.py</code> <pre><code>def resolve(self, identifier: IdentifierT) -&gt; Any:\n    \"\"\"Resolve an object from an identifier.\n\n    Args:\n        identifier: Identifier to an object.\n\n    Returns:\n        The resolved object.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/transformer/proxy/","title":"taps.transformer.proxy","text":"<code>taps/transformer/proxy.py</code>"},{"location":"api/transformer/proxy/#taps.transformer.proxy.ProxyTransformerConfig","title":"ProxyTransformerConfig","text":"<p>             Bases: <code>TransformerConfig</code></p> <p>Proxy transformer configuration.</p>"},{"location":"api/transformer/proxy/#taps.transformer.proxy.ProxyTransformerConfig.get_transformer","title":"get_transformer()","text":"<pre><code>get_transformer() -&gt; ProxyTransformer\n</code></pre> <p>Create a transformer from the configuration.</p> Source code in <code>taps/transformer/proxy.py</code> <pre><code>def get_transformer(self) -&gt; ProxyTransformer:\n    \"\"\"Create a transformer from the configuration.\"\"\"\n    connector: Connector[Any]\n    if self.connector == 'file':\n        if self.file_dir is None:  # pragma: no cover\n            raise ValueError(\n                'Option file_dir is required for the file connector.',\n            )\n        connector = FileConnector(self.file_dir)\n    elif self.connector == 'redis':\n        if self.redis_addr is None:\n            raise ValueError(  # pragma: no cover\n                'Option redis_addr is required for the Redis connector.',\n            )\n        parts = self.redis_addr.split(':')\n        host, port = parts[0], int(parts[1])\n        connector = RedisConnector(host, port)\n    else:\n        raise AssertionError(\n            f'Unknown ProxyStore connector type: {self.connector}.',\n        )\n\n    return ProxyTransformer(\n        store=Store(\n            'transformer',\n            connector=connector,\n            register=True,\n            populate_target=True,\n        ),\n        extract_target=self.extract_target,\n    )\n</code></pre>"},{"location":"api/transformer/proxy/#taps.transformer.proxy.ProxyTransformer","title":"ProxyTransformer","text":"<pre><code>ProxyTransformer(\n    store: Store[Any], *, extract_target: bool = False\n)\n</code></pre> <p>Proxy object transformer.</p> <p>Transforms objects into proxies which act as the identifier.</p> <p>Parameters:</p> <ul> <li> <code>store</code>             (<code>Store[Any]</code>)         \u2013          <p>Store instance to use for proxying objects.</p> </li> <li> <code>extract_target</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>When <code>True</code>, resolving an identifier (i.e., a proxy) will return the target object. Otherwise, the proxy is returned since a proxy can act as the target object.</p> </li> </ul> Source code in <code>taps/transformer/proxy.py</code> <pre><code>def __init__(\n    self,\n    store: Store[Any],\n    *,\n    extract_target: bool = False,\n) -&gt; None:\n    self.store = store\n    self.extract_target = extract_target\n</code></pre>"},{"location":"api/transformer/proxy/#taps.transformer.proxy.ProxyTransformer.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the transformer.</p> Source code in <code>taps/transformer/proxy.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close the transformer.\"\"\"\n    self.store.close()\n</code></pre>"},{"location":"api/transformer/proxy/#taps.transformer.proxy.ProxyTransformer.is_identifier","title":"is_identifier()","text":"<pre><code>is_identifier(obj: Any) -&gt; bool\n</code></pre> <p>Check if the object is an identifier instance.</p> Source code in <code>taps/transformer/proxy.py</code> <pre><code>def is_identifier(self, obj: Any) -&gt; bool:\n    \"\"\"Check if the object is an identifier instance.\"\"\"\n    return isinstance(obj, Proxy)\n</code></pre>"},{"location":"api/transformer/proxy/#taps.transformer.proxy.ProxyTransformer.transform","title":"transform()","text":"<pre><code>transform(obj: T) -&gt; Proxy[T]\n</code></pre> <p>Transform the object into an identifier.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>T</code>)         \u2013          <p>Object to transform.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Proxy[T]</code>         \u2013          <p>Identifier object that can be used to resolve <code>obj</code>.</p> </li> </ul> Source code in <code>taps/transformer/proxy.py</code> <pre><code>def transform(self, obj: T) -&gt; Proxy[T]:\n    \"\"\"Transform the object into an identifier.\n\n    Args:\n        obj: Object to transform.\n\n    Returns:\n        Identifier object that can be used to resolve `obj`.\n    \"\"\"\n    return self.store.proxy(obj)\n</code></pre>"},{"location":"api/transformer/proxy/#taps.transformer.proxy.ProxyTransformer.resolve","title":"resolve()","text":"<pre><code>resolve(identifier: Proxy[T]) -&gt; T | Proxy[T]\n</code></pre> <p>Resolve an object from an identifier.</p> <p>Parameters:</p> <ul> <li> <code>identifier</code>             (<code>Proxy[T]</code>)         \u2013          <p>Identifier to an object.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>T | Proxy[T]</code>         \u2013          <p>The resolved object or a proxy of the resolved object depending             on the setting of <code>extract_target</code>.</p> </li> </ul> Source code in <code>taps/transformer/proxy.py</code> <pre><code>def resolve(self, identifier: Proxy[T]) -&gt; T | Proxy[T]:\n    \"\"\"Resolve an object from an identifier.\n\n    Args:\n        identifier: Identifier to an object.\n\n    Returns:\n        The resolved object or a proxy of the resolved object depending \\\n        on the setting of `extract_target`.\n    \"\"\"\n    return extract(identifier) if self.extract_target else identifier\n</code></pre>"},{"location":"apps/","title":"Applications","text":"<p>TaPS provides a diverse set of parallel and distributed applications for benchmarking. These applications, summarized below, span many domains, datasets, and structures to support comprehensive performance evaluation of existing and future systems.</p> <p></p> <p>Example task dependency diagrams of various applications provided by TaPS. In most applications, the exact structure depends on the application configuration.</p> Application Domain Task Type(s) Data Format(s) Cholesky Factorization Linear Algebra Python Functions In-memory Docking Proteins Drug Discovery Executable, Python Functions File Failure Injection N/A Any Any Federated Learning Machine Learning Python Functions In-memory MapReduce Text Analysis Python Functions File, In-memory Molecular Design Molecular Design Python Functions In-memory Montage Astronomy Executable File Synthetic N/A Python Functions In-memory <p>Check out the application specific guides for more information and instructions.</p>"},{"location":"apps/cholesky/","title":"Tiled Cholesky Decomposition","text":"<p>Computes the Cholesky decomposition of a randomly generated positive definite matrix. Based on the tiled algorithm from this paper.</p> <p>Tiled Cholesky decomposition is a canonical example of a dataflow-based workflow because of the inter-task dependencies between different tiles on the matrix. This application is also data-intensive, with task input/output sizes being \\(O(b^2)\\) where \\(b\\) is the side length of each tile.</p>"},{"location":"apps/cholesky/#installation","title":"Installation","text":"<p>This application requires numpy which can be installed automatically when installing the TaPS package. <pre><code>pip install -e .[cholesky]\n</code></pre></p>"},{"location":"apps/cholesky/#example","title":"Example","text":"<p>The following command computes the decomposition of a 10,000 x 10,000 matrix using 1000 x 1000 block/tile sizes. <pre><code>$ python -m taps.run --app cholesky --engine.executor process-pool --app.matrix-size 10000 --block-size 1000\n[2024-05-17 11:09:24.779] RUN   (taps.run) :: Starting application (name=cholesky)\n...\n[2024-05-17 11:09:24.810] APP  (taps.apps.cholesky) :: Input matrix: (10000, 10000)\n[2024-05-17 11:09:24.810] APP  (taps.apps.cholesky) :: Block size: 1000\n[2024-05-17 11:09:25.000] APP  (taps.apps.cholesky) :: Output matrix: (10000, 10000)\n[2024-05-17 11:09:25.004] RUN   (taps.run) :: Finished application (name=cholesky, runtime=33.20s, tasks=385)\n</code></pre> Here there are 100 tiles which results in 385 total tasks. Using a smaller block/tile size would increase the total number of blocks, and therefore the total number of tasks. This reduces the memory required per-task but also increases the cumulative task overheads.</p>"},{"location":"apps/docking/","title":"Protein Docking","text":"<p>This application is modified from ParslDock.</p> <p>Protein docking aims to predict the orientation and position of two molecules, where one molecule is a protein, and the other is a protein or a smaller molecule (ligand). Docking is commonly used in structure-based drug design, as it can predict the strength of docking between target small molecule ligands (drugs) to target binding site (receptors).</p>"},{"location":"apps/docking/#installation","title":"Installation","text":"<p>The docking application requires Conda to install all of the required dependencies.</p> <pre><code>conda create --name taps-docking python=3.11\nconda activate taps-docking\nconda install -c conda-forge -c bioconda autodock-vina libglu mgltools vmd\npython3 -m pip install -e .[docking]\n</code></pre> <p>Warning</p> <p>This environment installs Python 2 and 3 so <code>python3</code> will need be be used for all commands.</p> <p>The <code>MGLTOOLS_HOME</code> environment must be set. If you install MGLTools with Conda, the path is likely the same as <code>CONDA_PREFIX</code>. <pre><code>export MGLTOOLS_HOME=$CONDA_PREFIX\n</code></pre></p> <p>Warning</p> <p>Dependencies are not compatible with ARM64 architectures.</p> <p>Tip</p> <p>Certain executors do not play nicely with the parallelism used by the simulation codes. If tasks appear to get suck, it may be necessary to set <code>OMP_NUM_THREADS=1</code>.</p>"},{"location":"apps/docking/#data","title":"Data","text":"<p>Sample input data is provided in the ParslDock tutorial. The following CLI will download the <code>dataset_orz_original_1k.csv</code> (SMILES string), <code>1iep_receptor.pdbqt</code> (input receptor), and <code>set_element.tcl</code> (TCL script) files.</p> <pre><code>python3 -m taps.apps.docking.data --output data/docking/\n</code></pre>"},{"location":"apps/docking/#example","title":"Example","text":"<p>The docking application can be invoked as follows.</p> <pre><code>python3 -m taps.run --app docking \\\n    --app.smi-file-name-ligand data/docking/dataset_orz_original_1k.csv \\\n    --app.receptor data/docking/1iep_receptor.pdbqt \\\n    --app.tcl-path data/docking/set_element.tcl\n    --engine.executor process-pool \\\n    --engine.executor.max-processes 40 \\\n</code></pre> <p>Checkout the full list of docking parameters with <code>python -m taps.run --app docking --help</code>. For example, the <code>--app.batch-size</code> and <code>--app.num-iterations</code> parameters control the parallelism and length of the application.</p> <p>Failure</p> <p>If you get an error that looks like the following: <pre><code>ImportError: /home/cc/miniconda3/envs/taps-docking/lib/python3.11/lib-dynload/_sqlite3.cpython-311-x86_64-linux-gnu.so: undefined symbol: sqlite3_trace_v2\n</code></pre> You may need to install <code>libsqlite</code>. <pre><code>conda install libsqlite\n</code></pre></p>"},{"location":"apps/failures/","title":"Failure Injection","text":"<p>The <code>failures</code> application randomly injects task failure scenarios into another TaPS application. This is useful to understanding how an application or execution engine handles certain forms of task failures.</p> <p>Warning</p> <p>Some of the error scenarios may have unexpected consequences to other actively running programs. For example:</p> <ul> <li><code>MANAGER_KILLED</code> will kill the parent process that a task is executing within.</li> <li><code>MEMORY</code> will continually consume memory until an error is raised. This can cause other applications to crash.</li> <li><code>NODE_KILLED</code> attempt to kill other processes on the node to simulate failures.</li> <li><code>RANDOM</code> will select a random, potentially dangerous, failure mode.</li> <li><code>WORKER_KILLED</code> will kill the process that a task is executing within.</li> </ul> <p>Please be careful when using this application, and run the application in an isolated environment (e.g., a container or ephemeral node).</p>"},{"location":"apps/failures/#installation","title":"Installation","text":"<p>This application requires some extra dependencies which can be installed automatically when installing the TaPS package. The base application that failures are injected into may have additional requirements. For example, to use <code>failures</code> with the <code>cholesky</code> application, install TaPS using: <pre><code>pip install -e .[cholesky,failures]\n</code></pre></p>"},{"location":"apps/failures/#data","title":"Data","text":"<p>Data requirements depend on the base application that failures are injected into.</p>"},{"location":"apps/failures/#example","title":"Example","text":"<p>The base application name is specified using <code>--app.base</code> and the corresponding configuration must be provided as a JSON string to <code>--app.config</code>.</p> <pre><code>python -m taps.run --app failures \\\n    --app.base cholesky \\\n    --app.config '{\"matrix_size\": 100, \"block_size\": 50}' \\\n    --app.failure-rate 0.5 --app.failure-type dependency \\\n    --engine.executor process-pool --engine.executor.max-processes 4\n</code></pre> <p>Alternatively, the app can be configured using a TOML file.</p> <p>config.toml<pre><code>[app]\nname = \"failures\"\nbase = \"cholesky\"\nfailure_rate = 0.5\nfailure_type = \"dependency\"\n\n[app.config]\nmatrix_size = 100\nblock_size = 50\n\n[engine.executor]\nname = \"process-pool\"\nmax_processes = 4\n</code></pre> <pre><code>python -m taps.run --config config.toml\n</code></pre></p>"},{"location":"apps/fedlearn/","title":"Federated Learning","text":"<p>An implementation of a Federated Learning (FL) application.</p> <p>At a high level, FL is a paradigm for performing deep learning on decentralized data hosted on decentralized devices (e.g., Internet-of-Things devices). Each of these devices separately train their own copy of a shared model architecture. Their locally-trained copies are aggregated over time to update a global model which has essentially been able to learn over all the data in the system without directly accessing any data.</p> <p>Check out this paper to learn more about FL.</p> <p>The <code>fedlearn</code> application uses simple deep neural networks and select set of baseline datasets to evaluate the task overheads and data costs associated with tasks in an FL app.</p>"},{"location":"apps/fedlearn/#installation","title":"Installation","text":"<p>This application requires numpy, PyTorch, and torchvision which can be installed automatically when installing the TaPS package. <pre><code>pip install -e .[fedlearn]\n</code></pre> If you want to use an accelerator for training (e.g., a GPU), you may need to follow specific instructions for the hardware or device driver versions. Check out the PyTorch docs for more details.</p>"},{"location":"apps/fedlearn/#example","title":"Example","text":"<p>The <code>fedlearn</code> application has many parameters, so we suggest taking a look at those available with <code>python -m taps.run --app fedlearn --help</code>. A simple example can be run with:</p> <pre><code>python -m taps.run --app fedlearn \\\n    --app.dataset mnist --app.data-dir data/fedlearn \\\n    --app.rounds 1 --app.participation 0.5 \\\n    --engine.executor process-pool\n</code></pre> <p>The script will automatically download the training and testing data to <code>data/fedlearn</code>.</p> <p>Warning</p> <p>CPU training can sometimes hang with certain executors (e.g., process pool). If this happens, try setting <code>OMP_NUM_THREADS=1</code>.</p> <p>Warning</p> <p>Using the <code>fork</code> multiprocessing backend on MacOS can cause issues with PyTorch's backpropogation on CPU. This is most common with Parsl which forces the use of <code>fork</code>. If you encounter this issue, you may need to set the following.</p> <pre><code>import multiprocessing\nimport platform\n\nif platform.system() == 'Darwin':\n    multiprocessing.set_start_method('spawn', force=True)\n</code></pre>"},{"location":"apps/mapreduce/","title":"MapReduce","text":"<p>Counts words in a text corpus using a mapreduce strategy.</p>"},{"location":"apps/mapreduce/#installation","title":"Installation","text":"<p>This application only requires TaPS to be installed.</p>"},{"location":"apps/mapreduce/#data","title":"Data","text":"<p>The Enron email dataset is available at https://www.cs.cmu.edu/~enron/. The following command will download and extract the tarfile to <code>data/maildir</code>.</p> <pre><code>curl -L https://www.cs.cmu.edu/~enron/enron_mail_20150507.tar.gz | tar -xz -C data/\n</code></pre>"},{"location":"apps/mapreduce/#example","title":"Example","text":"<p>To see all parameters, run the following command: <pre><code>python -m taps.run --app mapreduce --help\n</code></pre></p> <p>Enron Corpus</p> <p>The following command distributes the text files of the Enron Corpus within <code>data/maildir</code> across 16 map tasks. Once the computations have finished, the top 10 most common tokens will be printed. <pre><code>python -m taps.run --app mapreduce\n    --app.data-dir data/maildir --app.map-tasks 16 \\\n    --engine.executor process-pool\n</code></pre></p> <p>Randomly Generated</p> <p>Here, we will generate 16 random files for each of 16 map tasks. <pre><code>python -m taps.run -app mapreduce \\\n    --app.data-dir /tmp/generated-files --app.map-tasks 16 \\\n    --app.generate true --app.generated-files 16 \\\n    --engine.executor process-pool\n</code></pre></p>"},{"location":"apps/moldesign/","title":"Molecular Design","text":"<p>This application is based on Molecular Design with Parsl.</p>"},{"location":"apps/moldesign/#installation","title":"Installation","text":"<p>This application has certain dependencies which require Conda to install. To get started, create a Conda environment, install the Conda dependencies, and then install the <code>taps</code> package into the Conda environment.</p> <pre><code>conda create --name taps-moldesign python=3.11\nconda activate taps-moldesign\nconda install -c conda-forge xtb-python==22.1\npip install -e .[moldesign]\n</code></pre>"},{"location":"apps/moldesign/#data","title":"Data","text":"<p>The data needs to be downloaded first. <pre><code>curl -o data/moldesign/QM9-search.tsv --create-dirs https://raw.githubusercontent.com/ExaWorks/molecular-design-parsl-demo/main/data/QM9-search.tsv\n</code></pre></p>"},{"location":"apps/moldesign/#example","title":"Example","text":"<p>The following configuration will execute tasks with a process pool of four workers. An initial four simulations will be performed and the results of those simulations will train the initial model. Then, the application will iteratively submit new batches of simulations for the highest ranked molecules from the model inference. After the batch of simulations completes, the model is retrained and the cycle starts again until <code>search_count</code> molecules have been simulated.</p> <pre><code>python -m taps.run --app moldesign \\\n    --app.dataset data/moldesign/QM9-search.tsv \\\n    --app.initial-count 4 --app.batch-size 4 --app.search-count 16 \\\n    --engine.executor process-pool --engine.executor.max-processes 4\n</code></pre> <p>Additional parameters are available with <code>python -m taps.run --app moldesign --help</code>.</p> <p>Warning</p> <p>It may be necessary to set <code>OMP_NUM_THREADS=1</code> with certain executors if the simulation task appear to be stuck.</p> <p>After the application completes, a CSV file containing the simulation results and a PNG graph of the molecules found over time will be saved to the run directory.</p>"},{"location":"apps/montage/","title":"Montage Mosaic","text":"<p>This application is based on the Parsl implementation of the Montage Getting Started tutorial.</p> <p>The Montage Mosaic application takes a directory of input astronomy images and stitches them into a single mosaic using Montage tools.</p>"},{"location":"apps/montage/#installation","title":"Installation","text":"<p>This application requires additional package dependencies and for the Montage binaries to be installed. We suggest using Conda so the correct compilers for Montage can be installed. <pre><code>conda create --name taps-montage python=3.11\nconda activate taps-montage\nconda install -c conda-forge gcc=9.5 libnsl\npip install -e .[montage]\n</code></pre></p> <p>Warning</p> <p>Build instructions may be different depending on your system. Here we used Ubuntu 22.04.</p> <p>Next, download, build, and install Montage, available at http://montage.ipac.caltech.edu/docs/download2.html. We will do this inside of our Conda environment directory. <pre><code>cd $CONDA_PREFIX\ncurl -L http://montage.ipac.caltech.edu/download/Montage_v6.0.tar.gz | tar -xz\ncd Montage\nmake\nexport PATH=\"$CONDA_PREFIX/Montage/bin:$PATH\"\n</code></pre> You can now return to your TaPS directory.</p>"},{"location":"apps/montage/#data","title":"Data","text":"<p>Input data available at http://montage.ipac.caltech.edu/docs/Kimages.tar. The following command will download and extract the tarfile to <code>data/Kimages</code>. <pre><code>curl -L http://montage.ipac.caltech.edu/docs/Kimages.tar | tar -x -C data/\n</code></pre></p>"},{"location":"apps/montage/#example","title":"Example","text":"<p>The application can be invoked using the downloaded data.</p> <pre><code>python -m taps.run --app montage --app.img-folder data/Kimages --engine.executor process-pool\n</code></pre> <p>Failure</p> <p>If you get an error like: <pre><code>montage_wrapper.status.MontageError: mProject: File (/home/cc/taps/data/Kimages/._aK_asky_990502s1350092.fits) is not a FITS image\n</code></pre> This is a side-effect of the tarfile being created on MacOS and MacOS using these special files for extra information. Simply remove those files from the image directory. <pre><code>rm -rf data/Kimages/._*\n</code></pre></p> <p>This will produce a single final FITS file within <code>data/</code> inside of the run directory.</p>"},{"location":"apps/synthetic/","title":"Synthetic Workflow","text":"<p>The synthetic workflow generates an arbitrary number of no-op sleep tasks that take and produce random data. The workflow supports four workflow structures:</p> <ul> <li><code>bag</code>: Executes a \"bag-of-tasks\" where <code>task-count</code> tasks are executed. At   most <code>bag-max-running</code> will be running at any given time. This is useful   for testing scalability.</li> <li><code>diamond</code>: Executes a diamond workflow where the output of an initial task   is given to <code>task-count</code> intermediate tasks, executed in parallel, and   the outputs of the intermediate tasks are aggregated in a single, final   task.</li> <li><code>reduce</code>: Executes <code>task-count</code> independent tasks in parallel and a single   reduce task that takes the output of all of the independent tasks.</li> <li><code>sequential</code>: Executes a chain of <code>task-count</code> tasks where each subsequent   task depends on the output data of the prior. There is no parallelism, but   is useful for evaluating task and data overheads.</li> </ul>"},{"location":"apps/synthetic/#installation-and-data","title":"Installation and Data","text":"<p>This application requires no additional dependencies besides TaPS and all data is generated randomly by the application.</p>"},{"location":"apps/synthetic/#example","title":"Example","text":"<p>The following example runs a bag of tasks workflow across four processes. A maximum of four task can be running at any time, a total of 40 tasks will be submitted, each tasks sleeps for one second, and each task takes and produces 10 kB of data.</p> <pre><code>python -m taps.run --app synthetic \\\n    --app.structure bag --app.task-count 40 \\\n    --app.task-data-bytes 10000 --app.task-sleep 1 --app.bag-max-running 4 \\\n    --engine.executor process-pool --engine.executor.max-processes 4\n</code></pre>"},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#getting-started-for-local-development","title":"Getting Started for Local Development","text":"<p>We recommend using Tox to setup the development environment. This will create a new virtual environment with all of the required packages installed and TaPS installed in editable mode with the necessary extras options.</p> <pre><code>$ git clone https://github.com/proxystore/taps\n$ cd foobar\n$ tox --devenv venv -e py311\n$ . venv/bin/activate\n</code></pre> <p>Warning</p> <p>Running Tox in a Conda environment is possible but it may conflict with Tox's ability to find the correct Python versions. E.g., if your Conda environment is Python 3.11, running <code>$ tox -e p310</code> may still use Python 3.11.</p> <p>To install manually: <pre><code>$ git clone https://github.com/proxystore/taps\n$ cd taps\n$ python -m venv venv\n$ . venv/bin/activate\n$ pip install -e .[dev,docs]\n</code></pre></p>"},{"location":"contributing/#continuous-integration","title":"Continuous Integration","text":"<p>FooBar uses pre-commit and Tox for continuous integration (test, linting, etc.).</p>"},{"location":"contributing/#linting-and-type-checking-pre-commit","title":"Linting and Type Checking (pre-commit)","text":"<p>To use pre-commit, install the hook and then run against files.</p> <pre><code>$ pre-commit install\n$ pre-commit run --all-files\n</code></pre>"},{"location":"contributing/#tests-tox","title":"Tests (tox)","text":"<p>The entire CI workflow can be run with <code>$ tox</code>. This will test against multiple versions of Python and can be slow.</p> <p>Module-level unit-test are located in the <code>tests/</code> directory and its structure is intended to match that of <code>foobar/</code>. E.g. the tests for <code>taps/x/y.py</code> are located in <code>tests/x/y_test.py</code>; however, additional test files can be added as needed. Tests should be narrowly focused and target a single aspect of the code's functionality, tests should not test internal implementation details of the code, and tests should not be dependent on the order in which they are run.</p> <p>Code that is useful for building tests but is not a test itself belongs in the <code>testing/</code> directory.</p> <pre><code># Run all tests in tests/\n$ tox -e py39\n# Run a specific test\n$ tox -e py39 -- tests/x/y_test.py::test_z\n</code></pre>"},{"location":"contributing/#docs","title":"Docs","text":"<p>If code changes require an update to the documentation (e.g., for function signature changes, new modules, etc.), the documentation can be built using MKDocs.</p> <pre><code># Manually\n$ pip install -e .[docs]\n$ mkdocs build --strict  # Build only to site/index.html\n$ mkdocs serve           # Serve locally\n\n# With tox (will only build, does not serve)\n$ tox -e docs\n</code></pre> <p>Docstrings are automatically generated, but it is recommended to check the generated docstrings to make sure details/links/etc. are correct.</p>"},{"location":"contributing/issues-pull-requests/","title":"Issues and Pull Requests","text":""},{"location":"contributing/issues-pull-requests/#issues","title":"Issues","text":"<p>Issue Tracker</p> <p>We use GitHub issues to report problems, request and track changes, and discuss future ideas. If you open an issue for a specific problem, please follow the template guides.</p>"},{"location":"contributing/issues-pull-requests/#pull-requests","title":"Pull Requests","text":"<p>We use the standard GitHub contribution cycle where all contributions are made via pull requests (including code owners!).</p> <ol> <li>Fork the repository and clone to your local machine.</li> <li> <p>Create local changes.</p> <ul> <li>Changes should conform to the style and testing guidelines, referenced   above.</li> <li>Preferred commit message format (source):<ul> <li>separate subject from body with a blank line,</li> <li>limit subject line to 50 characters,</li> <li>capitalize first word of subject line,</li> <li>do not end the subject line with a period,</li> <li>use the imperative mood for subject lines,</li> <li>include related issue numbers at end of subject line,</li> <li>wrap body at 72 characters, and</li> <li>use the body to explain what/why rather than how.</li> <li>Example: <code>Fix concurrency bug in Store (#42)</code></li> </ul> </li> </ul> </li> <li> <p>Push commits to your fork.</p> <ul> <li>Please squash commits fixing mistakes to keep the git history clean.   For example, if commit \"b\" follows commit \"a\" and only fixes a small typo   from \"a\", please squash \"a\" and \"b\" into a single, correct commit.   This keeps the commit history readable and easier to search through when   debugging (e.g., git blame/bisect).</li> </ul> </li> <li>Open a pull request in this repository.<ul> <li>The pull request should include a description of the motivation for the   PR and included changes. A PR template is provided to guide this process.</li> </ul> </li> </ol>"},{"location":"contributing/releases/","title":"Releases","text":""},{"location":"contributing/releases/#release-timeline","title":"Release Timeline","text":"<p>Releases are created on an as-needed basis. Milestones in the Issue Tracker are used to track features to be included in upcoming releases.</p>"},{"location":"contributing/releases/#versioning","title":"Versioning","text":"<p>TaPS uses semver as its versioning system. TaPS is an application package, rather than a library package, so internal changes within the TaPS benchmarking harness are not considered breaking changes. Rather, changes are only considered breaking if they change the way an application is run. For example, the command from a prior release no longer works in the following release.</p> <p>While TaPS is in major version zero (0.y.z), anything may change at any time.</p>"},{"location":"contributing/releases/#creating-releases","title":"Creating Releases","text":"<ol> <li>Choose the next version number, referred to as <code>{VERSION}</code> for the    rest of the instructions. Versioning follows semver    (<code>major.minor.patch</code>) with optional PEP-440    pre-release/post-release/dev-release segments. Major/minor/patch numbers    start at 0 and pre-release/post-release/dev-release segments start at 1.</li> <li>Update the version in <code>pyproject.toml</code> to <code>{VERSION}</code>.</li> <li>Commit and merge the version updates/changelogs into main.</li> <li>Tag the release commit and push (typically this is the commit updating the    version numbers).    <pre><code>$ git tag -s v{VERSION} -m \"FooBar v{VERSION}\"\n$ git push origin v{VERSION}\n</code></pre>    Note the version number is prepended by \"v\" for the tags so we can    distinguish release tags from non-release tags.</li> <li>Create a new release on GitHub using the tag. The title should be    <code>FooBar v{VERSION}</code>.</li> <li>Official release:<ol> <li>Use the \"Generate release notes\" option and set the previous tag as the previous official release tag. E.g., for <code>v0.4.1</code>, the previous release tag should be <code>v0.4.0</code> and NOT <code>v0.4.1a1</code>.</li> <li>Add an \"Upgrade Steps\" section at the top (see previous releases for examples).</li> <li>Review the generated notes and edit as needed. PRs are organized by tag, but some PRs will be missing tags and need to be moved from the \"Other Changes\" section to the correct section.</li> <li>Select \"Set as the latest release.\"</li> </ol> </li> <li>Unofficial release: (alpha/dev builds)<ol> <li>Do NOT generate release notes. The body can be along the lines of \"Development pre-prelease for <code>V{VERSION}</code>.\"</li> <li>Leave the previous tag as \"auto.\"</li> <li>Select \"Set as a pre-release.\"</li> </ol> </li> </ol>"},{"location":"contributing/style-guide/","title":"Style Guide","text":"<p>The Python code and docstring format mostly follows Google's Python Style Guide, but the pre-commit config is the authoritative source for code format compliance.</p> <p>Nits:</p> <ul> <li>Avoid imports in <code>__init__.py</code> (reduces the likelihood of circular imports).</li> <li>Prefer pure functions where possible.</li> <li>Define all class attributes inside <code>__init__</code> so all attributes are visible   in one place. Attributes that are defined later can be set as <code>None</code>   as a placeholder.</li> <li>Prefer f-strings (<code>f'name: {name}</code>) over string format   (<code>'name: {}'.format(name)</code>). Never use the <code>%</code> operator.</li> <li>Prefer typing.NamedTuple over collections.namedtuple.</li> <li>Use lower-case and no punctuation for log messages, but use upper-case and   punctuation for exception values.   <pre><code>logger.info(f'new connection opened to {address}')\nraise ValueError('Name must contain alphanumeric characters only.')\n</code></pre></li> <li>Document all exceptions that may be raised by a function in the docstring.</li> </ul>"},{"location":"guides/","title":"Guides","text":"<ul> <li>Create an Application</li> </ul>"},{"location":"guides/creating-apps/","title":"Create an Application","text":"<p>This guide describes creating a benchmarking application within the TaPS framework.</p>"},{"location":"guides/creating-apps/#installation","title":"Installation","text":"<p>A development environment needs to be configured first. Fork the repository and clone your fork locally. Then, configure a virtual environment with the TaPS package and development dependencies.</p> <pre><code>python -m venv venv\n. venv/bin/activate\npip install -e .[dev,docs]\n</code></pre> <p>See Getting Started for Local Development for detailed instructions on running the linters and continuous integration tests.</p>"},{"location":"guides/creating-apps/#application-structure","title":"Application Structure","text":"<p>Our example application is going to be called <code>foobar</code>. All applications in TaPS are composed of two required components: <code>AppConfig</code> and <code>Config</code>. The <code>AppConfig</code> is a Pydantic <code>BaseModel</code> containing all configuration options that should be exposed via the CLI. The <code>App</code> has a <code>run()</code> method which is the entry point to running the applications.</p>"},{"location":"guides/creating-apps/#the-app","title":"The <code>App</code>","text":"<p>All applications are submodules of <code>taps/apps/</code>. Our <code>foobar</code> application is simple so we will create a single file module named <code>taps/apps/foobar.py</code>. More complex applications can create a subdirectory containing many submodules.</p> taps/apps/foobar.py<pre><code>from __future__ import annotations\n\nimport logging\nimport pathlib\n\nfrom taps.engine import Engine\nfrom taps.logging import APP_LOG_LEVEL\n\nlogger = logging.getLogger(__name__)\n\n\ndef print_message(message: str) -&gt; None:\n    \"\"\"Print a message.\"\"\"\n    logger.log(APP_LOG_LEVEL, message)\n\n\nclass FoobarApp:\n    \"\"\"Foobar application.\n\n    Args:\n        message: Message to print.\n        repeat: Number of times to repeat the message.\n    \"\"\"\n\n    def __init__(self, message: str, repeat: int = 1) -&gt; None:\n        self.message = message\n        self.repeat = repeat\n\n    def close(self) -&gt; None:\n        \"\"\"Close the application.\"\"\"\n        pass\n\n    def run(self, engine: Engine, run_dir: pathlib.Path) -&gt; None:\n        \"\"\"Run the application.\n\n        Args:\n            engine: Application execution engine.\n            run_dir: Run directory.\n        \"\"\"\n        for _ in range(self.repeat):\n            task = engine.submit(print_message, self.message)\n            task.result()  # Wait on task to finish\n</code></pre> <ol> <li>Applications in TaPS are composed on tasks which are just Python functions.    Here, our task is the <code>print_message</code> function.</li> <li>The <code>FoobarApp</code> implements the <code>App</code> protocol.</li> <li>The <code>close()</code> method can be used to close any stateful connection objects created in <code>__init__</code> or perform any clean up if needed.</li> <li>Once <code>FoobarApp</code> is instantiated by the CLI, <code>FoobarApp.run()</code> will be invoked.    This method takes two arguments: an <code>Engine</code> and a path to the invocations run directory.    Applications are free to use the run directory as needed, such as to store result files.</li> </ol> <p>The <code>Engine</code> is the key abstraction of the TaPS framework. The CLI arguments provided by the user for the compute engine, data management, and task logging logic are used to create an <code>Engine</code> instance which is then provided to the application. <code>Engine.submit()</code> is the primary method that application will use to execute tasks asynchronously. This method returns a <code>TaskFuture</code> object with a <code>result()</code> which will wait on the task to finish and return the result. Alternatively, <code>Engine.map()</code> can be used to map a task onto a sequence of inputs, compute the tasks in parallel, and gather the results. Importantly, a <code>TaskFuture</code> can also be passed as input to another tasks. Doing so indicates to the <code>Engine</code> that there is a dependency between those two tasks.</p>"},{"location":"guides/creating-apps/#the-appconfig","title":"The <code>AppConfig</code>","text":"<p>An <code>AppConfig</code> is registered with the TaPS CLI and defines (1) what arguments should be available in the CLI and (2) how to construct and <code>App</code> from the configuration. Each <code>App</code> definition has a corresponding <code>AppConfig</code> defined in <code>taps/apps/configs/</code>. Here, we'll create a file <code>taps/apps/configs/foobar.py</code> for our <code>FoobarConfig</code>. This configuration will contain all of the parameters that the user is required to provide and any optional parameters.</p> taps/apps/configs/foobar.py<pre><code>from __future__ import annotations\n\nfrom typing import Literal\n\nfrom pydantic import Field\n\nfrom taps.apps import App\nfrom taps.apps import AppConfig\nfrom taps.plugins import register\n\n\n@register('app')\nclass FoobarConfig(AppConfig):\n    \"\"\"Foobar application configuration.\"\"\"\n\n    name: Literal['foobar'] = 'foobar'\n    message: str = Field(description='message to print')\n    repeat: int = Field(1, description='number of times to repeat message')\n\n    def get_app(self) -&gt; App:\n        \"\"\"Create an application instance from the config.\"\"\"\n        from taps.apps.foobar import FoobarApp\n\n        return FoobarApp(message=self.message, repeat=self.repeat)\n</code></pre> <ol> <li>The <code>@register()</code> decorator registers the <code>FoobarConfig</code> with the TaPS as an <code>'app'</code> plugin.    The <code>name</code> attribute of the config is the name under which the application will be available in the CLI.    For example, here we can use <code>python -m taps.run --app foobar {args}</code> to run our application.</li> <li>The <code>AppConfig</code> class supports required arguments without default values (e.g., <code>message</code>) and optional arguments with default values (e.g., <code>repeat</code>).</li> <li>The <code>get_app()</code> method is required and is invoked by the CLI to create an <code>App</code> instance.</li> <li>Note: <code>FoobarApp</code> is imported inside of <code>get_app()</code> to delay importing dependencies specific to the application until the user has decided which application they want to execute.</li> </ol>"},{"location":"guides/creating-apps/#dependencies","title":"Dependencies","text":"<p>Applications which require extra dependencies should do one of the following.</p> <ol> <li>Add an optional dependencies section to <code>pyproject.toml</code>.    If the dependencies are pip installable, add a new section with the name of the application to the <code>[project.optional-dependencies]</code> section in <code>pyproject.toml</code>.    For example:    <pre><code>[project.optional-depedencies]\nfoobar = [\"my-dependency\"]\n</code></pre></li> <li>Add installation instructions to the application's documentation.    More complex applications may have dependencies which are not installable with pip.    In this case, instructions should be provided in documentation, discussed in the next section.</li> </ol>"},{"location":"guides/creating-apps/#documentation","title":"Documentation","text":"<p>Each application should have an associated documentation page which describes (1) what the application is based on, (2) what the application does, and (3) how to run the application. Application documentation is written using markdown files in <code>docs/apps/</code>. For example, our <code>foobar</code> application will have a file called <code>docs/apps/foobar.md</code>. Once your markdown file is written, it needs to be added to the documentation navigation tree.</p> <p>First, modify <code>docs/apps/index.md</code> to contain a link to the file. <pre><code>- [Foobar](foobar.md)\n</code></pre> Then, modify the navigation tree in <code>mkdocs.yml</code> to contain the path to the markdown file within the \"Apps\" section of the docs. <pre><code>nav:\n  - App:\n      - apps/index.md\n      - Foobar: apps/foobar.md\n</code></pre> Please keep the lists in each of these files alphabetized.</p> <p>Once these files have been added, you can build the documentation. This requires having installed TaPS with the <code>docs</code> option (e.g., <code>pip install .[docs]</code>). <pre><code>mkdocs build --strict\n</code></pre> You will be able to inspect that your page is visible in the \"Apps\" section of the docs and is formatted correctly.</p>"},{"location":"guides/creating-apps/#running-the-application","title":"Running the Application","text":"<p>Once an application is created and registered within TaPS, the application is available within the CLI. <pre><code>python -m taps.run --app foobar --help\n</code></pre> The <code>--help</code> flag will print all of the required and optional arguments as specified in the <code>FoobarConfig</code> because <code>--app foobar</code> was specified. If no app is specified, <code>--help</code> will just print the available apps that can be used. The arguments will be separated into sections, such as for arguments specific the <code>foobar</code> app or for executor arguments.</p> <p>The following command will execute the application to print \"Hello, World!\" three times. We specify the <code>thread-pool</code> executor because this will allow our printing to show up in the main process. <pre><code>$ python -m taps.run --app foobar --app.message 'Hello, World!' --app.repeat 3 --engine.executor thread-pool\nRUN   (taps.run) :: Starting application (name=foobar)\n...\nAPP  (taps.apps.foobar) :: Hello, World!\nAPP  (taps.apps.foobar) :: Hello, World!\nAPP  (taps.apps.foobar) :: Hello, World!\nRUN   (taps.run) :: Finished application (name=foobar, runtime=0.00s)\n</code></pre></p>"}]}