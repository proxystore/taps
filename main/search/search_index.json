{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Workflow Execution Benchmark Suite","text":"<p>:warning: This repository is currently under development.</p> <p>Workflows benchmark suite for task-based execution frameworks.</p>"},{"location":"get-started/","title":"Quick Start","text":"<p>The Workflow Execution Benchmark Suite (WEBS) provides a set of standard computational workflows that can be executed with a variety of execution engines.</p>"},{"location":"get-started/#installation","title":"Installation","text":"<pre><code>git clone https://github.com/proxystore/webs\ncd webs\npython -m venv venv\n. venv/bin/activate\npip install -e .\n</code></pre> <p>Documentation on installing for local development is provided in Contributing.</p>"},{"location":"get-started/#usage","title":"Usage","text":"<pre><code>python -m webs.run {workflow-name} {args}\n</code></pre>"},{"location":"api/","title":"webs","text":"<code>webs/__init__.py</code> <p>Workflows benchmark package.</p>"},{"location":"api/SUMMARY/","title":"SUMMARY","text":"<ul> <li>webs</li> <li>webs.config</li> <li>webs.context</li> <li>webs.data<ul> <li>file</li> <li>filter</li> <li>proxy</li> <li>transform</li> </ul> </li> <li>webs.executor<ul> <li>config</li> <li>dag</li> <li>dask</li> <li>globus</li> <li>parsl</li> <li>python</li> <li>workflow</li> </ul> </li> <li>webs.logging</li> <li>webs.record</li> <li>webs.run<ul> <li>config</li> <li>main</li> </ul> </li> <li>webs.wf<ul> <li>synthetic<ul> <li>config</li> <li>utils</li> <li>workflow</li> </ul> </li> </ul> </li> <li>webs.workflow</li> </ul>"},{"location":"api/config/","title":"webs.config","text":"<code>webs/config.py</code>"},{"location":"api/config/#webs.config.Config","title":"Config","text":"<p>             Bases: <code>BaseModel</code></p> <p>Base configuration model type.</p>"},{"location":"api/config/#webs.config.Config.add_argument_group","title":"add_argument_group()  <code>classmethod</code>","text":"<pre><code>add_argument_group(\n    parser: ArgumentParser,\n    *,\n    argv: Sequence[str] | None = None,\n    required: bool = True\n) -&gt; None\n</code></pre> <p>Add model fields as arguments of an argument group on the parser.</p> <p>Parameters:</p> <ul> <li> <code>parser</code>             (<code>ArgumentParser</code>)         \u2013          <p>Parser to add a new argument group to.</p> </li> <li> <code>argv</code>             (<code>Sequence[str] | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional sequence of string arguments.</p> </li> <li> <code>required</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Mark arguments without defaults as required.</p> </li> </ul> Source code in <code>webs/config.py</code> <pre><code>@classmethod\ndef add_argument_group(\n    cls,\n    parser: argparse.ArgumentParser,\n    *,\n    argv: Sequence[str] | None = None,\n    required: bool = True,\n) -&gt; None:\n    \"\"\"Add model fields as arguments of an argument group on the parser.\n\n    Args:\n        parser: Parser to add a new argument group to.\n        argv: Optional sequence of string arguments.\n        required: Mark arguments without defaults as required.\n    \"\"\"\n    group = parser.add_argument_group(cls.__name__)\n    for field_name, field_info in cls.model_fields.items():\n        arg_name = field_name.replace('_', '-').lower()\n        group.add_argument(\n            f'--{arg_name}',\n            dest=field_name,\n            # type=field_info.annotation,\n            default=field_info.get_default(),\n            required=field_info.is_required() and required,\n            help=field_info.description,\n        )\n</code></pre>"},{"location":"api/context/","title":"webs.context","text":"<code>webs/context.py</code>"},{"location":"api/context/#webs.context.ContextManagerAddIn","title":"ContextManagerAddIn","text":"<pre><code>ContextManagerAddIn(\n    managers: (\n        Sequence[AbstractContextManager[Any] | None] | None\n    ) = None,\n)\n</code></pre> <p>Context manager add in class.</p> Source code in <code>webs/context.py</code> <pre><code>def __init__(\n    self,\n    managers: Sequence[AbstractContextManager[Any] | None] | None = None,\n) -&gt; None:\n    self._managers = [] if managers is None else managers\n</code></pre>"},{"location":"api/logging/","title":"webs.logging","text":"<code>webs/logging.py</code>"},{"location":"api/logging/#webs.logging.init_logging","title":"init_logging()","text":"<pre><code>init_logging(\n    logfile: Path | None = None,\n    level: int | str = logging.INFO,\n    logfile_level: int | str = logging.INFO,\n    force: bool = False,\n) -&gt; None\n</code></pre> <p>Initialize logging with custom formats.</p> <p>Adds a custom log levels RUN and WORK which are higher than INFO and lower than WARNING. RUN is used by the workflow benchmark harness and WORK is using within the workflows.</p> Usage <p>logger = init_logger(...) logger.log(RUN_LOG_LEVEL, 'message')</p> <p>Parameters:</p> <ul> <li> <code>logfile</code>             (<code>str</code>, default:                 <code>None</code> )         \u2013          <p>option filepath to write log to (default: None).</p> </li> <li> <code>level</code>             (<code>(int, str)</code>, default:                 <code>INFO</code> )         \u2013          <p>minimum logging level (default: INFO).</p> </li> <li> <code>logfile_level</code>             (<code>(int, str)</code>, default:                 <code>INFO</code> )         \u2013          <p>minimum logging level for the logfile (default: INFO).</p> </li> <li> <code>force</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>remove any existing handlers attached to the root handler. This option is useful to silencing the third-party package logging. Note: should not be set when running inside pytest (default: False).</p> </li> </ul> Source code in <code>webs/logging.py</code> <pre><code>def init_logging(\n    logfile: pathlib.Path | None = None,\n    level: int | str = logging.INFO,\n    logfile_level: int | str = logging.INFO,\n    force: bool = False,\n) -&gt; None:\n    \"\"\"Initialize logging with custom formats.\n\n    Adds a custom log levels RUN and WORK which are higher than INFO and\n    lower than WARNING. RUN is used by the workflow benchmark harness\n    and WORK is using within the workflows.\n\n    Usage:\n        &gt;&gt;&gt; logger = init_logger(...)\n        &gt;&gt;&gt; logger.log(RUN_LOG_LEVEL, 'message')\n\n    Args:\n        logfile (str): option filepath to write log to (default: None).\n        level (int, str): minimum logging level (default: INFO).\n        logfile_level (int, str): minimum logging level for the logfile\n            (default: INFO).\n        force (bool): remove any existing handlers attached to the root\n            handler. This option is useful to silencing the third-party\n            package logging. Note: should not be set when running inside\n            pytest (default: False).\n    \"\"\"\n    logging.addLevelName(RUN_LOG_LEVEL, 'RUN')\n    logging.addLevelName(WORK_LOG_LEVEL, 'WORK')\n\n    stdout_handler = logging.StreamHandler(sys.stdout)\n    stdout_handler.setLevel(level)\n\n    handlers: list[logging.Handler] = [stdout_handler]\n    if logfile is not None:\n        logfile.parent.mkdir(parents=True, exist_ok=True)\n        handler = logging.FileHandler(logfile)\n        handler.setLevel(logfile_level)\n        handlers.append(handler)\n\n    kwargs: dict[str, Any] = {}\n    if force:  # pragma: no cover\n        kwargs['force'] = force\n\n    logging.basicConfig(\n        format=(\n            '[%(asctime)s.%(msecs)03d] %(levelname)-5s (%(name)s) :: '\n            '%(message)s'\n        ),\n        datefmt='%Y-%m-%d %H:%M:%S',\n        level=logging.DEBUG,\n        handlers=handlers,\n        **kwargs,\n    )\n</code></pre>"},{"location":"api/record/","title":"webs.record","text":"<code>webs/record.py</code>"},{"location":"api/record/#webs.record.Record","title":"Record  <code>module-attribute</code>","text":"<pre><code>Record: TypeAlias = Dict[str, Any]\n</code></pre> <p>Record type.</p>"},{"location":"api/record/#webs.record.RecordLogger","title":"RecordLogger","text":"<p>             Bases: <code>Protocol</code></p> <p>Record logger protocol.</p>"},{"location":"api/record/#webs.record.RecordLogger.log","title":"log()","text":"<pre><code>log(record: Record) -&gt; None\n</code></pre> <p>Log a record.</p> Source code in <code>webs/record.py</code> <pre><code>def log(self, record: Record) -&gt; None:\n    \"\"\"Log a record.\"\"\"\n    ...\n</code></pre>"},{"location":"api/record/#webs.record.RecordLogger.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the logger.</p> Source code in <code>webs/record.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close the logger.\"\"\"\n    ...\n</code></pre>"},{"location":"api/record/#webs.record.JSONRecordLogger","title":"JSONRecordLogger","text":"<pre><code>JSONRecordLogger(filepath: Path | str)\n</code></pre> <p>JSON lines record logger.</p> <p>Logs records as JSON strings per line to a file.</p> <p>Parameters:</p> <ul> <li> <code>filepath</code>             (<code>Path | str</code>)         \u2013          <p>Filepath to log to.</p> </li> </ul> Source code in <code>webs/record.py</code> <pre><code>def __init__(self, filepath: pathlib.Path | str) -&gt; None:\n    self._filepath = pathlib.Path(filepath)\n    self._handle = open(self._filepath, 'a')  # noqa: SIM115\n</code></pre>"},{"location":"api/record/#webs.record.JSONRecordLogger.log","title":"log()","text":"<pre><code>log(record: Record) -&gt; None\n</code></pre> <p>Log a record.</p> Source code in <code>webs/record.py</code> <pre><code>def log(self, record: Record) -&gt; None:\n    \"\"\"Log a record.\"\"\"\n    self._handle.write(json.dumps(record) + '\\n')\n</code></pre>"},{"location":"api/record/#webs.record.JSONRecordLogger.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the logger.</p> Source code in <code>webs/record.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close the logger.\"\"\"\n    self._handle.close()\n</code></pre>"},{"location":"api/record/#webs.record.NullRecordLogger","title":"NullRecordLogger","text":"<p>Null/no-op record logger.</p>"},{"location":"api/record/#webs.record.NullRecordLogger.log","title":"log()","text":"<pre><code>log(record: Record) -&gt; None\n</code></pre> <p>Log a record.</p> Source code in <code>webs/record.py</code> <pre><code>def log(self, record: Record) -&gt; None:\n    \"\"\"Log a record.\"\"\"\n    return\n</code></pre>"},{"location":"api/record/#webs.record.NullRecordLogger.close","title":"close()","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the logger.</p> Source code in <code>webs/record.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close the logger.\"\"\"\n    return\n</code></pre>"},{"location":"api/workflow/","title":"webs.workflow","text":"<code>webs/workflow.py</code>"},{"location":"api/workflow/#webs.workflow.Workflow","title":"Workflow","text":"<p>             Bases: <code>Protocol[WorkflowConfigT]</code></p> <p>Workflow protocol.</p> <p>Attributes:</p> <ul> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>Name of the workflow.</p> </li> <li> <code>config_type</code>             (<code>type[WorkflowConfigT]</code>)         \u2013          <p>Workflow configuration type.</p> </li> </ul>"},{"location":"api/workflow/#webs.workflow.Workflow.from_config","title":"from_config()  <code>classmethod</code>","text":"<pre><code>from_config(config: WorkflowConfigT) -&gt; Self\n</code></pre> <p>Initialize a workflow instance from a config.</p> Source code in <code>webs/workflow.py</code> <pre><code>@classmethod\ndef from_config(cls, config: WorkflowConfigT) -&gt; Self:\n    \"\"\"Initialize a workflow instance from a config.\"\"\"\n    ...\n</code></pre>"},{"location":"api/workflow/#webs.workflow.Workflow.run","title":"run()","text":"<pre><code>run(executor: WorkflowExecutor, run_dir: Path) -&gt; None\n</code></pre> <p>Run the workflow.</p> Source code in <code>webs/workflow.py</code> <pre><code>def run(\n    self,\n    executor: WorkflowExecutor,\n    run_dir: pathlib.Path,\n) -&gt; None:\n    \"\"\"Run the workflow.\"\"\"\n    ...\n</code></pre>"},{"location":"api/data/","title":"webs.data","text":"<code>webs/data/__init__.py</code>"},{"location":"api/data/file/","title":"webs.data.file","text":"<code>webs/data/file.py</code>"},{"location":"api/data/file/#webs.data.file.Identifier","title":"Identifier","text":"<p>             Bases: <code>NamedTuple</code></p> <p>Object identifier.</p> <p>Attributes:</p> <ul> <li> <code>cache_dir</code>             (<code>Path</code>)         \u2013          <p>Object directory.</p> </li> <li> <code>obj_id</code>             (<code>UUID</code>)         \u2013          <p>Object ID.</p> </li> </ul>"},{"location":"api/data/file/#webs.data.file.Identifier.path","title":"path()","text":"<pre><code>path() -&gt; Path\n</code></pre> <p>Get path to the object.</p> Source code in <code>webs/data/file.py</code> <pre><code>def path(self) -&gt; pathlib.Path:\n    \"\"\"Get path to the object.\"\"\"\n    return self.cache_dir / str(self.obj_id)\n</code></pre>"},{"location":"api/data/file/#webs.data.file.PickleFileTransformer","title":"PickleFileTransformer","text":"<pre><code>PickleFileTransformer(cache_dir: Path | str)\n</code></pre> <p>Pickle file object transformer.</p> <p>Parameters:</p> <ul> <li> <code>cache_dir</code>             (<code>Path | str</code>)         \u2013          <p>Directory to store pickled objects in.</p> </li> </ul> Source code in <code>webs/data/file.py</code> <pre><code>def __init__(\n    self,\n    cache_dir: pathlib.Path | str,\n) -&gt; None:\n    self.cache_dir = pathlib.Path(cache_dir).resolve()\n</code></pre>"},{"location":"api/data/file/#webs.data.file.PickleFileTransformer.is_identifier","title":"is_identifier()","text":"<pre><code>is_identifier(obj: Any) -&gt; bool\n</code></pre> <p>Check if the object is an identifier instance.</p> Source code in <code>webs/data/file.py</code> <pre><code>def is_identifier(self, obj: Any) -&gt; bool:\n    \"\"\"Check if the object is an identifier instance.\"\"\"\n    return isinstance(obj, Identifier)\n</code></pre>"},{"location":"api/data/file/#webs.data.file.PickleFileTransformer.transform","title":"transform()","text":"<pre><code>transform(obj: T) -&gt; Identifier\n</code></pre> <p>Transform the object into an identifier.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>T</code>)         \u2013          <p>Object to transform.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Identifier</code>         \u2013          <p>Identifier object that can be used to resolve <code>obj</code>.</p> </li> </ul> Source code in <code>webs/data/file.py</code> <pre><code>def transform(self, obj: T) -&gt; Identifier:\n    \"\"\"Transform the object into an identifier.\n\n    Args:\n        obj: Object to transform.\n\n    Returns:\n        Identifier object that can be used to resolve `obj`.\n    \"\"\"\n    identifier = Identifier(self.cache_dir, uuid.uuid4())\n    filepath = identifier.path()\n    filepath.parent.mkdir(parents=True, exist_ok=True)\n\n    with open(filepath, 'wb', buffering=0) as f:\n        pickle.dump(obj, f)\n\n    return identifier\n</code></pre>"},{"location":"api/data/file/#webs.data.file.PickleFileTransformer.resolve","title":"resolve()","text":"<pre><code>resolve(identifier: Identifier) -&gt; Any\n</code></pre> <p>Resolve an object from an identifier.</p> <p>Parameters:</p> <ul> <li> <code>identifier</code>             (<code>Identifier</code>)         \u2013          <p>Identifier to an object.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Any</code>         \u2013          <p>The resolved object.</p> </li> </ul> Source code in <code>webs/data/file.py</code> <pre><code>def resolve(self, identifier: Identifier) -&gt; Any:\n    \"\"\"Resolve an object from an identifier.\n\n    Args:\n        identifier: Identifier to an object.\n\n    Returns:\n        The resolved object.\n    \"\"\"\n    filepath = identifier.path()\n    with open(filepath, 'rb') as f:\n        obj = pickle.load(f)\n    filepath.unlink()\n    return obj\n</code></pre>"},{"location":"api/data/filter/","title":"webs.data.filter","text":"<code>webs/data/filter.py</code>"},{"location":"api/data/filter/#webs.data.filter.Filter","title":"Filter","text":"<p>             Bases: <code>Protocol</code></p> <p>Filter protocol.</p>"},{"location":"api/data/filter/#webs.data.filter.Filter.__call__","title":"__call__()","text":"<pre><code>__call__(obj: Any) -&gt; bool\n</code></pre> <p>Check if an abject passes through the filter.</p> Source code in <code>webs/data/filter.py</code> <pre><code>def __call__(self, obj: Any) -&gt; bool:\n    \"\"\"Check if an abject passes through the filter.\"\"\"\n    ...\n</code></pre>"},{"location":"api/data/filter/#webs.data.filter.NullFilter","title":"NullFilter","text":"<p>Null filter that lets all objects pass through.</p>"},{"location":"api/data/filter/#webs.data.filter.NullFilter.__call__","title":"__call__()","text":"<pre><code>__call__(obj: Any) -&gt; bool\n</code></pre> <p>Check if an object passes through the filter.</p> Source code in <code>webs/data/filter.py</code> <pre><code>def __call__(self, obj: Any) -&gt; bool:\n    \"\"\"Check if an object passes through the filter.\"\"\"\n    return True\n</code></pre>"},{"location":"api/data/filter/#webs.data.filter.ObjectSizeFilter","title":"ObjectSizeFilter","text":"<pre><code>ObjectSizeFilter(\n    *, min_bytes: int = 0, max_bytes: float = math.inf\n)\n</code></pre> <p>Object size filter.</p> <p>Checks if the size of an object (computed using <code>sys.getsizeof()</code>) is greater than a minimum size and less than a maximum size.</p> Warning <p><code>sys.getsizeof()</code> does not count the size of objects referred to by the main object.</p> <p>Parameters:</p> <ul> <li> <code>min_bytes</code>             (<code>int</code>, default:                 <code>0</code> )         \u2013          <p>Minimum size threshold (inclusive) to pass through the filter.</p> </li> <li> <code>max_bytes</code>             (<code>float</code>, default:                 <code>inf</code> )         \u2013          <p>Maximum size threshold (inclusive) to pass through the filter.</p> </li> </ul> Source code in <code>webs/data/filter.py</code> <pre><code>def __init__(\n    self,\n    *,\n    min_bytes: int = 0,\n    max_bytes: float = math.inf,\n) -&gt; None:\n    self.min_bytes = min_bytes\n    self.max_bytes = max_bytes\n</code></pre>"},{"location":"api/data/filter/#webs.data.filter.ObjectSizeFilter.__call__","title":"__call__()","text":"<pre><code>__call__(obj: Any) -&gt; bool\n</code></pre> <p>Check if an object passes through the filter.</p> Source code in <code>webs/data/filter.py</code> <pre><code>def __call__(self, obj: Any) -&gt; bool:\n    \"\"\"Check if an object passes through the filter.\"\"\"\n    size = sys.getsizeof(obj)\n    return self.min_bytes &lt;= size &lt;= self.max_bytes\n</code></pre>"},{"location":"api/data/filter/#webs.data.filter.ObjectTypeFilter","title":"ObjectTypeFilter","text":"<pre><code>ObjectTypeFilter(*types: type)\n</code></pre> <p>Object type filter.</p> <p>Checks if an object is of a certain type.</p> <p>Parameters:</p> <ul> <li> <code>types</code>             (<code>type</code>, default:                 <code>()</code> )         \u2013          <p>Types to check.</p> </li> </ul> Source code in <code>webs/data/filter.py</code> <pre><code>def __init__(self, *types: type) -&gt; None:\n    self.types = types\n</code></pre>"},{"location":"api/data/filter/#webs.data.filter.ObjectTypeFilter.__call__","title":"__call__()","text":"<pre><code>__call__(obj: Any) -&gt; bool\n</code></pre> <p>Check if an object passes through the filter.</p> Source code in <code>webs/data/filter.py</code> <pre><code>def __call__(self, obj: Any) -&gt; bool:\n    \"\"\"Check if an object passes through the filter.\"\"\"\n    return isinstance(obj, self.types)\n</code></pre>"},{"location":"api/data/filter/#webs.data.filter.PickleSizeFilter","title":"PickleSizeFilter","text":"<pre><code>PickleSizeFilter(\n    *, min_bytes: int = 0, max_bytes: float = math.inf\n)\n</code></pre> <p>Object size filter.</p> <p>Checks if the size of an object (computed using size of the pickled object) is greater than a minimum size and less than a maximum size.</p> Warning <p>Pickling large objects can take significant time.</p> <p>Parameters:</p> <ul> <li> <code>min_bytes</code>             (<code>int</code>, default:                 <code>0</code> )         \u2013          <p>Minimum size threshold (inclusive) to pass through the filter.</p> </li> <li> <code>max_bytes</code>             (<code>float</code>, default:                 <code>inf</code> )         \u2013          <p>Maximum size threshold (inclusive) to pass through the filter.</p> </li> </ul> Source code in <code>webs/data/filter.py</code> <pre><code>def __init__(\n    self,\n    *,\n    min_bytes: int = 0,\n    max_bytes: float = math.inf,\n) -&gt; None:\n    self.min_bytes = min_bytes\n    self.max_bytes = max_bytes\n</code></pre>"},{"location":"api/data/filter/#webs.data.filter.PickleSizeFilter.__call__","title":"__call__()","text":"<pre><code>__call__(obj: Any) -&gt; bool\n</code></pre> <p>Check if an object passes through the filter.</p> Source code in <code>webs/data/filter.py</code> <pre><code>def __call__(self, obj: Any) -&gt; bool:\n    \"\"\"Check if an object passes through the filter.\"\"\"\n    size = len(pickle.dumps(obj))\n    return self.min_bytes &lt;= size &lt;= self.max_bytes\n</code></pre>"},{"location":"api/data/proxy/","title":"webs.data.proxy","text":"<code>webs/data/proxy.py</code>"},{"location":"api/data/proxy/#webs.data.proxy.ProxyTransformer","title":"ProxyTransformer","text":"<pre><code>ProxyTransformer(\n    store: Store[Any], *, extract_target: bool = False\n)\n</code></pre> <p>Proxy object transformer.</p> <p>Transforms objects into proxies which act as the identifier.</p> <p>Parameters:</p> <ul> <li> <code>store</code>             (<code>Store[Any]</code>)         \u2013          <p>Store instance to use for proxying objects.</p> </li> <li> <code>extract_target</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>When <code>True</code>, resolving an identifier (i.e., a proxy) will return the target object. Otherwise, the proxy is returned since a proxy can act as the target object.</p> </li> </ul> Source code in <code>webs/data/proxy.py</code> <pre><code>def __init__(\n    self,\n    store: Store[Any],\n    *,\n    extract_target: bool = False,\n) -&gt; None:\n    self.store = store\n    self.extract_target = extract_target\n</code></pre>"},{"location":"api/data/proxy/#webs.data.proxy.ProxyTransformer.is_identifier","title":"is_identifier()","text":"<pre><code>is_identifier(obj: Any) -&gt; bool\n</code></pre> <p>Check if the object is an identifier instance.</p> Source code in <code>webs/data/proxy.py</code> <pre><code>def is_identifier(self, obj: Any) -&gt; bool:\n    \"\"\"Check if the object is an identifier instance.\"\"\"\n    return isinstance(obj, Proxy)\n</code></pre>"},{"location":"api/data/proxy/#webs.data.proxy.ProxyTransformer.transform","title":"transform()","text":"<pre><code>transform(obj: T) -&gt; Proxy[T]\n</code></pre> <p>Transform the object into an identifier.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>T</code>)         \u2013          <p>Object to transform.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Proxy[T]</code>         \u2013          <p>Identifier object that can be used to resolve <code>obj</code>.</p> </li> </ul> Source code in <code>webs/data/proxy.py</code> <pre><code>def transform(self, obj: T) -&gt; Proxy[T]:\n    \"\"\"Transform the object into an identifier.\n\n    Args:\n        obj: Object to transform.\n\n    Returns:\n        Identifier object that can be used to resolve `obj`.\n    \"\"\"\n    return self.store.proxy(obj)\n</code></pre>"},{"location":"api/data/proxy/#webs.data.proxy.ProxyTransformer.resolve","title":"resolve()","text":"<pre><code>resolve(identifier: Proxy[T]) -&gt; T | Proxy[T]\n</code></pre> <p>Resolve an object from an identifier.</p> <p>Parameters:</p> <ul> <li> <code>identifier</code>             (<code>Proxy[T]</code>)         \u2013          <p>Identifier to an object.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>T | Proxy[T]</code>         \u2013          <p>The resolved object or a proxy of the resolved object depending             on the setting of <code>extract_target</code>.</p> </li> </ul> Source code in <code>webs/data/proxy.py</code> <pre><code>def resolve(self, identifier: Proxy[T]) -&gt; T | Proxy[T]:\n    \"\"\"Resolve an object from an identifier.\n\n    Args:\n        identifier: Identifier to an object.\n\n    Returns:\n        The resolved object or a proxy of the resolved object depending \\\n        on the setting of `extract_target`.\n    \"\"\"\n    obj: T | Proxy[T]\n    if self.extract_target:\n        obj = extract(identifier)\n        self.store.evict(get_key(identifier))\n    else:\n        obj = identifier\n    return obj\n</code></pre>"},{"location":"api/data/transform/","title":"webs.data.transform","text":"<code>webs/data/transform.py</code>"},{"location":"api/data/transform/#webs.data.transform.Transformer","title":"Transformer","text":"<p>             Bases: <code>Protocol[IdentifierT]</code></p> <p>Object transformer protocol.</p>"},{"location":"api/data/transform/#webs.data.transform.Transformer.is_identifier","title":"is_identifier()","text":"<pre><code>is_identifier(obj: T) -&gt; bool\n</code></pre> <p>Check if the object is an identifier instance.</p> Source code in <code>webs/data/transform.py</code> <pre><code>def is_identifier(self, obj: T) -&gt; bool:\n    \"\"\"Check if the object is an identifier instance.\"\"\"\n    ...\n</code></pre>"},{"location":"api/data/transform/#webs.data.transform.Transformer.transform","title":"transform()","text":"<pre><code>transform(obj: T) -&gt; IdentifierT\n</code></pre> <p>Transform the object into an identifier.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>T</code>)         \u2013          <p>Object to transform.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>IdentifierT</code>         \u2013          <p>Identifier object that can be used to resolve <code>obj</code>.</p> </li> </ul> Source code in <code>webs/data/transform.py</code> <pre><code>def transform(self, obj: T) -&gt; IdentifierT:\n    \"\"\"Transform the object into an identifier.\n\n    Args:\n        obj: Object to transform.\n\n    Returns:\n        Identifier object that can be used to resolve `obj`.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/data/transform/#webs.data.transform.Transformer.resolve","title":"resolve()","text":"<pre><code>resolve(identifier: IdentifierT) -&gt; Any\n</code></pre> <p>Resolve an object from an identifier.</p> <p>Parameters:</p> <ul> <li> <code>identifier</code>             (<code>IdentifierT</code>)         \u2013          <p>Identifier to an object.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Any</code>         \u2013          <p>The resolved object.</p> </li> </ul> Source code in <code>webs/data/transform.py</code> <pre><code>def resolve(self, identifier: IdentifierT) -&gt; Any:\n    \"\"\"Resolve an object from an identifier.\n\n    Args:\n        identifier: Identifier to an object.\n\n    Returns:\n        The resolved object.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/data/transform/#webs.data.transform.NullTransformer","title":"NullTransformer","text":"<p>Null transformer that does no transformations.</p>"},{"location":"api/data/transform/#webs.data.transform.NullTransformer.is_identifier","title":"is_identifier()","text":"<pre><code>is_identifier(obj: Any) -&gt; bool\n</code></pre> <p>Check if the object is an identifier instance.</p> <p>Always <code>False</code> in this implementation.</p> Source code in <code>webs/data/transform.py</code> <pre><code>def is_identifier(self, obj: Any) -&gt; bool:\n    \"\"\"Check if the object is an identifier instance.\n\n    Always `False` in this implementation.\n    \"\"\"\n    return False\n</code></pre>"},{"location":"api/data/transform/#webs.data.transform.NullTransformer.transform","title":"transform()","text":"<pre><code>transform(obj: T) -&gt; T\n</code></pre> <p>Transform the object into an identifier.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>T</code>)         \u2013          <p>Object to transform.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>T</code>         \u2013          <p>Identifier object that can be usd to resolve <code>obj</code>.</p> </li> </ul> Source code in <code>webs/data/transform.py</code> <pre><code>def transform(self, obj: T) -&gt; T:\n    \"\"\"Transform the object into an identifier.\n\n    Args:\n        obj: Object to transform.\n\n    Returns:\n        Identifier object that can be usd to resolve `obj`.\n    \"\"\"\n    return obj\n</code></pre>"},{"location":"api/data/transform/#webs.data.transform.NullTransformer.resolve","title":"resolve()","text":"<pre><code>resolve(identifier: Any) -&gt; NoReturn\n</code></pre> <p>Resolve an object from an identifier.</p> <p>Parameters:</p> <ul> <li> <code>identifier</code>             (<code>Any</code>)         \u2013          <p>Identifier to an object.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NoReturn</code>         \u2013          <p>The resolved object.</p> </li> </ul> Source code in <code>webs/data/transform.py</code> <pre><code>def resolve(self, identifier: Any) -&gt; NoReturn:\n    \"\"\"Resolve an object from an identifier.\n\n    Args:\n        identifier: Identifier to an object.\n\n    Returns:\n        The resolved object.\n    \"\"\"\n    raise NotImplementedError(\n        f'{self.__class__.__name__} does not support identifiers',\n    )\n</code></pre>"},{"location":"api/data/transform/#webs.data.transform.TaskDataTransformer","title":"TaskDataTransformer","text":"<pre><code>TaskDataTransformer(\n    transformer: Transformer[IdentifierT],\n    filter_: Filter | None = None,\n)\n</code></pre> <p>             Bases: <code>Generic[IdentifierT]</code></p> <p>Task data transformer.</p> <p>This class combines a simple object <code>Transformer</code> and a <code>Filter</code> into useful methods for transforming the positional arguments, keyword arguments, and results of tasks.</p> <p>Parameters:</p> <ul> <li> <code>transformer</code>             (<code>Transformer[IdentifierT]</code>)         \u2013          <p>Object transformer.</p> </li> <li> <code>filter_</code>             (<code>Filter | None</code>, default:                 <code>None</code> )         \u2013          <p>A filter which when called on an object returns <code>True</code> if the object should be transformed.</p> </li> </ul> Source code in <code>webs/data/transform.py</code> <pre><code>def __init__(\n    self,\n    transformer: Transformer[IdentifierT],\n    filter_: Filter | None = None,\n) -&gt; None:\n    self.transformer = transformer\n    self.filter_ = NullFilter() if filter_ is None else filter_\n</code></pre>"},{"location":"api/data/transform/#webs.data.transform.TaskDataTransformer.transform","title":"transform()","text":"<pre><code>transform(obj: T) -&gt; T | IdentifierT\n</code></pre> <p>Transform an object.</p> <p>Transforms <code>obj</code> into an identifier if it passes the filter check. The identifier can later be used to resolve the object.</p> Source code in <code>webs/data/transform.py</code> <pre><code>def transform(self, obj: T) -&gt; T | IdentifierT:\n    \"\"\"Transform an object.\n\n    Transforms `obj` into an identifier if it passes the filter check.\n    The identifier can later be used to resolve the object.\n    \"\"\"\n    if self.filter_(obj):\n        return self.transformer.transform(obj)\n    else:\n        return obj\n</code></pre>"},{"location":"api/data/transform/#webs.data.transform.TaskDataTransformer.transform_iterable","title":"transform_iterable()","text":"<pre><code>transform_iterable(\n    iterable: Iterable[T],\n) -&gt; tuple[T | IdentifierT, ...]\n</code></pre> <p>Transform each object in an iterable.</p> Source code in <code>webs/data/transform.py</code> <pre><code>def transform_iterable(\n    self,\n    iterable: Iterable[T],\n) -&gt; tuple[T | IdentifierT, ...]:\n    \"\"\"Transform each object in an iterable.\"\"\"\n    return tuple(self.transform(obj) for obj in iterable)\n</code></pre>"},{"location":"api/data/transform/#webs.data.transform.TaskDataTransformer.transform_mapping","title":"transform_mapping()","text":"<pre><code>transform_mapping(\n    mapping: Mapping[K, T]\n) -&gt; dict[K, Any]\n</code></pre> <p>Transform each value in a mapping.</p> Source code in <code>webs/data/transform.py</code> <pre><code>def transform_mapping(self, mapping: Mapping[K, T]) -&gt; dict[K, Any]:\n    \"\"\"Transform each value in a mapping.\"\"\"\n    return {k: self.transform(v) for k, v in mapping.items()}\n</code></pre>"},{"location":"api/data/transform/#webs.data.transform.TaskDataTransformer.resolve","title":"resolve()","text":"<pre><code>resolve(obj: Any) -&gt; Any\n</code></pre> <p>Resolve an object.</p> <p>Resolves the object if it is an identifier, otherwise returns the passed object.</p> Source code in <code>webs/data/transform.py</code> <pre><code>def resolve(self, obj: Any) -&gt; Any:\n    \"\"\"Resolve an object.\n\n    Resolves the object if it is an identifier, otherwise returns the\n    passed object.\n    \"\"\"\n    if self.transformer.is_identifier(obj):\n        return self.transformer.resolve(obj)\n    else:\n        return obj\n</code></pre>"},{"location":"api/data/transform/#webs.data.transform.TaskDataTransformer.resolve_iterable","title":"resolve_iterable()","text":"<pre><code>resolve_iterable(\n    iterable: Iterable[Any],\n) -&gt; tuple[Any, ...]\n</code></pre> <p>Resolve each object in an iterable.</p> Source code in <code>webs/data/transform.py</code> <pre><code>def resolve_iterable(self, iterable: Iterable[Any]) -&gt; tuple[Any, ...]:\n    \"\"\"Resolve each object in an iterable.\"\"\"\n    return tuple(self.resolve(obj) for obj in iterable)\n</code></pre>"},{"location":"api/data/transform/#webs.data.transform.TaskDataTransformer.resolve_mapping","title":"resolve_mapping()","text":"<pre><code>resolve_mapping(mapping: Mapping[K, Any]) -&gt; dict[K, Any]\n</code></pre> <p>Resolve each value in a mapping.</p> Source code in <code>webs/data/transform.py</code> <pre><code>def resolve_mapping(self, mapping: Mapping[K, Any]) -&gt; dict[K, Any]:\n    \"\"\"Resolve each value in a mapping.\"\"\"\n    return {k: self.resolve(v) for k, v in mapping.items()}\n</code></pre>"},{"location":"api/executor/","title":"webs.executor","text":"<code>webs/executor/__init__.py</code>"},{"location":"api/executor/config/","title":"webs.executor.config","text":"<code>webs/executor/config.py</code>"},{"location":"api/executor/config/#webs.executor.config.ExecutorConfig","title":"ExecutorConfig","text":"<p>             Bases: <code>Config</code>, <code>ABC</code></p> <p>Executor configuration abstract base class.</p>"},{"location":"api/executor/config/#webs.executor.config.ExecutorConfig.add_argument_group","title":"add_argument_group()  <code>classmethod</code>","text":"<pre><code>add_argument_group(\n    parser: ArgumentParser,\n    *,\n    argv: Sequence[str] | None = None,\n    required: bool = True\n) -&gt; None\n</code></pre> <p>Add model fields as arguments of an argument group on the parser.</p> <p>Parameters:</p> <ul> <li> <code>parser</code>             (<code>ArgumentParser</code>)         \u2013          <p>Parser to add a new argument group to.</p> </li> <li> <code>argv</code>             (<code>Sequence[str] | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional sequence of string arguments.</p> </li> <li> <code>required</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Mark arguments without defaults as required.</p> </li> </ul> Source code in <code>webs/config.py</code> <pre><code>@classmethod\ndef add_argument_group(\n    cls,\n    parser: argparse.ArgumentParser,\n    *,\n    argv: Sequence[str] | None = None,\n    required: bool = True,\n) -&gt; None:\n    \"\"\"Add model fields as arguments of an argument group on the parser.\n\n    Args:\n        parser: Parser to add a new argument group to.\n        argv: Optional sequence of string arguments.\n        required: Mark arguments without defaults as required.\n    \"\"\"\n    group = parser.add_argument_group(cls.__name__)\n    for field_name, field_info in cls.model_fields.items():\n        arg_name = field_name.replace('_', '-').lower()\n        group.add_argument(\n            f'--{arg_name}',\n            dest=field_name,\n            # type=field_info.annotation,\n            default=field_info.get_default(),\n            required=field_info.is_required() and required,\n            help=field_info.description,\n        )\n</code></pre>"},{"location":"api/executor/config/#webs.executor.config.ExecutorConfig.get_executor","title":"get_executor()  <code>abstractmethod</code>","text":"<pre><code>get_executor() -&gt; Executor\n</code></pre> <p>Create an executor instance from the config.</p> Source code in <code>webs/executor/config.py</code> <pre><code>@abc.abstractmethod\ndef get_executor(self) -&gt; Executor:\n    \"\"\"Create an executor instance from the config.\"\"\"\n    ...\n</code></pre>"},{"location":"api/executor/config/#webs.executor.config.ExecutorChoicesConfig","title":"ExecutorChoicesConfig","text":"<p>             Bases: <code>Config</code></p> <p>Executor choice configuration.</p>"},{"location":"api/executor/config/#webs.executor.config.ExecutorChoicesConfig.add_argument_group","title":"add_argument_group()  <code>classmethod</code>","text":"<pre><code>add_argument_group(\n    parser: ArgumentParser,\n    *,\n    argv: Sequence[str] | None = None,\n    required: bool = True\n) -&gt; None\n</code></pre> <p>Add model fields as arguments of an argument group on the parser.</p> <p>Parameters:</p> <ul> <li> <code>parser</code>             (<code>ArgumentParser</code>)         \u2013          <p>Parser to add a new argument group to.</p> </li> <li> <code>argv</code>             (<code>Sequence[str] | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional sequence of string arguments.</p> </li> <li> <code>required</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Mark arguments without defaults as required.</p> </li> </ul> Source code in <code>webs/executor/config.py</code> <pre><code>@classmethod\ndef add_argument_group(\n    cls,\n    parser: argparse.ArgumentParser,\n    *,\n    argv: Sequence[str] | None = None,\n    required: bool = True,\n) -&gt; None:\n    \"\"\"Add model fields as arguments of an argument group on the parser.\n\n    Args:\n        parser: Parser to add a new argument group to.\n        argv: Optional sequence of string arguments.\n        required: Mark arguments without defaults as required.\n    \"\"\"\n    configs = get_registered()\n\n    group = parser.add_argument_group(cls.__name__)\n    group.add_argument(\n        '--executor',\n        choices=sorted(configs.keys()),\n        required=required,\n        help='executor to use',\n    )\n\n    executor_type: str | None = None\n    if argv is not None and '--executor' in argv:\n        executor_type = argv[argv.index('--executor') + 1]\n\n    for name, config_type in configs.items():\n        config_type.add_argument_group(\n            parser,\n            argv=argv,\n            required=name == executor_type,\n        )\n</code></pre>"},{"location":"api/executor/dag/","title":"webs.executor.dag","text":"<code>webs/executor/dag.py</code>"},{"location":"api/executor/dag/#webs.executor.dag.DAGExecutor","title":"DAGExecutor","text":"<pre><code>DAGExecutor(executor: Executor)\n</code></pre> <p>             Bases: <code>Executor</code></p> <p>Executor wrapper that adds DAG-like features.</p> <p>An <code>Executor</code> implementation that wraps another executor with logic for delaying task submission until all <code>Future</code> instances which are args or kwargs of a task have completed. In other words, child tasks will not be scheduled until the results of the child's parent tasks are available.</p> <p>Parameters:</p> <ul> <li> <code>executor</code>             (<code>Executor</code>)         \u2013          <p>Executor to wrap.</p> </li> </ul> Source code in <code>webs/executor/dag.py</code> <pre><code>def __init__(self, executor: Executor) -&gt; None:\n    self.executor = executor\n    self._tasks: dict[Future[Any], _Task[Any, Any]] = {}\n</code></pre>"},{"location":"api/executor/dag/#webs.executor.dag.DAGExecutor.submit","title":"submit()","text":"<pre><code>submit(\n    function: Callable[P, T],\n    /,\n    *args: args,\n    **kwargs: kwargs,\n) -&gt; Future[T]\n</code></pre> <p>Schedule the callable to be executed.</p> <p>Parameters:</p> <ul> <li> <code>function</code>             (<code>Callable[P, T]</code>)         \u2013          <p>Callable to execute.</p> </li> <li> <code>args</code>             (<code>args</code>, default:                 <code>()</code> )         \u2013          <p>Positional arguments.</p> </li> <li> <code>kwargs</code>             (<code>kwargs</code>, default:                 <code>{}</code> )         \u2013          <p>Keyword arguments.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Future[T]</code>         \u2013          <p><code>Future</code> object representing the             result of the execution of the callable.</p> </li> </ul> Source code in <code>webs/executor/dag.py</code> <pre><code>def submit(\n    self,\n    function: Callable[P, T],\n    /,\n    *args: P.args,\n    **kwargs: P.kwargs,\n) -&gt; Future[T]:\n    \"\"\"Schedule the callable to be executed.\n\n    Args:\n        function: Callable to execute.\n        args: Positional arguments.\n        kwargs: Keyword arguments.\n\n    Returns:\n        [`Future`][concurrent.futures.Future] object representing the \\\n        result of the execution of the callable.\n    \"\"\"\n    client_future: Future[T] = Future()\n    task = _Task(self.executor, function, args, kwargs, client_future)\n    self._tasks[client_future] = task\n    client_future.add_done_callback(self._task_future_callback)\n    return client_future\n</code></pre>"},{"location":"api/executor/dag/#webs.executor.dag.DAGExecutor.map","title":"map()","text":"<pre><code>map(\n    function: Callable[P, T],\n    *iterables: Iterable[args],\n    timeout: float | None = None,\n    chunksize: int = 1\n) -&gt; Iterator[T]\n</code></pre> <p>Map a function onto iterables of arguments.</p> <p>Parameters:</p> <ul> <li> <code>function</code>             (<code>Callable[P, T]</code>)         \u2013          <p>A callable that will take as many arguments as there are passed iterables.</p> </li> <li> <code>iterables</code>             (<code>Iterable[args]</code>, default:                 <code>()</code> )         \u2013          <p>Variable number of iterables.</p> </li> <li> <code>timeout</code>             (<code>float | None</code>, default:                 <code>None</code> )         \u2013          <p>The maximum number of seconds to wait. If None, then there is no limit on the wait time.</p> </li> <li> <code>chunksize</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>If greater than one, the iterables will be chopped into chunks of size chunksize and submitted to the executor. If set to one, the items in the list will be sent one at a time.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Iterator[T]</code>         \u2013          <p>An iterator equivalent to: <code>map(func, *iterables)</code> but the calls             may be evaluated out-of-order.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013          <p>if chunksize is less than one.</p> </li> </ul> Source code in <code>webs/executor/dag.py</code> <pre><code>def map(\n    self,\n    function: Callable[P, T],\n    *iterables: Iterable[P.args],\n    timeout: float | None = None,\n    chunksize: int = 1,\n) -&gt; Iterator[T]:\n    \"\"\"Map a function onto iterables of arguments.\n\n    Args:\n        function: A callable that will take as many arguments as there are\n            passed iterables.\n        iterables: Variable number of iterables.\n        timeout: The maximum number of seconds to wait. If None, then there\n            is no limit on the wait time.\n        chunksize: If greater than one, the iterables will be chopped into\n            chunks of size chunksize and submitted to the executor. If set\n            to one, the items in the list will be sent one at a time.\n\n    Returns:\n        An iterator equivalent to: `map(func, *iterables)` but the calls \\\n        may be evaluated out-of-order.\n\n    Raises:\n        ValueError: if chunksize is less than one.\n    \"\"\"\n    # Based on concurrent.futures.ProcessPoolExecutor.map()\n    # https://github.com/python/cpython/blob/37959e25cbbe1d207c660b5bc9583b9bd1403f1a/Lib/concurrent/futures/process.py\n    if chunksize &lt; 1:\n        raise ValueError('chunksize must be &gt;= 1.')\n\n    results = super().map(\n        functools.partial(_process_chunk, function),\n        _get_chunks(*iterables, chunksize=chunksize),\n        timeout=timeout,\n    )\n\n    def _result_iterator(\n        iterable: Iterator[list[T]],\n    ) -&gt; Generator[T, None, None]:\n        for element in iterable:\n            element.reverse()\n            while element:\n                yield element.pop()\n\n    return _result_iterator(results)\n</code></pre>"},{"location":"api/executor/dag/#webs.executor.dag.DAGExecutor.shutdown","title":"shutdown()","text":"<pre><code>shutdown(\n    wait: bool = True, *, cancel_futures: bool = False\n) -&gt; None\n</code></pre> <p>Shutdown the executor.</p> <p>Parameters:</p> <ul> <li> <code>wait</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Wait on all pending futures to complete.</p> </li> <li> <code>cancel_futures</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Cancel all pending futures that the executor has not started running. Only used in Python 3.9 and later.</p> </li> </ul> Source code in <code>webs/executor/dag.py</code> <pre><code>def shutdown(\n    self,\n    wait: bool = True,\n    *,\n    cancel_futures: bool = False,\n) -&gt; None:\n    \"\"\"Shutdown the executor.\n\n    Args:\n        wait: Wait on all pending futures to complete.\n        cancel_futures: Cancel all pending futures that the executor\n            has not started running. Only used in Python 3.9 and later.\n    \"\"\"\n    if sys.version_info &gt;= (3, 9):  # pragma: &gt;=3.9 cover\n        self.executor.shutdown(wait=wait, cancel_futures=cancel_futures)\n    else:  # pragma: &lt;3.9 cover\n        self.executor.shutdown(wait=wait)\n</code></pre>"},{"location":"api/executor/dask/","title":"webs.executor.dask","text":"<code>webs/executor/dask.py</code>"},{"location":"api/executor/dask/#webs.executor.dask.DaskDistributedExecutor","title":"DaskDistributedExecutor","text":"<pre><code>DaskDistributedExecutor(client: Client)\n</code></pre> <p>             Bases: <code>Executor</code></p> <p>Dask task execution engine.</p> <p>Parameters:</p> <ul> <li> <code>client</code>             (<code>Client</code>)         \u2013          <p>Dask distributed client.</p> </li> </ul> Source code in <code>webs/executor/dask.py</code> <pre><code>def __init__(self, client: Client) -&gt; None:\n    self.client = client\n</code></pre>"},{"location":"api/executor/dask/#webs.executor.dask.DaskDistributedExecutor.submit","title":"submit()","text":"<pre><code>submit(\n    function: Callable[P, T],\n    /,\n    *args: args,\n    **kwargs: kwargs,\n) -&gt; Future[T]\n</code></pre> <p>Schedule the callable to be executed.</p> <p>Parameters:</p> <ul> <li> <code>function</code>             (<code>Callable[P, T]</code>)         \u2013          <p>Callable to execute.</p> </li> <li> <code>args</code>             (<code>args</code>, default:                 <code>()</code> )         \u2013          <p>Positional arguments.</p> </li> <li> <code>kwargs</code>             (<code>kwargs</code>, default:                 <code>{}</code> )         \u2013          <p>Keyword arguments.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Future[T]</code>         \u2013          <p><code>Future</code>-like object representing             the result of the execution of the callable.</p> </li> </ul> Source code in <code>webs/executor/dask.py</code> <pre><code>def submit(\n    self,\n    function: Callable[P, T],\n    /,\n    *args: P.args,\n    **kwargs: P.kwargs,\n) -&gt; Future[T]:\n    \"\"\"Schedule the callable to be executed.\n\n    Args:\n        function: Callable to execute.\n        args: Positional arguments.\n        kwargs: Keyword arguments.\n\n    Returns:\n        [`Future`][concurrent.futures.Future]-like object representing \\\n        the result of the execution of the callable.\n    \"\"\"\n    return self.client.submit(function, *args, **kwargs)\n</code></pre>"},{"location":"api/executor/dask/#webs.executor.dask.DaskDistributedExecutor.map","title":"map()","text":"<pre><code>map(\n    function: Callable[P, T],\n    *iterables: Iterable[args],\n    timeout: float | None = None,\n    chunksize: int = 1\n) -&gt; Iterator[T]\n</code></pre> <p>Map a function onto iterables of arguments.</p> <p>Parameters:</p> <ul> <li> <code>function</code>             (<code>Callable[P, T]</code>)         \u2013          <p>A callable that will take as many arguments as there are passed iterables.</p> </li> <li> <code>iterables</code>             (<code>Iterable[args]</code>, default:                 <code>()</code> )         \u2013          <p>Variable number of iterables.</p> </li> <li> <code>timeout</code>             (<code>float | None</code>, default:                 <code>None</code> )         \u2013          <p>The maximum number of seconds to wait. If None, then there is no limit on the wait time.</p> </li> <li> <code>chunksize</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Sets the Dask batch size.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Iterator[T]</code>         \u2013          <p>An iterator equivalent to: <code>map(func, *iterables)</code> but the calls             may be evaluated out-of-order.</p> </li> </ul> Source code in <code>webs/executor/dask.py</code> <pre><code>def map(\n    self,\n    function: Callable[P, T],\n    *iterables: Iterable[P.args],\n    timeout: float | None = None,\n    chunksize: int = 1,\n) -&gt; Iterator[T]:\n    \"\"\"Map a function onto iterables of arguments.\n\n    Args:\n        function: A callable that will take as many arguments as there are\n            passed iterables.\n        iterables: Variable number of iterables.\n        timeout: The maximum number of seconds to wait. If None, then there\n            is no limit on the wait time.\n        chunksize: Sets the Dask batch size.\n\n    Returns:\n        An iterator equivalent to: `map(func, *iterables)` but the calls \\\n        may be evaluated out-of-order.\n    \"\"\"\n    # Based on the Parsl implementation.\n    # https://github.com/Parsl/parsl/blob/7fba7d634ccade76618ee397d3c951c5cbf2cd49/parsl/concurrent/__init__.py#L58\n    futures = self.client.map(function, *iterables, batch_size=chunksize)\n\n    def _result_iterator() -&gt; Generator[T, None, None]:\n        futures.reverse()\n        while futures:\n            yield futures.pop().result(timeout)\n\n    return _result_iterator()\n</code></pre>"},{"location":"api/executor/dask/#webs.executor.dask.DaskDistributedExecutor.shutdown","title":"shutdown()","text":"<pre><code>shutdown(\n    wait: bool = True, *, cancel_futures: bool = False\n) -&gt; None\n</code></pre> <p>Shutdown the client.</p> Source code in <code>webs/executor/dask.py</code> <pre><code>def shutdown(\n    self,\n    wait: bool = True,\n    *,\n    cancel_futures: bool = False,\n) -&gt; None:\n    \"\"\"Shutdown the client.\"\"\"\n    # Note: wait and cancel_futures are not implemented.\n    self.client.close()\n</code></pre>"},{"location":"api/executor/dask/#webs.executor.dask.DaskDistributedConfig","title":"DaskDistributedConfig","text":"<p>             Bases: <code>ExecutorConfig</code></p> <p>Dask Distributed configuration.</p> <p>Attributes:</p> <ul> <li> <code>endpoint</code>         \u2013          <p>Globus Compute endpoint UUID.</p> </li> </ul>"},{"location":"api/executor/dask/#webs.executor.dask.DaskDistributedConfig.add_argument_group","title":"add_argument_group()  <code>classmethod</code>","text":"<pre><code>add_argument_group(\n    parser: ArgumentParser,\n    *,\n    argv: Sequence[str] | None = None,\n    required: bool = True\n) -&gt; None\n</code></pre> <p>Add model fields as arguments of an argument group on the parser.</p> <p>Parameters:</p> <ul> <li> <code>parser</code>             (<code>ArgumentParser</code>)         \u2013          <p>Parser to add a new argument group to.</p> </li> <li> <code>argv</code>             (<code>Sequence[str] | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional sequence of string arguments.</p> </li> <li> <code>required</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Mark arguments without defaults as required.</p> </li> </ul> Source code in <code>webs/config.py</code> <pre><code>@classmethod\ndef add_argument_group(\n    cls,\n    parser: argparse.ArgumentParser,\n    *,\n    argv: Sequence[str] | None = None,\n    required: bool = True,\n) -&gt; None:\n    \"\"\"Add model fields as arguments of an argument group on the parser.\n\n    Args:\n        parser: Parser to add a new argument group to.\n        argv: Optional sequence of string arguments.\n        required: Mark arguments without defaults as required.\n    \"\"\"\n    group = parser.add_argument_group(cls.__name__)\n    for field_name, field_info in cls.model_fields.items():\n        arg_name = field_name.replace('_', '-').lower()\n        group.add_argument(\n            f'--{arg_name}',\n            dest=field_name,\n            # type=field_info.annotation,\n            default=field_info.get_default(),\n            required=field_info.is_required() and required,\n            help=field_info.description,\n        )\n</code></pre>"},{"location":"api/executor/dask/#webs.executor.dask.DaskDistributedConfig.get_executor","title":"get_executor()","text":"<pre><code>get_executor() -&gt; DaskDistributedExecutor\n</code></pre> <p>Create an executor instance from the config.</p> Source code in <code>webs/executor/dask.py</code> <pre><code>def get_executor(self) -&gt; DaskDistributedExecutor:\n    \"\"\"Create an executor instance from the config.\"\"\"\n    if self.dask_scheduler_address is not None:\n        client = Client(self.dask_scheduler_address)\n    else:\n        client = Client(\n            n_workers=self.dask_workers,\n            processes=not self.dask_use_threads,\n            dashboard_address=None,\n        )\n    return DaskDistributedExecutor(client)\n</code></pre>"},{"location":"api/executor/globus/","title":"webs.executor.globus","text":"<code>webs/executor/globus.py</code>"},{"location":"api/executor/globus/#webs.executor.globus.GlobusComputeConfig","title":"GlobusComputeConfig","text":"<p>             Bases: <code>ExecutorConfig</code></p> <p>Globus Compute configuration.</p> <p>Attributes:</p> <ul> <li> <code>endpoint</code>             (<code>str</code>)         \u2013          <p>Globus Compute endpoint UUID.</p> </li> </ul>"},{"location":"api/executor/globus/#webs.executor.globus.GlobusComputeConfig.add_argument_group","title":"add_argument_group()  <code>classmethod</code>","text":"<pre><code>add_argument_group(\n    parser: ArgumentParser,\n    *,\n    argv: Sequence[str] | None = None,\n    required: bool = True\n) -&gt; None\n</code></pre> <p>Add model fields as arguments of an argument group on the parser.</p> <p>Parameters:</p> <ul> <li> <code>parser</code>             (<code>ArgumentParser</code>)         \u2013          <p>Parser to add a new argument group to.</p> </li> <li> <code>argv</code>             (<code>Sequence[str] | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional sequence of string arguments.</p> </li> <li> <code>required</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Mark arguments without defaults as required.</p> </li> </ul> Source code in <code>webs/config.py</code> <pre><code>@classmethod\ndef add_argument_group(\n    cls,\n    parser: argparse.ArgumentParser,\n    *,\n    argv: Sequence[str] | None = None,\n    required: bool = True,\n) -&gt; None:\n    \"\"\"Add model fields as arguments of an argument group on the parser.\n\n    Args:\n        parser: Parser to add a new argument group to.\n        argv: Optional sequence of string arguments.\n        required: Mark arguments without defaults as required.\n    \"\"\"\n    group = parser.add_argument_group(cls.__name__)\n    for field_name, field_info in cls.model_fields.items():\n        arg_name = field_name.replace('_', '-').lower()\n        group.add_argument(\n            f'--{arg_name}',\n            dest=field_name,\n            # type=field_info.annotation,\n            default=field_info.get_default(),\n            required=field_info.is_required() and required,\n            help=field_info.description,\n        )\n</code></pre>"},{"location":"api/executor/globus/#webs.executor.globus.GlobusComputeConfig.get_executor","title":"get_executor()","text":"<pre><code>get_executor() -&gt; Executor\n</code></pre> <p>Create an executor instance from the config.</p> Source code in <code>webs/executor/globus.py</code> <pre><code>def get_executor(self) -&gt; globus_compute_sdk.Executor:\n    \"\"\"Create an executor instance from the config.\"\"\"\n    return globus_compute_sdk.Executor(self.endpoint)\n</code></pre>"},{"location":"api/executor/parsl/","title":"webs.executor.parsl","text":"<code>webs/executor/parsl.py</code>"},{"location":"api/executor/parsl/#webs.executor.parsl.ParslConfig","title":"ParslConfig","text":"<p>             Bases: <code>ExecutorConfig</code></p> <p>Parsl configuration.</p> <p>Attributes:</p> <ul> <li> <code>endpoint</code>         \u2013          <p>Globus Compute endpoint UUID.</p> </li> </ul>"},{"location":"api/executor/parsl/#webs.executor.parsl.ParslConfig.add_argument_group","title":"add_argument_group()  <code>classmethod</code>","text":"<pre><code>add_argument_group(\n    parser: ArgumentParser,\n    *,\n    argv: Sequence[str] | None = None,\n    required: bool = True\n) -&gt; None\n</code></pre> <p>Add model fields as arguments of an argument group on the parser.</p> <p>Parameters:</p> <ul> <li> <code>parser</code>             (<code>ArgumentParser</code>)         \u2013          <p>Parser to add a new argument group to.</p> </li> <li> <code>argv</code>             (<code>Sequence[str] | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional sequence of string arguments.</p> </li> <li> <code>required</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Mark arguments without defaults as required.</p> </li> </ul> Source code in <code>webs/config.py</code> <pre><code>@classmethod\ndef add_argument_group(\n    cls,\n    parser: argparse.ArgumentParser,\n    *,\n    argv: Sequence[str] | None = None,\n    required: bool = True,\n) -&gt; None:\n    \"\"\"Add model fields as arguments of an argument group on the parser.\n\n    Args:\n        parser: Parser to add a new argument group to.\n        argv: Optional sequence of string arguments.\n        required: Mark arguments without defaults as required.\n    \"\"\"\n    group = parser.add_argument_group(cls.__name__)\n    for field_name, field_info in cls.model_fields.items():\n        arg_name = field_name.replace('_', '-').lower()\n        group.add_argument(\n            f'--{arg_name}',\n            dest=field_name,\n            # type=field_info.annotation,\n            default=field_info.get_default(),\n            required=field_info.is_required() and required,\n            help=field_info.description,\n        )\n</code></pre>"},{"location":"api/executor/parsl/#webs.executor.parsl.ParslConfig.get_executor_config","title":"get_executor_config()","text":"<pre><code>get_executor_config() -&gt; Config\n</code></pre> <p>Create a Parsl config from this config.</p> Source code in <code>webs/executor/parsl.py</code> <pre><code>def get_executor_config(self) -&gt; Config:\n    \"\"\"Create a Parsl config from this config.\"\"\"\n    workers = (\n        self.parsl_workers\n        if self.parsl_workers is not None\n        else multiprocessing.cpu_count()\n    )\n\n    if self.parsl_use_threads:\n        executor = ThreadPoolExecutor(max_threads=workers)\n    else:\n        executor = HighThroughputExecutor(\n            label='htex-local',\n            max_workers_per_node=workers,\n            address=address_by_hostname(),\n            cores_per_worker=1,\n            provider=LocalProvider(\n                channel=LocalChannel(),\n                init_blocks=1,\n                max_blocks=1,\n            ),\n        )\n\n    return Config(executors=[executor], run_dir=self.parsl_run_dir)\n</code></pre>"},{"location":"api/executor/parsl/#webs.executor.parsl.ParslConfig.get_executor","title":"get_executor()","text":"<pre><code>get_executor() -&gt; Executor\n</code></pre> <p>Create an executor instance from the config.</p> Source code in <code>webs/executor/parsl.py</code> <pre><code>def get_executor(self) -&gt; globus_compute_sdk.Executor:\n    \"\"\"Create an executor instance from the config.\"\"\"\n    return ParslPoolExecutor(self.get_executor_config())\n</code></pre>"},{"location":"api/executor/python/","title":"webs.executor.python","text":"<code>webs/executor/python.py</code>"},{"location":"api/executor/python/#webs.executor.python.ProcessPoolConfig","title":"ProcessPoolConfig","text":"<p>             Bases: <code>ExecutorConfig</code></p> <p>Process pool executor configuration.</p> <p>Attributes:</p> <ul> <li> <code>max_processes</code>             (<code>int</code>)         \u2013          <p>Maximum number of processes.</p> </li> </ul>"},{"location":"api/executor/python/#webs.executor.python.ProcessPoolConfig.add_argument_group","title":"add_argument_group()  <code>classmethod</code>","text":"<pre><code>add_argument_group(\n    parser: ArgumentParser,\n    *,\n    argv: Sequence[str] | None = None,\n    required: bool = True\n) -&gt; None\n</code></pre> <p>Add model fields as arguments of an argument group on the parser.</p> <p>Parameters:</p> <ul> <li> <code>parser</code>             (<code>ArgumentParser</code>)         \u2013          <p>Parser to add a new argument group to.</p> </li> <li> <code>argv</code>             (<code>Sequence[str] | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional sequence of string arguments.</p> </li> <li> <code>required</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Mark arguments without defaults as required.</p> </li> </ul> Source code in <code>webs/config.py</code> <pre><code>@classmethod\ndef add_argument_group(\n    cls,\n    parser: argparse.ArgumentParser,\n    *,\n    argv: Sequence[str] | None = None,\n    required: bool = True,\n) -&gt; None:\n    \"\"\"Add model fields as arguments of an argument group on the parser.\n\n    Args:\n        parser: Parser to add a new argument group to.\n        argv: Optional sequence of string arguments.\n        required: Mark arguments without defaults as required.\n    \"\"\"\n    group = parser.add_argument_group(cls.__name__)\n    for field_name, field_info in cls.model_fields.items():\n        arg_name = field_name.replace('_', '-').lower()\n        group.add_argument(\n            f'--{arg_name}',\n            dest=field_name,\n            # type=field_info.annotation,\n            default=field_info.get_default(),\n            required=field_info.is_required() and required,\n            help=field_info.description,\n        )\n</code></pre>"},{"location":"api/executor/python/#webs.executor.python.ProcessPoolConfig.get_executor","title":"get_executor()","text":"<pre><code>get_executor() -&gt; DAGExecutor\n</code></pre> <p>Create an executor instance from the config.</p> Source code in <code>webs/executor/python.py</code> <pre><code>def get_executor(self) -&gt; DAGExecutor:\n    \"\"\"Create an executor instance from the config.\"\"\"\n    return DAGExecutor(ProcessPoolExecutor(self.max_processes))\n</code></pre>"},{"location":"api/executor/python/#webs.executor.python.ThreadPoolConfig","title":"ThreadPoolConfig","text":"<p>             Bases: <code>ExecutorConfig</code></p> <p>Thread pool executor configuration.</p> <p>Attributes:</p> <ul> <li> <code>max_threads</code>             (<code>int</code>)         \u2013          <p>Maximum number of threads.</p> </li> </ul>"},{"location":"api/executor/python/#webs.executor.python.ThreadPoolConfig.add_argument_group","title":"add_argument_group()  <code>classmethod</code>","text":"<pre><code>add_argument_group(\n    parser: ArgumentParser,\n    *,\n    argv: Sequence[str] | None = None,\n    required: bool = True\n) -&gt; None\n</code></pre> <p>Add model fields as arguments of an argument group on the parser.</p> <p>Parameters:</p> <ul> <li> <code>parser</code>             (<code>ArgumentParser</code>)         \u2013          <p>Parser to add a new argument group to.</p> </li> <li> <code>argv</code>             (<code>Sequence[str] | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional sequence of string arguments.</p> </li> <li> <code>required</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Mark arguments without defaults as required.</p> </li> </ul> Source code in <code>webs/config.py</code> <pre><code>@classmethod\ndef add_argument_group(\n    cls,\n    parser: argparse.ArgumentParser,\n    *,\n    argv: Sequence[str] | None = None,\n    required: bool = True,\n) -&gt; None:\n    \"\"\"Add model fields as arguments of an argument group on the parser.\n\n    Args:\n        parser: Parser to add a new argument group to.\n        argv: Optional sequence of string arguments.\n        required: Mark arguments without defaults as required.\n    \"\"\"\n    group = parser.add_argument_group(cls.__name__)\n    for field_name, field_info in cls.model_fields.items():\n        arg_name = field_name.replace('_', '-').lower()\n        group.add_argument(\n            f'--{arg_name}',\n            dest=field_name,\n            # type=field_info.annotation,\n            default=field_info.get_default(),\n            required=field_info.is_required() and required,\n            help=field_info.description,\n        )\n</code></pre>"},{"location":"api/executor/python/#webs.executor.python.ThreadPoolConfig.get_executor","title":"get_executor()","text":"<pre><code>get_executor() -&gt; DAGExecutor\n</code></pre> <p>Create an executor instance from the config.</p> Source code in <code>webs/executor/python.py</code> <pre><code>def get_executor(self) -&gt; DAGExecutor:\n    \"\"\"Create an executor instance from the config.\"\"\"\n    return DAGExecutor(ThreadPoolExecutor(self.max_threads))\n</code></pre>"},{"location":"api/executor/workflow/","title":"webs.executor.workflow","text":"<code>webs/executor/workflow.py</code>"},{"location":"api/executor/workflow/#webs.executor.workflow.ExecutionInfo","title":"ExecutionInfo  <code>dataclass</code>","text":"<pre><code>ExecutionInfo(\n    hostname: str,\n    execution_start_time: float,\n    execution_end_time: float,\n    task_start_time: float,\n    task_end_time: float,\n    input_transform_start_time: float,\n    input_transform_end_time: float,\n    result_transform_start_time: float,\n    result_transform_end_time: float,\n)\n</code></pre> <p>Task execution information.</p>"},{"location":"api/executor/workflow/#webs.executor.workflow.TaskInfo","title":"TaskInfo  <code>dataclass</code>","text":"<pre><code>TaskInfo(\n    task_id: str,\n    function_name: str,\n    parent_task_ids: list[str],\n    submit_time: float,\n    received_time: float | None = None,\n    execution: ExecutionInfo | None = None,\n)\n</code></pre> <p>Task information.</p>"},{"location":"api/executor/workflow/#webs.executor.workflow.TaskFuture","title":"TaskFuture","text":"<pre><code>TaskFuture(\n    future: Future[_TaskResult[T]],\n    info: TaskInfo,\n    data_transformer: TaskDataTransformer[Any],\n)\n</code></pre> <p>             Bases: <code>Generic[T]</code></p> <p>Workflow task future.</p> Note <p>This class should not be instantiated by clients.</p> <p>Attributes:</p> <ul> <li> <code>info</code>         \u2013          <p>Task information and metadata.</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>future</code>             (<code>Future[_TaskResult[T]]</code>)         \u2013          <p>Underlying future returned by the compute executor.</p> </li> <li> <code>info</code>             (<code>TaskInfo</code>)         \u2013          <p>Task information and metadata.</p> </li> <li> <code>data_transformer</code>             (<code>TaskDataTransformer[Any]</code>)         \u2013          <p>Data transformer used to resolve the task result.</p> </li> </ul> Source code in <code>webs/executor/workflow.py</code> <pre><code>def __init__(\n    self,\n    future: Future[_TaskResult[T]],\n    info: TaskInfo,\n    data_transformer: TaskDataTransformer[Any],\n) -&gt; None:\n    self.info = info\n    self._future = future\n    self._data_transformer = data_transformer\n</code></pre>"},{"location":"api/executor/workflow/#webs.executor.workflow.TaskFuture.cancel","title":"cancel()","text":"<pre><code>cancel() -&gt; bool\n</code></pre> <p>Attempt to cancel the task.</p> <p>If the call is currently being executed or finished running and cannot be cancelled then the method will return <code>False</code>, otherwise the call will be cancelled and the method will return <code>True</code>.</p> Source code in <code>webs/executor/workflow.py</code> <pre><code>def cancel(self) -&gt; bool:\n    \"\"\"Attempt to cancel the task.\n\n    If the call is currently being executed or finished running and\n    cannot be cancelled then the method will return `False`, otherwise\n    the call will be cancelled and the method will return `True`.\n    \"\"\"\n    return self._future.cancel()\n</code></pre>"},{"location":"api/executor/workflow/#webs.executor.workflow.TaskFuture.result","title":"result()","text":"<pre><code>result(timeout: float | None = None) -&gt; T\n</code></pre> <p>Get the result of the task.</p> <p>Parameters:</p> <ul> <li> <code>timeout</code>             (<code>float | None</code>, default:                 <code>None</code> )         \u2013          <p>If the task has not finished, wait up to <code>timeout</code> seconds.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>T</code>         \u2013          <p>Task result if the task completed successfully.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>TimeoutError</code>           \u2013          <p>If <code>timeout</code> is specified and the task does not complete within <code>timeout</code> seconds.</p> </li> </ul> Source code in <code>webs/executor/workflow.py</code> <pre><code>def result(self, timeout: float | None = None) -&gt; T:\n    \"\"\"Get the result of the task.\n\n    Args:\n        timeout: If the task has not finished, wait up to `timeout`\n            seconds.\n\n    Returns:\n        Task result if the task completed successfully.\n\n    Raises:\n        TimeoutError: If `timeout` is specified and the task does not\n            complete within `timeout` seconds.\n    \"\"\"\n    task_result = self._future.result(timeout=timeout)\n    result = self._data_transformer.resolve(task_result.result)\n    return result\n</code></pre>"},{"location":"api/executor/workflow/#webs.executor.workflow.WorkflowExecutor","title":"WorkflowExecutor","text":"<pre><code>WorkflowExecutor(\n    compute_executor: Executor,\n    *,\n    data_transformer: (\n        TaskDataTransformer[Any] | None\n    ) = None,\n    record_logger: RecordLogger | None = None\n)\n</code></pre> <p>Workflow executor.</p> <p>Parameters:</p> <ul> <li> <code>compute_executor</code>             (<code>Executor</code>)         \u2013          <p>Compute executor.</p> </li> </ul> Source code in <code>webs/executor/workflow.py</code> <pre><code>def __init__(\n    self,\n    compute_executor: Executor,\n    *,\n    data_transformer: TaskDataTransformer[Any] | None = None,\n    record_logger: RecordLogger | None = None,\n) -&gt; None:\n    self.compute_executor = compute_executor\n    self.data_transformer = (\n        data_transformer\n        if data_transformer is not None\n        else TaskDataTransformer(NullTransformer())\n    )\n    self.record_logger = (\n        record_logger if record_logger is not None else NullRecordLogger()\n    )\n\n    # Internal bookkeeping\n    self._running_tasks: dict[Future[Any], TaskFuture[Any]] = {}\n</code></pre>"},{"location":"api/executor/workflow/#webs.executor.workflow.WorkflowExecutor.submit","title":"submit()","text":"<pre><code>submit(\n    function: Callable[P, T], /, *args: Any, **kwargs: Any\n) -&gt; TaskFuture[T]\n</code></pre> <p>Schedule the callable to be executed.</p> <p>This function can also accept <code>TaskFuture</code> objects as input to denote dependencies between a parent and this child task.</p> <p>Parameters:</p> <ul> <li> <code>function</code>             (<code>Callable[P, T]</code>)         \u2013          <p>Callable to execute.</p> </li> <li> <code>args</code>             (<code>Any</code>, default:                 <code>()</code> )         \u2013          <p>Positional arguments.</p> </li> <li> <code>kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>Keyword arguments.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>TaskFuture[T]</code>         \u2013          <p><code>TaskFuture</code> object             representing the result of the execution of the callable</p> </li> <li> <code>TaskFuture[T]</code>         \u2013          <p>accessible via             <code>TaskFuture.result()</code>.</p> </li> </ul> Source code in <code>webs/executor/workflow.py</code> <pre><code>def submit(\n    self,\n    function: Callable[P, T],\n    /,\n    *args: Any,\n    **kwargs: Any,\n) -&gt; TaskFuture[T]:\n    \"\"\"Schedule the callable to be executed.\n\n    This function can also accept\n    [`TaskFuture`][webs.executor.workflow.TaskFuture] objects as input\n    to denote dependencies between a parent and this child task.\n\n    Args:\n        function: Callable to execute.\n        args: Positional arguments.\n        kwargs: Keyword arguments.\n\n    Returns:\n        [`TaskFuture`][webs.executor.workflow.TaskFuture] object \\\n        representing the result of the execution of the callable\n        accessible via \\\n        [`TaskFuture.result()`][webs.executor.workflow.TaskFuture.result].\n    \"\"\"\n    task_id = uuid.uuid4()\n    task = _TaskWrapper(\n        function,\n        task_id=task_id,\n        data_transformer=self.data_transformer,\n    )\n\n    parents = [\n        str(arg.info.task_id)\n        for arg in (*args, *kwargs.values())\n        if isinstance(arg, TaskFuture)\n    ]\n    info = TaskInfo(\n        task_id=str(task_id),\n        function_name=function.__name__,\n        parent_task_ids=parents,\n        submit_time=time.time(),\n    )\n\n    # Extract executor futures from inside TaskFuture objects\n    args = tuple(\n        arg._future if isinstance(arg, TaskFuture) else arg for arg in args\n    )\n    kwargs = {\n        k: v._future if isinstance(v, TaskFuture) else v\n        for k, v in kwargs.items()\n    }\n\n    args = self.data_transformer.transform_iterable(args)\n    kwargs = self.data_transformer.transform_mapping(kwargs)\n\n    future = self.compute_executor.submit(task, *args, **kwargs)\n\n    task_future = TaskFuture(future, info, self.data_transformer)\n    self._running_tasks[future] = task_future\n    future.add_done_callback(self._task_done_callback)\n\n    return task_future\n</code></pre>"},{"location":"api/executor/workflow/#webs.executor.workflow.WorkflowExecutor.map","title":"map()","text":"<pre><code>map(\n    function: Callable[P, T],\n    *iterables: Iterable[args],\n    timeout: float | None = None,\n    chunksize: int = 1\n) -&gt; Iterator[T]\n</code></pre> <p>Map a function onto iterables of arguments.</p> <p>Parameters:</p> <ul> <li> <code>function</code>             (<code>Callable[P, T]</code>)         \u2013          <p>A callable that will take as many arguments as there are passed iterables.</p> </li> <li> <code>iterables</code>             (<code>Iterable[args]</code>, default:                 <code>()</code> )         \u2013          <p>Variable number of iterables.</p> </li> <li> <code>timeout</code>             (<code>float | None</code>, default:                 <code>None</code> )         \u2013          <p>The maximum number of seconds to wait. If None, then there is no limit on the wait time.</p> </li> <li> <code>chunksize</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Currently no supported. If greater than one, the iterables will be chopped into chunks of size chunksize and submitted to the executor. If set to one, the items in the list will be sent one at a time.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Iterator[T]</code>         \u2013          <p>An iterator equivalent to: <code>map(func, *iterables)</code> but the calls             may be evaluated out-of-order.</p> </li> </ul> Source code in <code>webs/executor/workflow.py</code> <pre><code>def map(\n    self,\n    function: Callable[P, T],\n    *iterables: Iterable[P.args],\n    timeout: float | None = None,\n    chunksize: int = 1,\n) -&gt; Iterator[T]:\n    \"\"\"Map a function onto iterables of arguments.\n\n    Args:\n        function: A callable that will take as many arguments as there are\n            passed iterables.\n        iterables: Variable number of iterables.\n        timeout: The maximum number of seconds to wait. If None, then there\n            is no limit on the wait time.\n        chunksize: Currently no supported. If greater than one, the\n            iterables will be chopped into chunks of size chunksize\n            and submitted to the executor. If set to one, the items in the\n            list will be sent one at a time.\n\n    Returns:\n        An iterator equivalent to: `map(func, *iterables)` but the calls \\\n        may be evaluated out-of-order.\n    \"\"\"\n    # Source: https://github.com/python/cpython/blob/ec1398e117fb142cc830495503dbdbb1ddafe941/Lib/concurrent/futures/_base.py#L583-L625\n    if timeout is not None:\n        end_time = timeout + time.monotonic()\n\n    tasks = [self.submit(function, *args) for args in zip(*iterables)]\n\n    # Yield must be hidden in closure so that the futures are submitted\n    # before the first iterator value is required.\n    def _result_iterator() -&gt; Generator[T, None, None]:\n        try:\n            # reverse to keep finishing order\n            tasks.reverse()\n            while tasks:\n                # Careful not to keep a reference to the popped future\n                if timeout is None:\n                    yield _result_or_cancel(tasks.pop())\n                else:\n                    yield _result_or_cancel(\n                        tasks.pop(),\n                        end_time - time.monotonic(),\n                    )\n        finally:  # pragma: no cover\n            for task in tasks:\n                task.cancel()\n\n    return _result_iterator()\n</code></pre>"},{"location":"api/executor/workflow/#webs.executor.workflow.WorkflowExecutor.shutdown","title":"shutdown()","text":"<pre><code>shutdown(\n    wait: bool = True, *, cancel_futures: bool = False\n) -&gt; None\n</code></pre> <p>Shutdown the executor.</p> <p>Parameters:</p> <ul> <li> <code>wait</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Wait on all pending futures to complete.</p> </li> <li> <code>cancel_futures</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Cancel all pending futures that the executor has not started running. Only used in Python 3.9 and later.</p> </li> </ul> Source code in <code>webs/executor/workflow.py</code> <pre><code>def shutdown(\n    self,\n    wait: bool = True,\n    *,\n    cancel_futures: bool = False,\n) -&gt; None:\n    \"\"\"Shutdown the executor.\n\n    Args:\n        wait: Wait on all pending futures to complete.\n        cancel_futures: Cancel all pending futures that the executor\n            has not started running. Only used in Python 3.9 and later.\n    \"\"\"\n    if sys.version_info &gt;= (3, 9):  # pragma: &gt;=3.9 cover\n        self.compute_executor.shutdown(\n            wait=wait,\n            cancel_futures=cancel_futures,\n        )\n    else:  # pragma: &lt;3.9 cover\n        self.compute_executor.shutdown(wait=wait)\n</code></pre>"},{"location":"api/run/","title":"webs.run","text":"<code>webs/run/__init__.py</code>"},{"location":"api/run/config/","title":"webs.run.config","text":"<code>webs/run/config.py</code>"},{"location":"api/run/config/#webs.run.config.RunConfig","title":"RunConfig","text":"<p>             Bases: <code>Config</code></p> <p>Run configuration.</p> <p>Attributes:</p> <ul> <li> <code>log_file_level</code>             (<code>Union[int, str]</code>)         \u2013          <p>Logging level for the log file.</p> </li> <li> <code>log_file_name</code>             (<code>Optional[str]</code>)         \u2013          <p>Logging file name. If <code>None</code>, only logging to <code>stdout</code> is used.</p> </li> <li> <code>log_level</code>             (<code>Union[int, str]</code>)         \u2013          <p>Logging level for <code>stdout</code>.</p> </li> <li> <code>run_dir</code>             (<code>str</code>)         \u2013          <p>Runtime directory.</p> </li> </ul>"},{"location":"api/run/config/#webs.run.config.RunConfig.add_argument_group","title":"add_argument_group()  <code>classmethod</code>","text":"<pre><code>add_argument_group(\n    parser: ArgumentParser,\n    *,\n    argv: Sequence[str] | None = None,\n    required: bool = True\n) -&gt; None\n</code></pre> <p>Add model fields as arguments of an argument group on the parser.</p> <p>Parameters:</p> <ul> <li> <code>parser</code>             (<code>ArgumentParser</code>)         \u2013          <p>Parser to add a new argument group to.</p> </li> <li> <code>argv</code>             (<code>Sequence[str] | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional sequence of string arguments.</p> </li> <li> <code>required</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Mark arguments without defaults as required.</p> </li> </ul> Source code in <code>webs/config.py</code> <pre><code>@classmethod\ndef add_argument_group(\n    cls,\n    parser: argparse.ArgumentParser,\n    *,\n    argv: Sequence[str] | None = None,\n    required: bool = True,\n) -&gt; None:\n    \"\"\"Add model fields as arguments of an argument group on the parser.\n\n    Args:\n        parser: Parser to add a new argument group to.\n        argv: Optional sequence of string arguments.\n        required: Mark arguments without defaults as required.\n    \"\"\"\n    group = parser.add_argument_group(cls.__name__)\n    for field_name, field_info in cls.model_fields.items():\n        arg_name = field_name.replace('_', '-').lower()\n        group.add_argument(\n            f'--{arg_name}',\n            dest=field_name,\n            # type=field_info.annotation,\n            default=field_info.get_default(),\n            required=field_info.is_required() and required,\n            help=field_info.description,\n        )\n</code></pre>"},{"location":"api/run/config/#webs.run.config.BenchmarkConfig","title":"BenchmarkConfig","text":"<p>             Bases: <code>Config</code></p> <p>Workflow benchmark configuration.</p> <p>Attributes:</p> <ul> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>Name of the workflow to execute.</p> </li> <li> <code>timestamp</code>             (<code>datetime</code>)         \u2013          <p>Start time of the workflow.</p> </li> <li> <code>run</code>             (<code>SerializeAsAny[RunConfig]</code>)         \u2013          <p>Run configuration.</p> </li> <li> <code>workflow</code>             (<code>SerializeAsAny[Config]</code>)         \u2013          <p>Workflow configuration.</p> </li> </ul>"},{"location":"api/run/config/#webs.run.config.BenchmarkConfig.add_argument_group","title":"add_argument_group()  <code>classmethod</code>","text":"<pre><code>add_argument_group(\n    parser: ArgumentParser,\n    *,\n    argv: Sequence[str] | None = None,\n    required: bool = True\n) -&gt; None\n</code></pre> <p>Add model fields as arguments of an argument group on the parser.</p> <p>Parameters:</p> <ul> <li> <code>parser</code>             (<code>ArgumentParser</code>)         \u2013          <p>Parser to add a new argument group to.</p> </li> <li> <code>argv</code>             (<code>Sequence[str] | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional sequence of string arguments.</p> </li> <li> <code>required</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Mark arguments without defaults as required.</p> </li> </ul> Source code in <code>webs/config.py</code> <pre><code>@classmethod\ndef add_argument_group(\n    cls,\n    parser: argparse.ArgumentParser,\n    *,\n    argv: Sequence[str] | None = None,\n    required: bool = True,\n) -&gt; None:\n    \"\"\"Add model fields as arguments of an argument group on the parser.\n\n    Args:\n        parser: Parser to add a new argument group to.\n        argv: Optional sequence of string arguments.\n        required: Mark arguments without defaults as required.\n    \"\"\"\n    group = parser.add_argument_group(cls.__name__)\n    for field_name, field_info in cls.model_fields.items():\n        arg_name = field_name.replace('_', '-').lower()\n        group.add_argument(\n            f'--{arg_name}',\n            dest=field_name,\n            # type=field_info.annotation,\n            default=field_info.get_default(),\n            required=field_info.is_required() and required,\n            help=field_info.description,\n        )\n</code></pre>"},{"location":"api/run/config/#webs.run.config.BenchmarkConfig.get_log_file","title":"get_log_file()","text":"<pre><code>get_log_file() -&gt; Path | None\n</code></pre> <p>Get the log file if specified.</p> Source code in <code>webs/run/config.py</code> <pre><code>def get_log_file(self) -&gt; pathlib.Path | None:\n    \"\"\"Get the log file if specified.\"\"\"\n    log_file_name = self.run.log_file_name\n    if log_file_name is None:\n        return None\n    return self.get_run_dir() / log_file_name\n</code></pre>"},{"location":"api/run/config/#webs.run.config.BenchmarkConfig.get_task_record_file","title":"get_task_record_file()","text":"<pre><code>get_task_record_file() -&gt; Path\n</code></pre> <p>Get the task record file.</p> Source code in <code>webs/run/config.py</code> <pre><code>def get_task_record_file(self) -&gt; pathlib.Path:\n    \"\"\"Get the task record file.\"\"\"\n    return self.get_run_dir() / self.run.task_record_file_name\n</code></pre>"},{"location":"api/run/config/#webs.run.config.BenchmarkConfig.get_run_dir","title":"get_run_dir()","text":"<pre><code>get_run_dir() -&gt; Path\n</code></pre> <p>Create and return the path to the run directory.</p> Source code in <code>webs/run/config.py</code> <pre><code>def get_run_dir(self) -&gt; pathlib.Path:\n    \"\"\"Create and return the path to the run directory.\"\"\"\n    timestamp = self.timestamp.strftime('%Y-%m-%d-%H-%M-%S')\n    run_dir = pathlib.Path(\n        self.run.run_dir.format(name=self.name, timestamp=timestamp),\n    )\n    run_dir.mkdir(parents=True, exist_ok=True)\n    return run_dir\n</code></pre>"},{"location":"api/run/main/","title":"webs.run.main","text":"<code>webs/run/main.py</code>"},{"location":"api/run/main/#webs.run.main.parse_args_to_config","title":"parse_args_to_config()","text":"<pre><code>parse_args_to_config(\n    argv: Sequence[str],\n) -&gt; BenchmarkConfig\n</code></pre> <p>Parse sequence of string arguments into a config.</p> <p>Parameters:</p> <ul> <li> <code>argv</code>             (<code>Sequence[str]</code>)         \u2013          <p>Sequence of string arguments.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>BenchmarkConfig</code>         \u2013          <p>Configuration.</p> </li> </ul> Source code in <code>webs/run/main.py</code> <pre><code>def parse_args_to_config(argv: Sequence[str]) -&gt; BenchmarkConfig:\n    \"\"\"Parse sequence of string arguments into a config.\n\n    Args:\n        argv: Sequence of string arguments.\n\n    Returns:\n        Configuration.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        description='Workflow benchmark suite.',\n        prog='python -m webs.run',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n    )\n\n    subparsers = parser.add_subparsers(\n        title='Workflows',\n        dest='name',\n        required=True,\n        help='workflow to execute',\n    )\n\n    workflows = get_registered()\n    workflow_names = sorted(workflows.keys())\n    for workflow_name in workflow_names:\n        workflow = workflows[workflow_name]\n        subparser = subparsers.add_parser(workflow.name)\n\n        RunConfig.add_argument_group(subparser, argv=argv, required=True)\n        ExecutorChoicesConfig.add_argument_group(\n            subparser,\n            argv=argv,\n            required=True,\n        )\n        workflow.config_type.add_argument_group(\n            subparser,\n            argv=argv,\n            required=True,\n        )\n\n    args = parser.parse_args(argv)\n    options = vars(args)\n\n    workflow_name = options['name']\n    executor_config = get_executor_config(**options)\n    run_config = RunConfig(**options)\n    workflow_config = workflows[workflow_name].config_type(**options)\n\n    return BenchmarkConfig(\n        name=workflow_name,\n        timestamp=datetime.now(),\n        executor=executor_config,\n        run=run_config,\n        workflow=workflow_config,\n    )\n</code></pre>"},{"location":"api/run/main/#webs.run.main.run","title":"run()","text":"<pre><code>run(config: BenchmarkConfig) -&gt; None\n</code></pre> <p>Run a workflow using the configuration.</p> Source code in <code>webs/run/main.py</code> <pre><code>@_cwd_run_dir\ndef run(config: BenchmarkConfig) -&gt; None:\n    \"\"\"Run a workflow using the configuration.\"\"\"\n    start = time.perf_counter()\n    logger.log(RUN_LOG_LEVEL, f'Starting workflow (name={config.name})')\n    logger.log(RUN_LOG_LEVEL, config)\n    logger.log(\n        RUN_LOG_LEVEL,\n        f'Runtime directory: {config.get_run_dir().resolve()}',\n    )\n\n    config_json = config.model_dump_json(exclude={'timestamp'}, indent=4)\n    with open(config.get_run_dir() / 'config.json', 'w') as f:\n        f.write(config_json)\n\n    workflow = get_registered()[config.name].from_config(config.workflow)\n\n    compute_executor = config.executor.get_executor()\n    record_logger = JSONRecordLogger(config.get_task_record_file())\n    executor = WorkflowExecutor(compute_executor, record_logger=record_logger)\n\n    with workflow, record_logger, executor:\n        workflow.run(executor=executor, run_dir=config.get_run_dir())\n\n    runtime = time.perf_counter() - start\n    logger.log(\n        RUN_LOG_LEVEL,\n        f'Finished workflow (name={config.name}, runtime={runtime:.2f}s)',\n    )\n</code></pre>"},{"location":"api/wf/","title":"webs.wf","text":"<code>webs/wf/__init__.py</code>"},{"location":"api/wf/synthetic/","title":"webs.wf.synthetic","text":"<code>webs/wf/synthetic/__init__.py</code>"},{"location":"api/wf/synthetic/config/","title":"webs.wf.synthetic.config","text":"<code>webs/wf/synthetic/config.py</code>"},{"location":"api/wf/synthetic/config/#webs.wf.synthetic.config.SyntheticWorkflowConfig","title":"SyntheticWorkflowConfig","text":"<p>             Bases: <code>Config</code></p> <p>Synthetic workflow configuration.</p>"},{"location":"api/wf/synthetic/config/#webs.wf.synthetic.config.SyntheticWorkflowConfig.add_argument_group","title":"add_argument_group()  <code>classmethod</code>","text":"<pre><code>add_argument_group(\n    parser: ArgumentParser,\n    *,\n    argv: Sequence[str] | None = None,\n    required: bool = True\n) -&gt; None\n</code></pre> <p>Add model fields as arguments of an argument group on the parser.</p> <p>Parameters:</p> <ul> <li> <code>parser</code>             (<code>ArgumentParser</code>)         \u2013          <p>Parser to add a new argument group to.</p> </li> <li> <code>argv</code>             (<code>Sequence[str] | None</code>, default:                 <code>None</code> )         \u2013          <p>Optional sequence of string arguments.</p> </li> <li> <code>required</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Mark arguments without defaults as required.</p> </li> </ul> Source code in <code>webs/config.py</code> <pre><code>@classmethod\ndef add_argument_group(\n    cls,\n    parser: argparse.ArgumentParser,\n    *,\n    argv: Sequence[str] | None = None,\n    required: bool = True,\n) -&gt; None:\n    \"\"\"Add model fields as arguments of an argument group on the parser.\n\n    Args:\n        parser: Parser to add a new argument group to.\n        argv: Optional sequence of string arguments.\n        required: Mark arguments without defaults as required.\n    \"\"\"\n    group = parser.add_argument_group(cls.__name__)\n    for field_name, field_info in cls.model_fields.items():\n        arg_name = field_name.replace('_', '-').lower()\n        group.add_argument(\n            f'--{arg_name}',\n            dest=field_name,\n            # type=field_info.annotation,\n            default=field_info.get_default(),\n            required=field_info.is_required() and required,\n            help=field_info.description,\n        )\n</code></pre>"},{"location":"api/wf/synthetic/utils/","title":"webs.wf.synthetic.utils","text":"<code>webs/wf/synthetic/utils.py</code>"},{"location":"api/wf/synthetic/utils/#webs.wf.synthetic.utils.randbytes","title":"randbytes()","text":"<pre><code>randbytes(size: int) -&gt; bytes\n</code></pre> <p>Get random byte string of specified size.</p> <p>Uses <code>random.randbytes()</code> in Python 3.9 or newer and <code>os.urandom()</code> in Python 3.8 and older.</p> <p>Parameters:</p> <ul> <li> <code>size</code>             (<code>int</code>)         \u2013          <p>size of byte string to return.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bytes</code>         \u2013          <p>random byte string.</p> </li> </ul> Source code in <code>webs/wf/synthetic/utils.py</code> <pre><code>def randbytes(size: int) -&gt; bytes:\n    \"\"\"Get random byte string of specified size.\n\n    Uses `random.randbytes()` in Python 3.9 or newer and\n    `os.urandom()` in Python 3.8 and older.\n\n    Args:\n        size (int): size of byte string to return.\n\n    Returns:\n        random byte string.\n    \"\"\"\n    max_bytes = int(1e9)\n    if sys.version_info &gt;= (3, 9) and size &lt; max_bytes:  # pragma: &gt;=3.9 cover\n        return random.randbytes(size)\n    else:  # pragma: &lt;3.9 cover\n        return os.urandom(size)\n</code></pre>"},{"location":"api/wf/synthetic/workflow/","title":"webs.wf.synthetic.workflow","text":"<code>webs/wf/synthetic/workflow.py</code>"},{"location":"api/wf/synthetic/workflow/#webs.wf.synthetic.workflow.SyntheticWorkflow","title":"SyntheticWorkflow","text":"<pre><code>SyntheticWorkflow(config: SyntheticWorkflowConfig)\n</code></pre> <p>             Bases: <code>ContextManagerAddIn</code></p> <p>Synthetic workflow.</p> <p>Parameters:</p> <ul> <li> <code>config</code>             (<code>SyntheticWorkflowConfig</code>)         \u2013          <p>Workflow configuration.</p> </li> </ul> Source code in <code>webs/wf/synthetic/workflow.py</code> <pre><code>def __init__(self, config: SyntheticWorkflowConfig) -&gt; None:\n    self.config = config\n    super().__init__()\n</code></pre>"},{"location":"api/wf/synthetic/workflow/#webs.wf.synthetic.workflow.SyntheticWorkflow.from_config","title":"from_config()  <code>classmethod</code>","text":"<pre><code>from_config(config: SyntheticWorkflowConfig) -&gt; Self\n</code></pre> <p>Initialize a workflow from a config.</p> <p>Parameters:</p> <ul> <li> <code>config</code>             (<code>SyntheticWorkflowConfig</code>)         \u2013          <p>Workflow configuration.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Self</code>         \u2013          <p>Workflow.</p> </li> </ul> Source code in <code>webs/wf/synthetic/workflow.py</code> <pre><code>@classmethod\ndef from_config(cls, config: SyntheticWorkflowConfig) -&gt; Self:\n    \"\"\"Initialize a workflow from a config.\n\n    Args:\n        config: Workflow configuration.\n\n    Returns:\n        Workflow.\n    \"\"\"\n    return cls(config)\n</code></pre>"},{"location":"api/wf/synthetic/workflow/#webs.wf.synthetic.workflow.SyntheticWorkflow.run","title":"run()","text":"<pre><code>run(executor: WorkflowExecutor, run_dir: Path) -&gt; None\n</code></pre> <p>Run the workflow.</p> <p>Parameters:</p> <ul> <li> <code>executor</code>             (<code>WorkflowExecutor</code>)         \u2013          <p>Workflow task executor.</p> </li> <li> <code>run_dir</code>             (<code>Path</code>)         \u2013          <p>Run directory.</p> </li> </ul> Source code in <code>webs/wf/synthetic/workflow.py</code> <pre><code>def run(self, executor: WorkflowExecutor, run_dir: pathlib.Path) -&gt; None:\n    \"\"\"Run the workflow.\n\n    Args:\n        executor: Workflow task executor.\n        run_dir: Run directory.\n    \"\"\"\n    initial_data = randbytes(self.config.task_data_bytes)\n    tasks: list[TaskFuture[bytes]] = []\n\n    for i in range(self.config.task_count):\n        input_data = initial_data if i == 0 else tasks[-1]\n        task = executor.submit(\n            noop_task,\n            input_data,\n            output_size=self.config.task_data_bytes,\n            sleep=self.config.task_sleep,\n        )\n        tasks.append(task)\n        logger.log(\n            WORK_LOG_LEVEL,\n            f'Submitted task {i+1}/{self.config.task_count} '\n            f'(task_id={task.info.task_id})',\n        )\n\n    for i, task in enumerate(tasks):\n        task.result()\n        logger.log(\n            WORK_LOG_LEVEL,\n            f'Received task {i+1}/{self.config.task_count} '\n            f'(task_id={task.info.task_id})',\n        )\n</code></pre>"},{"location":"api/wf/synthetic/workflow/#webs.wf.synthetic.workflow.noop_task","title":"noop_task()","text":"<pre><code>noop_task(\n    data: bytes, output_size: int, sleep: float\n) -&gt; bytes\n</code></pre> <p>No-op sleep task.</p> <p>Parameters:</p> <ul> <li> <code>data</code>             (<code>bytes</code>)         \u2013          <p>Input byte string.</p> </li> <li> <code>output_size</code>             (<code>int</code>)         \u2013          <p>Size in bytes of output byte-string.</p> </li> <li> <code>sleep</code>             (<code>float</code>)         \u2013          <p>Minimum runtime of the task. Time required to generate the output data will be subtracted from this sleep time.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bytes</code>         \u2013          <p>Byte-string of length <code>output_size</code>.</p> </li> </ul> Source code in <code>webs/wf/synthetic/workflow.py</code> <pre><code>def noop_task(data: bytes, output_size: int, sleep: float) -&gt; bytes:\n    \"\"\"No-op sleep task.\n\n    Args:\n        data: Input byte string.\n        output_size: Size in bytes of output byte-string.\n        sleep: Minimum runtime of the task. Time required to generate the\n            output data will be subtracted from this sleep time.\n\n    Returns:\n        Byte-string of length `output_size`.\n    \"\"\"\n    start = time.perf_counter_ns()\n    result = randbytes(output_size)\n    elapsed = (time.perf_counter_ns() - start) / 1e9\n\n    # Remove elapsed time for generating result from remaining\n    # sleep time.\n    time.sleep(max(0, sleep - elapsed))\n    return result\n</code></pre>"},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#getting-started-for-local-development","title":"Getting Started for Local Development","text":"<p>We recommend using Tox to setup the development environment. This will create a new virtual environment with all of the required packages installed and WEBS installed in editable mode with the necessary extras options.</p> <pre><code>$ git clone https://github.com/proxystore/webs\n$ cd foobar\n$ tox --devenv venv -e py311\n$ . venv/bin/activate\n</code></pre> <p>Warning</p> <p>Running Tox in a Conda environment is possible but it may conflict with Tox's ability to find the correct Python versions. E.g., if your Conda environment is Python 3.11, running <code>$ tox -e p310</code> may still use Python 3.11.</p> <p>To install manually: <pre><code>$ git clone https://github.com/proxystore/webs\n$ cd webs\n$ python -m venv venv\n$ . venv/bin/activate\n$ pip install -e .[dev,docs]\n</code></pre></p>"},{"location":"contributing/#continuous-integration","title":"Continuous Integration","text":"<p>FooBar uses pre-commit and Tox for continuous integration (test, linting, etc.).</p>"},{"location":"contributing/#linting-and-type-checking-pre-commit","title":"Linting and Type Checking (pre-commit)","text":"<p>To use pre-commit, install the hook and then run against files.</p> <pre><code>$ pre-commit install\n$ pre-commit run --all-files\n</code></pre>"},{"location":"contributing/#tests-tox","title":"Tests (tox)","text":"<p>The entire CI workflow can be run with <code>$ tox</code>. This will test against multiple versions of Python and can be slow.</p> <p>Module-level unit-test are located in the <code>tests/</code> directory and its structure is intended to match that of <code>foobar/</code>. E.g. the tests for <code>webs/x/y.py</code> are located in <code>tests/x/y_test.py</code>; however, additional test files can be added as needed. Tests should be narrowly focused and target a single aspect of the code's functionality, tests should not test internal implementation details of the code, and tests should not be dependent on the order in which they are run.</p> <p>Code that is useful for building tests but is not a test itself belongs in the <code>testing/</code> directory.</p> <pre><code># Run all tests in tests/\n$ tox -e py39\n# Run a specific test\n$ tox -e py39 -- tests/x/y_test.py::test_z\n</code></pre>"},{"location":"contributing/#docs","title":"Docs","text":"<p>If code changes require an update to the documentation (e.g., for function signature changes, new modules, etc.), the documentation can be built using MKDocs.</p> <pre><code># Manually\n$ pip install -e .[docs]\n$ mkdocs build --strict  # Build only to site/index.html\n$ mkdocs serve           # Serve locally\n\n# With tox (will only build, does not serve)\n$ tox -e docs\n</code></pre> <p>Docstrings are automatically generated, but it is recommended to check the generated docstrings to make sure details/links/etc. are correct.</p>"},{"location":"contributing/issues-pull-requests/","title":"Issues and Pull Requests","text":""},{"location":"contributing/issues-pull-requests/#issues","title":"Issues","text":"<p>Issue Tracker</p> <p>We use GitHub issues to report problems, request and track changes, and discuss future ideas. If you open an issue for a specific problem, please follow the template guides.</p>"},{"location":"contributing/issues-pull-requests/#pull-requests","title":"Pull Requests","text":"<p>We use the standard GitHub contribution cycle where all contributions are made via pull requests (including code owners!).</p> <ol> <li>Fork the repository and clone to your local machine.</li> <li> <p>Create local changes.</p> <ul> <li>Changes should conform to the style and testing guidelines, referenced   above.</li> <li>Preferred commit message format (source):<ul> <li>separate subject from body with a blank line,</li> <li>limit subject line to 50 characters,</li> <li>capitalize first word of subject line,</li> <li>do not end the subject line with a period,</li> <li>use the imperative mood for subject lines,</li> <li>include related issue numbers at end of subject line,</li> <li>wrap body at 72 characters, and</li> <li>use the body to explain what/why rather than how.</li> <li>Example: <code>Fix concurrency bug in Store (#42)</code></li> </ul> </li> </ul> </li> <li> <p>Push commits to your fork.</p> <ul> <li>Please squash commits fixing mistakes to keep the git history clean.   For example, if commit \"b\" follows commit \"a\" and only fixes a small typo   from \"a\", please squash \"a\" and \"b\" into a single, correct commit.   This keeps the commit history readable and easier to search through when   debugging (e.g., git blame/bisect).</li> </ul> </li> <li>Open a pull request in this repository.<ul> <li>The pull request should include a description of the motivation for the   PR and included changes. A PR template is provided to guide this process.</li> </ul> </li> </ol>"},{"location":"contributing/releases/","title":"Releases","text":""},{"location":"contributing/releases/#release-timeline","title":"Release Timeline","text":"<p>Releases are created on an as-needed basis. Milestones are the Issue Tracker are used to track features to be included in upcoming releases.</p>"},{"location":"contributing/releases/#creating-releases","title":"Creating Releases","text":"<ol> <li>Choose the next version number, referred to as <code>{VERSION}</code> for the    rest of the instructions. Versioning follows semver    (<code>major.minor.patch</code>) with optional PEP-440    pre-release/post-release/dev-release segments. Major/minor/patch numbers    start at 0 and pre-release/post-release/dev-release segments start at 1.</li> <li>Update the version in <code>pyproject.toml</code> to <code>{VERSION}</code>.</li> <li>Commit and merge the version updates/changelogs into main.</li> <li>Tag the release commit and push (typically this is the commit updating the    version numbers).    <pre><code>$ git tag -s v{VERSION} -m \"FooBar v{VERSION}\"\n$ git push origin v{VERSION}\n</code></pre>    Note the version number is prepended by \"v\" for the tags so we can    distinguish release tags from non-release tags.</li> <li>Create a new release on GitHub using the tag. The title should be    <code>FooBar v{VERSION}</code>.</li> <li>Official release:<ol> <li>Use the \"Generate release notes\" option and set the previous tag as the previous official release tag. E.g., for <code>v0.4.1</code>, the previous release tag should be <code>v0.4.0</code> and NOT <code>v0.4.1a1</code>.</li> <li>Add an \"Upgrade Steps\" section at the top (see previous releases for examples).</li> <li>Review the generated notes and edit as needed. PRs are organized by tag, but some PRs will be missing tags and need to be moved from the \"Other Changes\" section to the correct section.</li> <li>Select \"Set as the latest release.\"</li> </ol> </li> <li>Unofficial release: (alpha/dev builds)<ol> <li>Do NOT generate release notes. The body can be along the lines of \"Development pre-prelease for <code>V{VERSION}</code>.\"</li> <li>Leave the previous tag as \"auto.\"</li> <li>Select \"Set as a pre-release.\"</li> </ol> </li> </ol>"},{"location":"contributing/style-guide/","title":"Style Guide","text":"<p>The Python code and docstring format mostly follows Google's Python Style Guide, but the pre-commit config is the authoritative source for code format compliance.</p> <p>Nits:</p> <ul> <li>Avoid imports in <code>__init__.py</code> (reduces the likelihood of circular imports).</li> <li>Prefer pure functions where possible.</li> <li>Define all class attributes inside <code>__init__</code> so all attributes are visible   in one place. Attributes that are defined later can be set as <code>None</code>   as a placeholder.</li> <li>Prefer f-strings (<code>f'name: {name}</code>) over string format   (<code>'name: {}'.format(name)</code>). Never use the <code>%</code> operator.</li> <li>Prefer typing.NamedTuple over collections.namedtuple.</li> <li>Use lower-case and no punctuation for log messages, but use upper-case and   punctuation for exception values.   <pre><code>logger.info(f'new connection opened to {address}')\nraise ValueError('Name must contain alphanumeric characters only.')\n</code></pre></li> <li>Document all exceptions that may be raised by a function in the docstring.</li> </ul>"},{"location":"guides/","title":"Guides","text":"<ul> <li>Creating Workflows</li> </ul>"},{"location":"guides/creating-workflows/","title":"Creating Workflows","text":"<p>This guide describes creating a workflow within the WEBS framework.</p>"},{"location":"guides/creating-workflows/#installation","title":"Installation","text":"<p>A development environment needs to be configured first. Fork the repository and clone your fork locally. Then, configure a virtual environment with the WEBS package and development dependencies.</p> <pre><code>python -m venv venv\n. venv/bin/activate\npip install -e .[dev,docs]\n</code></pre> <p>See Getting Started for Local Development for detailed instructions on running the linters and continuous integration tests.</p>"},{"location":"guides/creating-workflows/#workflow-structure","title":"Workflow Structure","text":"<p>Our example workflow is going to be called <code>foobar</code>. All workflows in WEBS are composed of two required components: a <code>Config</code> and a <code>Workflow</code>. The <code>Config</code> is a Pydantic <code>BaseModel</code> with some extra functionality for constructing a config instance from command line arguments. The <code>Workflow</code> is a protocol with two key methods to implement: <code>from_config()</code> and <code>run()</code>.</p> <p>All workflows are submodules of <code>webs/wf/</code>. In this example, we will create the <code>webs/wf/foobar</code> directory containing the following files.</p> <pre><code>webs/\n\u251c\u2500 wf/\n\u2502  \u251c\u2500 __init__.py\n\u2502  \u251c\u2500 foobar/\n\u2502  \u2502  \u251c\u2500 __init__.py\n\u2502  \u2502  \u251c\u2500 config.py\n\u2502  \u2502  \u251c\u2500 workflow.py\n</code></pre> <p>The first file, <code>webs/wf/foobar/__init__.py</code>, will contain the following lines. webs/wf/foobar/__init__.py<pre><code>from __future__ import annotations\n\nimport webs.wf.foobar.workflow\n</code></pre> This import is necessary to run some registration code we will add in <code>webs/wf/foobar/workflow.py</code>. We will also need to add the following line to <code>webs/wf/__init__.py</code> or the above import will not be run when the CLI is invoked. <pre><code>import webs.wf.foobar\n</code></pre></p> <p>The second file, <code>webs/wf/foobar/config.py</code>, will contain the configuration model for the workflow. This configuration should contain all of the parameters that the user needs to provide or that can be adjusted for the workflow. In our case, the <code>foobar</code> workflow is simply going to print a user defined message <code>n</code> number of times. webs/wf/foobar/config.py<pre><code>from __future__ import annotations\n\nfrom pydantic import Field\n\nfrom webs.config import Config\n\n\nclass FoobarWorkflowConfig(Config):\n    \"\"\"Foobar workflow configuration.\"\"\"\n\n    message: str = Field(description='message to print')\n    repeat: int = Field(1, description='number of times to repeat message')\n</code></pre> The <code>Config</code> class supports required arguments without default values (e.g., <code>message</code>) and optional arguments with default values (e.g., <code>repeat</code>).</p> <p>The final file, <code>webs/wf/foobar/workflow.py</code>, will contain the core workflow logic. Task functions and workflow code can be included here or in another module within <code>webs/wf/foobar</code>. For example, this trivial example workflow will be entirely contained within <code>webs/wf/foobar/workflow.py</code> but more complex workflows may want to split up the code across many modules. Nonetheless, the entry point for the workflow will be in the <code>run()</code> method inside of <code>webs/wf/foorbar/workflow.py</code>. We'll first list the code, then discuss the important sections. webs/wf/foobar/workflow.py<pre><code>from __future__ import annotations\n\nimport logging\nimport pathlib\nimport sys\n\nif sys.version_info &gt;= (3, 11):  # pragma: &gt;=3.11 cover\n    from typing import Self\nelse:  # pragma: &lt;3.11 cover\n    from typing_extensions import Self\n\nfrom webs.context import ContextManagerAddIn\nfrom webs.executor.workflow import WorkflowExecutor\nfrom webs.logging import WORK_LOG_LEVEL\nfrom webs.wf.foobar.config import FoobarWorkflowConfig\nfrom webs.workflow import register\n\nlogger = logging.getLogger(__name__)\n\n\ndef print_message(message: str) -&gt; None:\n    \"\"\"Print a message.\"\"\"\n    logger.log(WORK_LOG_LEVEL, message)\n\n\n@register()\nclass FoobarWorkflow(ContextManagerAddIn):\n    \"\"\"Foobar workflow.\n\n    Args:\n        message: Message to print.\n        repeat: Number of times to repeat the message.\n    \"\"\"\n\n    name = 'foobar'\n    config_type = FoobarWorkflowConfig\n\n    def __init__(self, message: str, repeat: int = 1) -&gt; None:\n        self.message = message\n        self.repeat = repeat\n        super().__init__()\n\n    @classmethod\n    def from_config(cls, config: FoobarWorkflowConfig) -&gt; Self:\n        \"\"\"Initialize a workflow from a config.\n\n        Args:\n            config: Workflow configuration.\n\n        Returns:\n            Workflow.\n        \"\"\"\n        return cls(message=config.message, repeat=config.repeat)\n\n    def run(self, executor: WorkflowExecutor, run_dir: pathlib.Path) -&gt; None:\n        \"\"\"Run the workflow.\n\n        Args:\n            executor: Workflow task executor.\n            run_dir: Run directory.\n        \"\"\"\n        for _ in range(self.repeat):\n            task = executor.submit(print_message, self.message)\n            task.result()  # Wait on task to finish\n</code></pre></p> <ol> <li>Workflows in WEBS are composed on tasks which are just Python functions.    Here, our task is the <code>print_message</code> function.</li> <li>The <code>FoobarWorkflow</code> implements the <code>Workflow</code> protocol.    Importantly, <code>FoobarWorkflow</code> is decorated by the <code>@register()</code> decorator which tells WEBS to add this workflow to the command line interface (CLI).    The <code>@register()</code> decorator uses the <code>name = 'foobar'</code> attribute of <code>FoobarWorkflow</code> as the name used in the CLI to select this workflow.    The <code>config_type = FoobarWorkflowConfig</code> attribute tells the CLI that the <code>FoobarWorkflowConfig</code> we defined in <code>webs/wf/foobar/config.py</code> is the configuration to create command line arguments from.</li> <li>When the CLI is invoked for this workflow, the arguments will be parsed into a <code>FoobarWorkflowConfig</code> and then <code>FoobarWorkflow.from_config()</code> will be used to instantiate the workflow runner.</li> <li>Once <code>FoobarWorkflow</code> is instantiated from the config, <code>FoobarWorkflow.run()</code> will be invoked.    This method takes two arguments: a <code>WorkflowExecutor</code> and a path to the invocations run directory.    Workflows are free to use the run directory as needed, such as to store result files.</li> </ol>"},{"location":"guides/creating-workflows/#workflow-executor","title":"Workflow Executor","text":"<p>The <code>WorkflowExecutor</code> is the key abstraction of the WEBS framework. The CLI arguments provided by the user for the compute engine, data management, and task logging logic are used to create a <code>WorkflowExecutor</code> instance which is then provided to the workflow. <code>WorkflowExecutor.submit()</code> is the primary method that workflows will use to execute tasks asynchronously. This method returns a <code>TaskFuture</code> object with a <code>result()</code> which will wait on the task to finish and return the result. Alternatively, <code>WorkflowExecutor.map()</code> can be used to map a task onto a sequence of inputs, compute the tasks in parallel, and gather the results. Importantly, a <code>TaskFuture</code> can also be passed as input to another tasks. Doing so indicates to the <code>WorkflowExecutor</code> that there is a dependency between those two tasks.</p>"},{"location":"guides/creating-workflows/#running-a-workflow","title":"Running a Workflow","text":"<p>Once a workflow is created and registered within WEBS, the workflow is available within the CLI. <pre><code>python -m webs.run foobar --help\n</code></pre> Using <code>foobar</code> as the first positional argument indicates we want to execute the <code>foobar</code> workflow, and <code>--help</code> will print all of the required and optional arguments of the workflow. The arguments will be separated into sections, such as for arguments specific to the <code>foobar</code> workflow or for executor arguments.</p> <p>The following command will execute the workflow to print \"Hello, World!\" three times. We specify the <code>thread-pool</code> executor because this will allow our printing to show up in the main process. <pre><code>$ python -m webs.run foobar --message 'Hello, World!' --repeat 3 --executor thread-pool\nRUN   (webs.run) :: Starting workflow (name=foobar)\n...\nWORK  (webs.wf.foobar.workflow) :: Hello, World!\nWORK  (webs.wf.foobar.workflow) :: Hello, World!\nWORK  (webs.wf.foobar.workflow) :: Hello, World!\nRUN   (webs.run) :: Finished workflow (name=foobar, runtime=0.00s)\n</code></pre></p>"}]}